{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "\n",
        "def print_model_layers(model, prefix=''):\n",
        "    for name, module in model.named_children():\n",
        "        if len(list(module.children())) > 0:\n",
        "            print_model_layers(module, prefix + name + '.')\n",
        "        else:\n",
        "            print(f'{prefix +\"sep---------------\"+ name}: {module}')\n",
        "\n",
        "# Load the model\n",
        "model = timm.create_model(\"hf_hub:timm/maxvit_tiny_tf_224.in1k\", pretrained=False)\n",
        "\n",
        "# Print all layers and sub-modules of the model\n",
        "print(\"Printing all layers and sub-modules of the model:\")\n",
        "print_model_layers(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT_adgKxt7fV",
        "outputId": "af692ed8-5c49-49ee-a0e1-db203e83936a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing all layers and sub-modules of the model:\n",
            "stem.sep---------------conv1: Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "stem.norm1.sep---------------drop: Identity()\n",
            "stem.norm1.sep---------------act: GELUTanh()\n",
            "stem.sep---------------conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "stages.0.blocks.0.conv.shortcut.sep---------------pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.0.blocks.0.conv.shortcut.sep---------------expand: Identity()\n",
            "stages.0.blocks.0.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.0.blocks.0.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.0.blocks.0.conv.sep---------------down: Identity()\n",
            "stages.0.blocks.0.conv.sep---------------conv1_1x1: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.0.blocks.0.conv.norm1.sep---------------drop: Identity()\n",
            "stages.0.blocks.0.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.0.blocks.0.conv.sep---------------conv2_kxk: Conv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
            "stages.0.blocks.0.conv.norm2.sep---------------drop: Identity()\n",
            "stages.0.blocks.0.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.0.blocks.0.conv.se.sep---------------fc1: Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.0.conv.se.sep---------------bn: Identity()\n",
            "stages.0.blocks.0.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.0.blocks.0.conv.se.sep---------------fc2: Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.0.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.0.blocks.0.conv.sep---------------conv3_1x1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.0.conv.sep---------------drop_path: Identity()\n",
            "stages.0.blocks.0.attn_block.sep---------------norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_block.attn.sep---------------qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.0.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.0.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.attn.sep---------------proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.sep---------------ls1: Identity()\n",
            "stages.0.blocks.0.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.0.blocks.0.attn_block.sep---------------norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_block.mlp.sep---------------fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.0.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.0.blocks.0.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.0.blocks.0.attn_block.mlp.sep---------------fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.sep---------------ls2: Identity()\n",
            "stages.0.blocks.0.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.0.blocks.0.attn_grid.sep---------------norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_grid.attn.sep---------------qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.0.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.0.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.attn.sep---------------proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.sep---------------ls1: Identity()\n",
            "stages.0.blocks.0.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.0.blocks.0.attn_grid.sep---------------norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_grid.mlp.sep---------------fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.0.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.0.blocks.0.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.0.blocks.0.attn_grid.mlp.sep---------------fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.sep---------------ls2: Identity()\n",
            "stages.0.blocks.0.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.0.blocks.1.conv.sep---------------shortcut: Identity()\n",
            "stages.0.blocks.1.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.0.blocks.1.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.0.blocks.1.conv.sep---------------down: Identity()\n",
            "stages.0.blocks.1.conv.sep---------------conv1_1x1: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.0.blocks.1.conv.norm1.sep---------------drop: Identity()\n",
            "stages.0.blocks.1.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.0.blocks.1.conv.sep---------------conv2_kxk: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "stages.0.blocks.1.conv.norm2.sep---------------drop: Identity()\n",
            "stages.0.blocks.1.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.0.blocks.1.conv.se.sep---------------fc1: Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.1.conv.se.sep---------------bn: Identity()\n",
            "stages.0.blocks.1.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.0.blocks.1.conv.se.sep---------------fc2: Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.1.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.0.blocks.1.conv.sep---------------conv3_1x1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.1.conv.sep---------------drop_path: Identity()\n",
            "stages.0.blocks.1.attn_block.sep---------------norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_block.attn.sep---------------qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.1.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.1.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.attn.sep---------------proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.sep---------------ls1: Identity()\n",
            "stages.0.blocks.1.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.0.blocks.1.attn_block.sep---------------norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_block.mlp.sep---------------fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.1.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.0.blocks.1.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.0.blocks.1.attn_block.mlp.sep---------------fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.sep---------------ls2: Identity()\n",
            "stages.0.blocks.1.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.0.blocks.1.attn_grid.sep---------------norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_grid.attn.sep---------------qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.1.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.1.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.attn.sep---------------proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.sep---------------ls1: Identity()\n",
            "stages.0.blocks.1.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.0.blocks.1.attn_grid.sep---------------norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_grid.mlp.sep---------------fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.1.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.0.blocks.1.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.0.blocks.1.attn_grid.mlp.sep---------------fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.sep---------------ls2: Identity()\n",
            "stages.0.blocks.1.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.1.blocks.0.conv.shortcut.sep---------------pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.1.blocks.0.conv.shortcut.sep---------------expand: Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.1.blocks.0.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.1.blocks.0.conv.sep---------------down: Identity()\n",
            "stages.1.blocks.0.conv.sep---------------conv1_1x1: Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.1.blocks.0.conv.norm1.sep---------------drop: Identity()\n",
            "stages.1.blocks.0.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.1.blocks.0.conv.sep---------------conv2_kxk: Conv2dSame(512, 512, kernel_size=(3, 3), stride=(2, 2), groups=512, bias=False)\n",
            "stages.1.blocks.0.conv.norm2.sep---------------drop: Identity()\n",
            "stages.1.blocks.0.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.1.blocks.0.conv.se.sep---------------fc1: Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.se.sep---------------bn: Identity()\n",
            "stages.1.blocks.0.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.1.blocks.0.conv.se.sep---------------fc2: Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.1.blocks.0.conv.sep---------------conv3_1x1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.sep---------------drop_path: Identity()\n",
            "stages.1.blocks.0.attn_block.sep---------------norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_block.attn.sep---------------qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.0.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.0.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.attn.sep---------------proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.sep---------------ls1: Identity()\n",
            "stages.1.blocks.0.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.1.blocks.0.attn_block.sep---------------norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_block.mlp.sep---------------fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.0.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.1.blocks.0.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.1.blocks.0.attn_block.mlp.sep---------------fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.sep---------------ls2: Identity()\n",
            "stages.1.blocks.0.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.1.blocks.0.attn_grid.sep---------------norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_grid.attn.sep---------------qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.0.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.0.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.attn.sep---------------proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.sep---------------ls1: Identity()\n",
            "stages.1.blocks.0.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.1.blocks.0.attn_grid.sep---------------norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_grid.mlp.sep---------------fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.0.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.1.blocks.0.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.1.blocks.0.attn_grid.mlp.sep---------------fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.sep---------------ls2: Identity()\n",
            "stages.1.blocks.0.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.1.blocks.1.conv.sep---------------shortcut: Identity()\n",
            "stages.1.blocks.1.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.1.blocks.1.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.1.blocks.1.conv.sep---------------down: Identity()\n",
            "stages.1.blocks.1.conv.sep---------------conv1_1x1: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.1.blocks.1.conv.norm1.sep---------------drop: Identity()\n",
            "stages.1.blocks.1.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.1.blocks.1.conv.sep---------------conv2_kxk: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "stages.1.blocks.1.conv.norm2.sep---------------drop: Identity()\n",
            "stages.1.blocks.1.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.1.blocks.1.conv.se.sep---------------fc1: Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.1.conv.se.sep---------------bn: Identity()\n",
            "stages.1.blocks.1.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.1.blocks.1.conv.se.sep---------------fc2: Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.1.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.1.blocks.1.conv.sep---------------conv3_1x1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.1.conv.sep---------------drop_path: Identity()\n",
            "stages.1.blocks.1.attn_block.sep---------------norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_block.attn.sep---------------qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.1.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.1.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.attn.sep---------------proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.sep---------------ls1: Identity()\n",
            "stages.1.blocks.1.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.1.blocks.1.attn_block.sep---------------norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_block.mlp.sep---------------fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.1.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.1.blocks.1.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.1.blocks.1.attn_block.mlp.sep---------------fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.sep---------------ls2: Identity()\n",
            "stages.1.blocks.1.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.1.blocks.1.attn_grid.sep---------------norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_grid.attn.sep---------------qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.1.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.1.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.attn.sep---------------proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.sep---------------ls1: Identity()\n",
            "stages.1.blocks.1.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.1.blocks.1.attn_grid.sep---------------norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_grid.mlp.sep---------------fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.1.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.1.blocks.1.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.1.blocks.1.attn_grid.mlp.sep---------------fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.sep---------------ls2: Identity()\n",
            "stages.1.blocks.1.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.0.conv.shortcut.sep---------------pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.2.blocks.0.conv.shortcut.sep---------------expand: Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.2.blocks.0.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.2.blocks.0.conv.sep---------------down: Identity()\n",
            "stages.2.blocks.0.conv.sep---------------conv1_1x1: Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.0.conv.norm1.sep---------------drop: Identity()\n",
            "stages.2.blocks.0.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.0.conv.sep---------------conv2_kxk: Conv2dSame(1024, 1024, kernel_size=(3, 3), stride=(2, 2), groups=1024, bias=False)\n",
            "stages.2.blocks.0.conv.norm2.sep---------------drop: Identity()\n",
            "stages.2.blocks.0.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.0.conv.se.sep---------------fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.se.sep---------------bn: Identity()\n",
            "stages.2.blocks.0.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.2.blocks.0.conv.se.sep---------------fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.2.blocks.0.conv.sep---------------conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.sep---------------drop_path: Identity()\n",
            "stages.2.blocks.0.attn_block.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_block.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.0.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.0.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.sep---------------ls1: Identity()\n",
            "stages.2.blocks.0.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.0.attn_block.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_block.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.0.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.0.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.0.attn_block.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.sep---------------ls2: Identity()\n",
            "stages.2.blocks.0.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.0.attn_grid.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_grid.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.0.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.0.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.sep---------------ls1: Identity()\n",
            "stages.2.blocks.0.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.0.attn_grid.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_grid.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.0.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.0.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.0.attn_grid.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.sep---------------ls2: Identity()\n",
            "stages.2.blocks.0.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.1.conv.sep---------------shortcut: Identity()\n",
            "stages.2.blocks.1.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.2.blocks.1.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.2.blocks.1.conv.sep---------------down: Identity()\n",
            "stages.2.blocks.1.conv.sep---------------conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.1.conv.norm1.sep---------------drop: Identity()\n",
            "stages.2.blocks.1.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.1.conv.sep---------------conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.1.conv.norm2.sep---------------drop: Identity()\n",
            "stages.2.blocks.1.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.1.conv.se.sep---------------fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.1.conv.se.sep---------------bn: Identity()\n",
            "stages.2.blocks.1.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.2.blocks.1.conv.se.sep---------------fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.1.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.2.blocks.1.conv.sep---------------conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.1.conv.sep---------------drop_path: Identity()\n",
            "stages.2.blocks.1.attn_block.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_block.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.1.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.1.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.sep---------------ls1: Identity()\n",
            "stages.2.blocks.1.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.1.attn_block.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_block.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.1.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.1.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.1.attn_block.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.sep---------------ls2: Identity()\n",
            "stages.2.blocks.1.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.1.attn_grid.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_grid.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.1.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.1.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.sep---------------ls1: Identity()\n",
            "stages.2.blocks.1.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.1.attn_grid.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_grid.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.1.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.1.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.1.attn_grid.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.sep---------------ls2: Identity()\n",
            "stages.2.blocks.1.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.2.conv.sep---------------shortcut: Identity()\n",
            "stages.2.blocks.2.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.2.blocks.2.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.2.blocks.2.conv.sep---------------down: Identity()\n",
            "stages.2.blocks.2.conv.sep---------------conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.2.conv.norm1.sep---------------drop: Identity()\n",
            "stages.2.blocks.2.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.2.conv.sep---------------conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.2.conv.norm2.sep---------------drop: Identity()\n",
            "stages.2.blocks.2.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.2.conv.se.sep---------------fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.2.conv.se.sep---------------bn: Identity()\n",
            "stages.2.blocks.2.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.2.blocks.2.conv.se.sep---------------fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.2.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.2.blocks.2.conv.sep---------------conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.2.conv.sep---------------drop_path: Identity()\n",
            "stages.2.blocks.2.attn_block.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_block.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.2.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.2.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.sep---------------ls1: Identity()\n",
            "stages.2.blocks.2.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.2.attn_block.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_block.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.2.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.2.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.2.attn_block.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.sep---------------ls2: Identity()\n",
            "stages.2.blocks.2.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.2.attn_grid.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_grid.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.2.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.2.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.sep---------------ls1: Identity()\n",
            "stages.2.blocks.2.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.2.attn_grid.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_grid.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.2.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.2.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.2.attn_grid.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.sep---------------ls2: Identity()\n",
            "stages.2.blocks.2.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.3.conv.sep---------------shortcut: Identity()\n",
            "stages.2.blocks.3.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.2.blocks.3.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.2.blocks.3.conv.sep---------------down: Identity()\n",
            "stages.2.blocks.3.conv.sep---------------conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.3.conv.norm1.sep---------------drop: Identity()\n",
            "stages.2.blocks.3.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.3.conv.sep---------------conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.3.conv.norm2.sep---------------drop: Identity()\n",
            "stages.2.blocks.3.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.3.conv.se.sep---------------fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.3.conv.se.sep---------------bn: Identity()\n",
            "stages.2.blocks.3.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.2.blocks.3.conv.se.sep---------------fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.3.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.2.blocks.3.conv.sep---------------conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.3.conv.sep---------------drop_path: Identity()\n",
            "stages.2.blocks.3.attn_block.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_block.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.3.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.3.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.sep---------------ls1: Identity()\n",
            "stages.2.blocks.3.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.3.attn_block.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_block.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.3.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.3.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.3.attn_block.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.sep---------------ls2: Identity()\n",
            "stages.2.blocks.3.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.3.attn_grid.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_grid.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.3.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.3.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.sep---------------ls1: Identity()\n",
            "stages.2.blocks.3.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.3.attn_grid.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_grid.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.3.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.3.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.3.attn_grid.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.sep---------------ls2: Identity()\n",
            "stages.2.blocks.3.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.4.conv.sep---------------shortcut: Identity()\n",
            "stages.2.blocks.4.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.2.blocks.4.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.2.blocks.4.conv.sep---------------down: Identity()\n",
            "stages.2.blocks.4.conv.sep---------------conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.4.conv.norm1.sep---------------drop: Identity()\n",
            "stages.2.blocks.4.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.4.conv.sep---------------conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.4.conv.norm2.sep---------------drop: Identity()\n",
            "stages.2.blocks.4.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.4.conv.se.sep---------------fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.4.conv.se.sep---------------bn: Identity()\n",
            "stages.2.blocks.4.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.2.blocks.4.conv.se.sep---------------fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.4.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.2.blocks.4.conv.sep---------------conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.4.conv.sep---------------drop_path: Identity()\n",
            "stages.2.blocks.4.attn_block.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_block.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.4.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.4.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.sep---------------ls1: Identity()\n",
            "stages.2.blocks.4.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.4.attn_block.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_block.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.4.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.4.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.4.attn_block.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.sep---------------ls2: Identity()\n",
            "stages.2.blocks.4.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.2.blocks.4.attn_grid.sep---------------norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_grid.attn.sep---------------qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.4.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.4.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.attn.sep---------------proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.sep---------------ls1: Identity()\n",
            "stages.2.blocks.4.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.2.blocks.4.attn_grid.sep---------------norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_grid.mlp.sep---------------fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.4.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.2.blocks.4.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.2.blocks.4.attn_grid.mlp.sep---------------fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.sep---------------ls2: Identity()\n",
            "stages.2.blocks.4.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.3.blocks.0.conv.shortcut.sep---------------pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.3.blocks.0.conv.shortcut.sep---------------expand: Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.3.blocks.0.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.3.blocks.0.conv.sep---------------down: Identity()\n",
            "stages.3.blocks.0.conv.sep---------------conv1_1x1: Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.3.blocks.0.conv.norm1.sep---------------drop: Identity()\n",
            "stages.3.blocks.0.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.3.blocks.0.conv.sep---------------conv2_kxk: Conv2dSame(2048, 2048, kernel_size=(3, 3), stride=(2, 2), groups=2048, bias=False)\n",
            "stages.3.blocks.0.conv.norm2.sep---------------drop: Identity()\n",
            "stages.3.blocks.0.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.3.blocks.0.conv.se.sep---------------fc1: Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.se.sep---------------bn: Identity()\n",
            "stages.3.blocks.0.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.3.blocks.0.conv.se.sep---------------fc2: Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.3.blocks.0.conv.sep---------------conv3_1x1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.sep---------------drop_path: Identity()\n",
            "stages.3.blocks.0.attn_block.sep---------------norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_block.attn.sep---------------qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.0.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.0.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.attn.sep---------------proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.sep---------------ls1: Identity()\n",
            "stages.3.blocks.0.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.3.blocks.0.attn_block.sep---------------norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_block.mlp.sep---------------fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.0.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.3.blocks.0.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.3.blocks.0.attn_block.mlp.sep---------------fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.sep---------------ls2: Identity()\n",
            "stages.3.blocks.0.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.3.blocks.0.attn_grid.sep---------------norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_grid.attn.sep---------------qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.0.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.0.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.attn.sep---------------proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.sep---------------ls1: Identity()\n",
            "stages.3.blocks.0.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.3.blocks.0.attn_grid.sep---------------norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_grid.mlp.sep---------------fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.0.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.3.blocks.0.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.3.blocks.0.attn_grid.mlp.sep---------------fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.sep---------------ls2: Identity()\n",
            "stages.3.blocks.0.attn_grid.sep---------------drop_path2: Identity()\n",
            "stages.3.blocks.1.conv.sep---------------shortcut: Identity()\n",
            "stages.3.blocks.1.conv.pre_norm.sep---------------drop: Identity()\n",
            "stages.3.blocks.1.conv.pre_norm.sep---------------act: Identity()\n",
            "stages.3.blocks.1.conv.sep---------------down: Identity()\n",
            "stages.3.blocks.1.conv.sep---------------conv1_1x1: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.3.blocks.1.conv.norm1.sep---------------drop: Identity()\n",
            "stages.3.blocks.1.conv.norm1.sep---------------act: GELUTanh()\n",
            "stages.3.blocks.1.conv.sep---------------conv2_kxk: Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048, bias=False)\n",
            "stages.3.blocks.1.conv.norm2.sep---------------drop: Identity()\n",
            "stages.3.blocks.1.conv.norm2.sep---------------act: GELUTanh()\n",
            "stages.3.blocks.1.conv.se.sep---------------fc1: Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.1.conv.se.sep---------------bn: Identity()\n",
            "stages.3.blocks.1.conv.se.sep---------------act: SiLU(inplace=True)\n",
            "stages.3.blocks.1.conv.se.sep---------------fc2: Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.1.conv.se.sep---------------gate: Sigmoid()\n",
            "stages.3.blocks.1.conv.sep---------------conv3_1x1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.1.conv.sep---------------drop_path: Identity()\n",
            "stages.3.blocks.1.attn_block.sep---------------norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_block.attn.sep---------------qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.1.attn_block.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.1.attn_block.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.attn.sep---------------proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_block.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.sep---------------ls1: Identity()\n",
            "stages.3.blocks.1.attn_block.sep---------------drop_path1: Identity()\n",
            "stages.3.blocks.1.attn_block.sep---------------norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_block.mlp.sep---------------fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.1.attn_block.mlp.sep---------------act: GELUTanh()\n",
            "stages.3.blocks.1.attn_block.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.mlp.sep---------------norm: Identity()\n",
            "stages.3.blocks.1.attn_block.mlp.sep---------------fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_block.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.sep---------------ls2: Identity()\n",
            "stages.3.blocks.1.attn_block.sep---------------drop_path2: Identity()\n",
            "stages.3.blocks.1.attn_grid.sep---------------norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_grid.attn.sep---------------qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.1.attn_grid.attn.sep---------------rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.1.attn_grid.attn.sep---------------attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.attn.sep---------------proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_grid.attn.sep---------------proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.sep---------------ls1: Identity()\n",
            "stages.3.blocks.1.attn_grid.sep---------------drop_path1: Identity()\n",
            "stages.3.blocks.1.attn_grid.sep---------------norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_grid.mlp.sep---------------fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.1.attn_grid.mlp.sep---------------act: GELUTanh()\n",
            "stages.3.blocks.1.attn_grid.mlp.sep---------------drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.mlp.sep---------------norm: Identity()\n",
            "stages.3.blocks.1.attn_grid.mlp.sep---------------fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_grid.mlp.sep---------------drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.sep---------------ls2: Identity()\n",
            "stages.3.blocks.1.attn_grid.sep---------------drop_path2: Identity()\n",
            "sep---------------norm: Identity()\n",
            "head.global_pool.sep---------------pool: AdaptiveAvgPool2d(output_size=1)\n",
            "head.global_pool.sep---------------flatten: Identity()\n",
            "head.sep---------------norm: LayerNorm2d((512,), eps=1e-05, elementwise_affine=True)\n",
            "head.sep---------------flatten: Flatten(start_dim=1, end_dim=-1)\n",
            "head.pre_logits.sep---------------fc: Linear(in_features=512, out_features=512, bias=True)\n",
            "head.pre_logits.sep---------------act: Tanh()\n",
            "head.sep---------------drop: Dropout(p=0.0, inplace=False)\n",
            "head.sep---------------fc: Linear(in_features=512, out_features=1000, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "def print_model_layers(model, prefix=''):\n",
        "    \"\"\"\n",
        "    Prints all layers and sub-modules of a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "    - model (torch.nn.Module): The model to inspect.\n",
        "    - prefix (str): A prefix for layer naming, used for nested models.\n",
        "    \"\"\"\n",
        "    for name, module in model.named_children():\n",
        "        if len(list(module.children())) > 0:  # If the module has children, recursively print its layers\n",
        "            print_model_layers(module, prefix + name + '.')\n",
        "        else:\n",
        "            print(f'{prefix + name}: {module}')\n",
        "\n",
        "def get_submodel(model, layer_name):\n",
        "    \"\"\"\n",
        "    Extracts a submodel from the original model up to a specified layer.\n",
        "\n",
        "    Args:\n",
        "    - model (torch.nn.Module): The original PyTorch model.\n",
        "    - layer_name (str): The name of the layer up to which the submodel should be extracted.\n",
        "\n",
        "    Returns:\n",
        "    - torch.nn.Module: A submodel that ends at the specified layer.\n",
        "    \"\"\"\n",
        "    submodel = nn.Sequential()\n",
        "    for name, module in model.named_children():\n",
        "        submodel.add_module(name, module)\n",
        "        if name == layer_name:\n",
        "            break\n",
        "        # If the current module has children, recurse into it to find the layer\n",
        "        elif len(list(module.children())) > 0:\n",
        "            submodel[-1] = get_submodel(module, layer_name)\n",
        "            if submodel[-1] is not None:\n",
        "                break\n",
        "    return submodel\n",
        "\n",
        "# Load the model\n",
        "model_name = \"hf_hub:timm/maxvit_tiny_tf_224.in1k\"\n",
        "model = timm.create_model(model_name, pretrained=False)\n",
        "\n",
        "# Print all layers and sub-modules of the model\n",
        "print(\"Printing all layers and sub-modules of the model:\")\n",
        "print_model_layers(model)\n",
        "\n",
        "# Input for layer name\n",
        "layer_name = input(\"Enter the layer name up to which you want the submodel: \")\n",
        "\n",
        "# Extract and print the submodel\n",
        "submodel = get_submodel(model, layer_name)\n",
        "if submodel is not None:\n",
        "    print(f\"\\nSubmodel up to layer '{layer_name}':\")\n",
        "    print(submodel)\n",
        "else:\n",
        "    print(f\"Layer '{layer_name}' not found in the model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABQ1iTNEn1gh",
        "outputId": "5fb5f268-44c5-4fce-8145-2bbf0788f37a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing all layers and sub-modules of the model:\n",
            "stem.conv1: Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "stem.norm1.drop: Identity()\n",
            "stem.norm1.act: GELUTanh()\n",
            "stem.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "stages.0.blocks.0.conv.shortcut.pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.0.blocks.0.conv.shortcut.expand: Identity()\n",
            "stages.0.blocks.0.conv.pre_norm.drop: Identity()\n",
            "stages.0.blocks.0.conv.pre_norm.act: Identity()\n",
            "stages.0.blocks.0.conv.down: Identity()\n",
            "stages.0.blocks.0.conv.conv1_1x1: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.0.blocks.0.conv.norm1.drop: Identity()\n",
            "stages.0.blocks.0.conv.norm1.act: GELUTanh()\n",
            "stages.0.blocks.0.conv.conv2_kxk: Conv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
            "stages.0.blocks.0.conv.norm2.drop: Identity()\n",
            "stages.0.blocks.0.conv.norm2.act: GELUTanh()\n",
            "stages.0.blocks.0.conv.se.fc1: Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.0.conv.se.bn: Identity()\n",
            "stages.0.blocks.0.conv.se.act: SiLU(inplace=True)\n",
            "stages.0.blocks.0.conv.se.fc2: Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.0.conv.se.gate: Sigmoid()\n",
            "stages.0.blocks.0.conv.conv3_1x1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.0.conv.drop_path: Identity()\n",
            "stages.0.blocks.0.attn_block.norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_block.attn.qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.0.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.0.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.attn.proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.ls1: Identity()\n",
            "stages.0.blocks.0.attn_block.drop_path1: Identity()\n",
            "stages.0.blocks.0.attn_block.norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_block.mlp.fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.0.attn_block.mlp.act: GELUTanh()\n",
            "stages.0.blocks.0.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.mlp.norm: Identity()\n",
            "stages.0.blocks.0.attn_block.mlp.fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.ls2: Identity()\n",
            "stages.0.blocks.0.attn_block.drop_path2: Identity()\n",
            "stages.0.blocks.0.attn_grid.norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_grid.attn.qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.0.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.0.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.attn.proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.ls1: Identity()\n",
            "stages.0.blocks.0.attn_grid.drop_path1: Identity()\n",
            "stages.0.blocks.0.attn_grid.norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_grid.mlp.fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.0.attn_grid.mlp.act: GELUTanh()\n",
            "stages.0.blocks.0.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.mlp.norm: Identity()\n",
            "stages.0.blocks.0.attn_grid.mlp.fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.ls2: Identity()\n",
            "stages.0.blocks.0.attn_grid.drop_path2: Identity()\n",
            "stages.0.blocks.1.conv.shortcut: Identity()\n",
            "stages.0.blocks.1.conv.pre_norm.drop: Identity()\n",
            "stages.0.blocks.1.conv.pre_norm.act: Identity()\n",
            "stages.0.blocks.1.conv.down: Identity()\n",
            "stages.0.blocks.1.conv.conv1_1x1: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.0.blocks.1.conv.norm1.drop: Identity()\n",
            "stages.0.blocks.1.conv.norm1.act: GELUTanh()\n",
            "stages.0.blocks.1.conv.conv2_kxk: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "stages.0.blocks.1.conv.norm2.drop: Identity()\n",
            "stages.0.blocks.1.conv.norm2.act: GELUTanh()\n",
            "stages.0.blocks.1.conv.se.fc1: Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.1.conv.se.bn: Identity()\n",
            "stages.0.blocks.1.conv.se.act: SiLU(inplace=True)\n",
            "stages.0.blocks.1.conv.se.fc2: Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.1.conv.se.gate: Sigmoid()\n",
            "stages.0.blocks.1.conv.conv3_1x1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.1.conv.drop_path: Identity()\n",
            "stages.0.blocks.1.attn_block.norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_block.attn.qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.1.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.1.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.attn.proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.ls1: Identity()\n",
            "stages.0.blocks.1.attn_block.drop_path1: Identity()\n",
            "stages.0.blocks.1.attn_block.norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_block.mlp.fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.1.attn_block.mlp.act: GELUTanh()\n",
            "stages.0.blocks.1.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.mlp.norm: Identity()\n",
            "stages.0.blocks.1.attn_block.mlp.fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.ls2: Identity()\n",
            "stages.0.blocks.1.attn_block.drop_path2: Identity()\n",
            "stages.0.blocks.1.attn_grid.norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_grid.attn.qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.1.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.1.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.attn.proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.ls1: Identity()\n",
            "stages.0.blocks.1.attn_grid.drop_path1: Identity()\n",
            "stages.0.blocks.1.attn_grid.norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_grid.mlp.fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.1.attn_grid.mlp.act: GELUTanh()\n",
            "stages.0.blocks.1.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.mlp.norm: Identity()\n",
            "stages.0.blocks.1.attn_grid.mlp.fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.ls2: Identity()\n",
            "stages.0.blocks.1.attn_grid.drop_path2: Identity()\n",
            "stages.1.blocks.0.conv.shortcut.pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.1.blocks.0.conv.shortcut.expand: Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.pre_norm.drop: Identity()\n",
            "stages.1.blocks.0.conv.pre_norm.act: Identity()\n",
            "stages.1.blocks.0.conv.down: Identity()\n",
            "stages.1.blocks.0.conv.conv1_1x1: Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.1.blocks.0.conv.norm1.drop: Identity()\n",
            "stages.1.blocks.0.conv.norm1.act: GELUTanh()\n",
            "stages.1.blocks.0.conv.conv2_kxk: Conv2dSame(512, 512, kernel_size=(3, 3), stride=(2, 2), groups=512, bias=False)\n",
            "stages.1.blocks.0.conv.norm2.drop: Identity()\n",
            "stages.1.blocks.0.conv.norm2.act: GELUTanh()\n",
            "stages.1.blocks.0.conv.se.fc1: Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.se.bn: Identity()\n",
            "stages.1.blocks.0.conv.se.act: SiLU(inplace=True)\n",
            "stages.1.blocks.0.conv.se.fc2: Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.se.gate: Sigmoid()\n",
            "stages.1.blocks.0.conv.conv3_1x1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.drop_path: Identity()\n",
            "stages.1.blocks.0.attn_block.norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_block.attn.qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.0.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.0.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.attn.proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.ls1: Identity()\n",
            "stages.1.blocks.0.attn_block.drop_path1: Identity()\n",
            "stages.1.blocks.0.attn_block.norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_block.mlp.fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.0.attn_block.mlp.act: GELUTanh()\n",
            "stages.1.blocks.0.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.mlp.norm: Identity()\n",
            "stages.1.blocks.0.attn_block.mlp.fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.ls2: Identity()\n",
            "stages.1.blocks.0.attn_block.drop_path2: Identity()\n",
            "stages.1.blocks.0.attn_grid.norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_grid.attn.qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.0.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.0.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.attn.proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.ls1: Identity()\n",
            "stages.1.blocks.0.attn_grid.drop_path1: Identity()\n",
            "stages.1.blocks.0.attn_grid.norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_grid.mlp.fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.0.attn_grid.mlp.act: GELUTanh()\n",
            "stages.1.blocks.0.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.mlp.norm: Identity()\n",
            "stages.1.blocks.0.attn_grid.mlp.fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.ls2: Identity()\n",
            "stages.1.blocks.0.attn_grid.drop_path2: Identity()\n",
            "stages.1.blocks.1.conv.shortcut: Identity()\n",
            "stages.1.blocks.1.conv.pre_norm.drop: Identity()\n",
            "stages.1.blocks.1.conv.pre_norm.act: Identity()\n",
            "stages.1.blocks.1.conv.down: Identity()\n",
            "stages.1.blocks.1.conv.conv1_1x1: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.1.blocks.1.conv.norm1.drop: Identity()\n",
            "stages.1.blocks.1.conv.norm1.act: GELUTanh()\n",
            "stages.1.blocks.1.conv.conv2_kxk: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "stages.1.blocks.1.conv.norm2.drop: Identity()\n",
            "stages.1.blocks.1.conv.norm2.act: GELUTanh()\n",
            "stages.1.blocks.1.conv.se.fc1: Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.1.conv.se.bn: Identity()\n",
            "stages.1.blocks.1.conv.se.act: SiLU(inplace=True)\n",
            "stages.1.blocks.1.conv.se.fc2: Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.1.conv.se.gate: Sigmoid()\n",
            "stages.1.blocks.1.conv.conv3_1x1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.1.conv.drop_path: Identity()\n",
            "stages.1.blocks.1.attn_block.norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_block.attn.qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.1.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.1.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.attn.proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.ls1: Identity()\n",
            "stages.1.blocks.1.attn_block.drop_path1: Identity()\n",
            "stages.1.blocks.1.attn_block.norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_block.mlp.fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.1.attn_block.mlp.act: GELUTanh()\n",
            "stages.1.blocks.1.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.mlp.norm: Identity()\n",
            "stages.1.blocks.1.attn_block.mlp.fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.ls2: Identity()\n",
            "stages.1.blocks.1.attn_block.drop_path2: Identity()\n",
            "stages.1.blocks.1.attn_grid.norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_grid.attn.qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.1.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.1.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.attn.proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.ls1: Identity()\n",
            "stages.1.blocks.1.attn_grid.drop_path1: Identity()\n",
            "stages.1.blocks.1.attn_grid.norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_grid.mlp.fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.1.attn_grid.mlp.act: GELUTanh()\n",
            "stages.1.blocks.1.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.mlp.norm: Identity()\n",
            "stages.1.blocks.1.attn_grid.mlp.fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.ls2: Identity()\n",
            "stages.1.blocks.1.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.0.conv.shortcut.pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.2.blocks.0.conv.shortcut.expand: Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.0.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.0.conv.down: Identity()\n",
            "stages.2.blocks.0.conv.conv1_1x1: Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.0.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.0.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.0.conv.conv2_kxk: Conv2dSame(1024, 1024, kernel_size=(3, 3), stride=(2, 2), groups=1024, bias=False)\n",
            "stages.2.blocks.0.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.0.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.0.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.se.bn: Identity()\n",
            "stages.2.blocks.0.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.0.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.0.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.drop_path: Identity()\n",
            "stages.2.blocks.0.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.0.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.0.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.ls1: Identity()\n",
            "stages.2.blocks.0.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.0.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.0.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.0.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.0.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.ls2: Identity()\n",
            "stages.2.blocks.0.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.0.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.0.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.0.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.0.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.0.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.0.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.0.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.0.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.0.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.1.conv.shortcut: Identity()\n",
            "stages.2.blocks.1.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.1.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.1.conv.down: Identity()\n",
            "stages.2.blocks.1.conv.conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.1.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.1.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.1.conv.conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.1.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.1.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.1.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.1.conv.se.bn: Identity()\n",
            "stages.2.blocks.1.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.1.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.1.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.1.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.1.conv.drop_path: Identity()\n",
            "stages.2.blocks.1.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.1.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.1.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.ls1: Identity()\n",
            "stages.2.blocks.1.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.1.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.1.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.1.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.1.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.ls2: Identity()\n",
            "stages.2.blocks.1.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.1.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.1.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.1.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.1.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.1.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.1.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.1.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.1.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.1.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.2.conv.shortcut: Identity()\n",
            "stages.2.blocks.2.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.2.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.2.conv.down: Identity()\n",
            "stages.2.blocks.2.conv.conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.2.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.2.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.2.conv.conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.2.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.2.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.2.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.2.conv.se.bn: Identity()\n",
            "stages.2.blocks.2.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.2.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.2.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.2.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.2.conv.drop_path: Identity()\n",
            "stages.2.blocks.2.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.2.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.2.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.ls1: Identity()\n",
            "stages.2.blocks.2.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.2.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.2.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.2.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.2.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.ls2: Identity()\n",
            "stages.2.blocks.2.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.2.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.2.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.2.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.2.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.2.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.2.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.2.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.2.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.2.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.3.conv.shortcut: Identity()\n",
            "stages.2.blocks.3.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.3.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.3.conv.down: Identity()\n",
            "stages.2.blocks.3.conv.conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.3.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.3.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.3.conv.conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.3.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.3.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.3.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.3.conv.se.bn: Identity()\n",
            "stages.2.blocks.3.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.3.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.3.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.3.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.3.conv.drop_path: Identity()\n",
            "stages.2.blocks.3.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.3.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.3.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.ls1: Identity()\n",
            "stages.2.blocks.3.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.3.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.3.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.3.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.3.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.ls2: Identity()\n",
            "stages.2.blocks.3.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.3.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.3.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.3.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.3.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.3.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.3.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.3.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.3.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.3.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.4.conv.shortcut: Identity()\n",
            "stages.2.blocks.4.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.4.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.4.conv.down: Identity()\n",
            "stages.2.blocks.4.conv.conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.4.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.4.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.4.conv.conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.4.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.4.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.4.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.4.conv.se.bn: Identity()\n",
            "stages.2.blocks.4.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.4.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.4.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.4.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.4.conv.drop_path: Identity()\n",
            "stages.2.blocks.4.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.4.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.4.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.ls1: Identity()\n",
            "stages.2.blocks.4.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.4.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.4.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.4.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.4.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.ls2: Identity()\n",
            "stages.2.blocks.4.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.4.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.4.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.4.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.4.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.4.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.4.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.4.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.4.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.4.attn_grid.drop_path2: Identity()\n",
            "stages.3.blocks.0.conv.shortcut.pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.3.blocks.0.conv.shortcut.expand: Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.pre_norm.drop: Identity()\n",
            "stages.3.blocks.0.conv.pre_norm.act: Identity()\n",
            "stages.3.blocks.0.conv.down: Identity()\n",
            "stages.3.blocks.0.conv.conv1_1x1: Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.3.blocks.0.conv.norm1.drop: Identity()\n",
            "stages.3.blocks.0.conv.norm1.act: GELUTanh()\n",
            "stages.3.blocks.0.conv.conv2_kxk: Conv2dSame(2048, 2048, kernel_size=(3, 3), stride=(2, 2), groups=2048, bias=False)\n",
            "stages.3.blocks.0.conv.norm2.drop: Identity()\n",
            "stages.3.blocks.0.conv.norm2.act: GELUTanh()\n",
            "stages.3.blocks.0.conv.se.fc1: Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.se.bn: Identity()\n",
            "stages.3.blocks.0.conv.se.act: SiLU(inplace=True)\n",
            "stages.3.blocks.0.conv.se.fc2: Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.se.gate: Sigmoid()\n",
            "stages.3.blocks.0.conv.conv3_1x1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.drop_path: Identity()\n",
            "stages.3.blocks.0.attn_block.norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_block.attn.qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.0.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.0.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.attn.proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.ls1: Identity()\n",
            "stages.3.blocks.0.attn_block.drop_path1: Identity()\n",
            "stages.3.blocks.0.attn_block.norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_block.mlp.fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.0.attn_block.mlp.act: GELUTanh()\n",
            "stages.3.blocks.0.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.mlp.norm: Identity()\n",
            "stages.3.blocks.0.attn_block.mlp.fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.ls2: Identity()\n",
            "stages.3.blocks.0.attn_block.drop_path2: Identity()\n",
            "stages.3.blocks.0.attn_grid.norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_grid.attn.qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.0.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.0.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.attn.proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.ls1: Identity()\n",
            "stages.3.blocks.0.attn_grid.drop_path1: Identity()\n",
            "stages.3.blocks.0.attn_grid.norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_grid.mlp.fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.0.attn_grid.mlp.act: GELUTanh()\n",
            "stages.3.blocks.0.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.mlp.norm: Identity()\n",
            "stages.3.blocks.0.attn_grid.mlp.fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.ls2: Identity()\n",
            "stages.3.blocks.0.attn_grid.drop_path2: Identity()\n",
            "stages.3.blocks.1.conv.shortcut: Identity()\n",
            "stages.3.blocks.1.conv.pre_norm.drop: Identity()\n",
            "stages.3.blocks.1.conv.pre_norm.act: Identity()\n",
            "stages.3.blocks.1.conv.down: Identity()\n",
            "stages.3.blocks.1.conv.conv1_1x1: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.3.blocks.1.conv.norm1.drop: Identity()\n",
            "stages.3.blocks.1.conv.norm1.act: GELUTanh()\n",
            "stages.3.blocks.1.conv.conv2_kxk: Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048, bias=False)\n",
            "stages.3.blocks.1.conv.norm2.drop: Identity()\n",
            "stages.3.blocks.1.conv.norm2.act: GELUTanh()\n",
            "stages.3.blocks.1.conv.se.fc1: Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.1.conv.se.bn: Identity()\n",
            "stages.3.blocks.1.conv.se.act: SiLU(inplace=True)\n",
            "stages.3.blocks.1.conv.se.fc2: Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.1.conv.se.gate: Sigmoid()\n",
            "stages.3.blocks.1.conv.conv3_1x1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.1.conv.drop_path: Identity()\n",
            "stages.3.blocks.1.attn_block.norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_block.attn.qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.1.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.1.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.attn.proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.ls1: Identity()\n",
            "stages.3.blocks.1.attn_block.drop_path1: Identity()\n",
            "stages.3.blocks.1.attn_block.norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_block.mlp.fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.1.attn_block.mlp.act: GELUTanh()\n",
            "stages.3.blocks.1.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.mlp.norm: Identity()\n",
            "stages.3.blocks.1.attn_block.mlp.fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.ls2: Identity()\n",
            "stages.3.blocks.1.attn_block.drop_path2: Identity()\n",
            "stages.3.blocks.1.attn_grid.norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_grid.attn.qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.1.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.1.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.attn.proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.ls1: Identity()\n",
            "stages.3.blocks.1.attn_grid.drop_path1: Identity()\n",
            "stages.3.blocks.1.attn_grid.norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_grid.mlp.fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.1.attn_grid.mlp.act: GELUTanh()\n",
            "stages.3.blocks.1.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.mlp.norm: Identity()\n",
            "stages.3.blocks.1.attn_grid.mlp.fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.ls2: Identity()\n",
            "stages.3.blocks.1.attn_grid.drop_path2: Identity()\n",
            "norm: Identity()\n",
            "head.global_pool.pool: AdaptiveAvgPool2d(output_size=1)\n",
            "head.global_pool.flatten: Identity()\n",
            "head.norm: LayerNorm2d((512,), eps=1e-05, elementwise_affine=True)\n",
            "head.flatten: Flatten(start_dim=1, end_dim=-1)\n",
            "head.pre_logits.fc: Linear(in_features=512, out_features=512, bias=True)\n",
            "head.pre_logits.act: Tanh()\n",
            "head.drop: Dropout(p=0.0, inplace=False)\n",
            "head.fc: Linear(in_features=512, out_features=1000, bias=True)\n",
            "Enter the layer name up to which you want the submodel: stages.3.blocks.1.attn_grid.mlp.norm\n",
            "\n",
            "Submodel up to layer 'stages.3.blocks.1.attn_grid.mlp.norm':\n",
            "Sequential(\n",
            "  (stem): Sequential(\n",
            "    (conv1): Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (norm1): Sequential(\n",
            "      (drop): Identity()\n",
            "      (act): GELUTanh()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "def print_model_layers(model, prefix=''):\n",
        "    \"\"\"\n",
        "    Prints all layers and sub-modules of a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "    - model (torch.nn.Module): The model to inspect.\n",
        "    - prefix (str): A prefix for layer naming, used for nested models.\n",
        "    \"\"\"\n",
        "    for name, module in model.named_children():\n",
        "        if len(list(module.children())) > 0:  # If the module has children, recursively print its layers\n",
        "            print_model_layers(module, prefix + name + '.')\n",
        "        else:\n",
        "            print(f'{prefix + name}: {module}')\n",
        "\n",
        "def extract_submodel(model, layer_name, prefix=''):\n",
        "    \"\"\"\n",
        "    Recursively searches for and extracts a submodel up to the specified layer.\n",
        "\n",
        "    Args:\n",
        "    - model (nn.Module): The model to search.\n",
        "    - layer_name (str): The name of the layer to stop at.\n",
        "    - prefix (str): Current traversal path, used for matching nested layer names.\n",
        "\n",
        "    Returns:\n",
        "    - nn.Sequential: A new model that includes all layers up to the specified one.\n",
        "    \"\"\"\n",
        "    submodel = nn.Sequential()\n",
        "    found = False\n",
        "    for name, module in model.named_children():\n",
        "        current_layer = f\"{prefix}{name}\"\n",
        "        if len(list(module.children())) == 0 or current_layer == layer_name:  # Leaf or target layer\n",
        "            submodel.add_module(name, module)\n",
        "            if current_layer == layer_name:\n",
        "                found = True\n",
        "                break\n",
        "        else:\n",
        "            nested_model, nested_found = extract_submodel(module, layer_name, prefix=current_layer + '.')\n",
        "            if nested_found:\n",
        "                submodel.add_module(name, nested_model)\n",
        "                found = True\n",
        "                break\n",
        "            else:\n",
        "                submodel.add_module(name, module)\n",
        "    return submodel, found\n",
        "\n",
        "# Load the model\n",
        "model_name = \"hf_hub:timm/maxvit_tiny_tf_224.in1k\"\n",
        "model = timm.create_model(model_name, pretrained=False)\n",
        "\n",
        "# Print all layers and sub-modules of the model\n",
        "print(\"Printing all layers and sub-modules of the model:\")\n",
        "print_model_layers(model)\n",
        "\n",
        "# Input for layer name\n",
        "layer_name = input(\"Enter the layer name up to which you want the submodel: \")\n",
        "\n",
        "# Extract and print the submodel\n",
        "submodel, found = extract_submodel(model, layer_name)\n",
        "if found:\n",
        "    print(f\"\\nSubmodel up to layer '{layer_name}':\")\n",
        "    print(submodel)\n",
        "else:\n",
        "    print(f\"Layer '{layer_name}' not found in the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdm3412mwVLQ",
        "outputId": "b7fb1de2-d9bf-4009-9fee-645d5183f572"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing all layers and sub-modules of the model:\n",
            "stem.conv1: Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "stem.norm1.drop: Identity()\n",
            "stem.norm1.act: GELUTanh()\n",
            "stem.conv2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "stages.0.blocks.0.conv.shortcut.pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.0.blocks.0.conv.shortcut.expand: Identity()\n",
            "stages.0.blocks.0.conv.pre_norm.drop: Identity()\n",
            "stages.0.blocks.0.conv.pre_norm.act: Identity()\n",
            "stages.0.blocks.0.conv.down: Identity()\n",
            "stages.0.blocks.0.conv.conv1_1x1: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.0.blocks.0.conv.norm1.drop: Identity()\n",
            "stages.0.blocks.0.conv.norm1.act: GELUTanh()\n",
            "stages.0.blocks.0.conv.conv2_kxk: Conv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
            "stages.0.blocks.0.conv.norm2.drop: Identity()\n",
            "stages.0.blocks.0.conv.norm2.act: GELUTanh()\n",
            "stages.0.blocks.0.conv.se.fc1: Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.0.conv.se.bn: Identity()\n",
            "stages.0.blocks.0.conv.se.act: SiLU(inplace=True)\n",
            "stages.0.blocks.0.conv.se.fc2: Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.0.conv.se.gate: Sigmoid()\n",
            "stages.0.blocks.0.conv.conv3_1x1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.0.conv.drop_path: Identity()\n",
            "stages.0.blocks.0.attn_block.norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_block.attn.qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.0.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.0.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.attn.proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.ls1: Identity()\n",
            "stages.0.blocks.0.attn_block.drop_path1: Identity()\n",
            "stages.0.blocks.0.attn_block.norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_block.mlp.fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.0.attn_block.mlp.act: GELUTanh()\n",
            "stages.0.blocks.0.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.mlp.norm: Identity()\n",
            "stages.0.blocks.0.attn_block.mlp.fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_block.ls2: Identity()\n",
            "stages.0.blocks.0.attn_block.drop_path2: Identity()\n",
            "stages.0.blocks.0.attn_grid.norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_grid.attn.qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.0.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.0.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.attn.proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.ls1: Identity()\n",
            "stages.0.blocks.0.attn_grid.drop_path1: Identity()\n",
            "stages.0.blocks.0.attn_grid.norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.0.attn_grid.mlp.fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.0.attn_grid.mlp.act: GELUTanh()\n",
            "stages.0.blocks.0.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.mlp.norm: Identity()\n",
            "stages.0.blocks.0.attn_grid.mlp.fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.0.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.0.attn_grid.ls2: Identity()\n",
            "stages.0.blocks.0.attn_grid.drop_path2: Identity()\n",
            "stages.0.blocks.1.conv.shortcut: Identity()\n",
            "stages.0.blocks.1.conv.pre_norm.drop: Identity()\n",
            "stages.0.blocks.1.conv.pre_norm.act: Identity()\n",
            "stages.0.blocks.1.conv.down: Identity()\n",
            "stages.0.blocks.1.conv.conv1_1x1: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.0.blocks.1.conv.norm1.drop: Identity()\n",
            "stages.0.blocks.1.conv.norm1.act: GELUTanh()\n",
            "stages.0.blocks.1.conv.conv2_kxk: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "stages.0.blocks.1.conv.norm2.drop: Identity()\n",
            "stages.0.blocks.1.conv.norm2.act: GELUTanh()\n",
            "stages.0.blocks.1.conv.se.fc1: Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.1.conv.se.bn: Identity()\n",
            "stages.0.blocks.1.conv.se.act: SiLU(inplace=True)\n",
            "stages.0.blocks.1.conv.se.fc2: Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.1.conv.se.gate: Sigmoid()\n",
            "stages.0.blocks.1.conv.conv3_1x1: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.0.blocks.1.conv.drop_path: Identity()\n",
            "stages.0.blocks.1.attn_block.norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_block.attn.qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.1.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.1.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.attn.proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.ls1: Identity()\n",
            "stages.0.blocks.1.attn_block.drop_path1: Identity()\n",
            "stages.0.blocks.1.attn_block.norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_block.mlp.fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.1.attn_block.mlp.act: GELUTanh()\n",
            "stages.0.blocks.1.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.mlp.norm: Identity()\n",
            "stages.0.blocks.1.attn_block.mlp.fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_block.ls2: Identity()\n",
            "stages.0.blocks.1.attn_block.drop_path2: Identity()\n",
            "stages.0.blocks.1.attn_grid.norm1: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_grid.attn.qkv: Linear(in_features=64, out_features=192, bias=True)\n",
            "stages.0.blocks.1.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.0.blocks.1.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.attn.proj: Linear(in_features=64, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.ls1: Identity()\n",
            "stages.0.blocks.1.attn_grid.drop_path1: Identity()\n",
            "stages.0.blocks.1.attn_grid.norm2: LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "stages.0.blocks.1.attn_grid.mlp.fc1: Linear(in_features=64, out_features=256, bias=True)\n",
            "stages.0.blocks.1.attn_grid.mlp.act: GELUTanh()\n",
            "stages.0.blocks.1.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.mlp.norm: Identity()\n",
            "stages.0.blocks.1.attn_grid.mlp.fc2: Linear(in_features=256, out_features=64, bias=True)\n",
            "stages.0.blocks.1.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.0.blocks.1.attn_grid.ls2: Identity()\n",
            "stages.0.blocks.1.attn_grid.drop_path2: Identity()\n",
            "stages.1.blocks.0.conv.shortcut.pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.1.blocks.0.conv.shortcut.expand: Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.pre_norm.drop: Identity()\n",
            "stages.1.blocks.0.conv.pre_norm.act: Identity()\n",
            "stages.1.blocks.0.conv.down: Identity()\n",
            "stages.1.blocks.0.conv.conv1_1x1: Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.1.blocks.0.conv.norm1.drop: Identity()\n",
            "stages.1.blocks.0.conv.norm1.act: GELUTanh()\n",
            "stages.1.blocks.0.conv.conv2_kxk: Conv2dSame(512, 512, kernel_size=(3, 3), stride=(2, 2), groups=512, bias=False)\n",
            "stages.1.blocks.0.conv.norm2.drop: Identity()\n",
            "stages.1.blocks.0.conv.norm2.act: GELUTanh()\n",
            "stages.1.blocks.0.conv.se.fc1: Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.se.bn: Identity()\n",
            "stages.1.blocks.0.conv.se.act: SiLU(inplace=True)\n",
            "stages.1.blocks.0.conv.se.fc2: Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.se.gate: Sigmoid()\n",
            "stages.1.blocks.0.conv.conv3_1x1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.0.conv.drop_path: Identity()\n",
            "stages.1.blocks.0.attn_block.norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_block.attn.qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.0.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.0.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.attn.proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.ls1: Identity()\n",
            "stages.1.blocks.0.attn_block.drop_path1: Identity()\n",
            "stages.1.blocks.0.attn_block.norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_block.mlp.fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.0.attn_block.mlp.act: GELUTanh()\n",
            "stages.1.blocks.0.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.mlp.norm: Identity()\n",
            "stages.1.blocks.0.attn_block.mlp.fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_block.ls2: Identity()\n",
            "stages.1.blocks.0.attn_block.drop_path2: Identity()\n",
            "stages.1.blocks.0.attn_grid.norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_grid.attn.qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.0.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.0.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.attn.proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.ls1: Identity()\n",
            "stages.1.blocks.0.attn_grid.drop_path1: Identity()\n",
            "stages.1.blocks.0.attn_grid.norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.0.attn_grid.mlp.fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.0.attn_grid.mlp.act: GELUTanh()\n",
            "stages.1.blocks.0.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.mlp.norm: Identity()\n",
            "stages.1.blocks.0.attn_grid.mlp.fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.0.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.0.attn_grid.ls2: Identity()\n",
            "stages.1.blocks.0.attn_grid.drop_path2: Identity()\n",
            "stages.1.blocks.1.conv.shortcut: Identity()\n",
            "stages.1.blocks.1.conv.pre_norm.drop: Identity()\n",
            "stages.1.blocks.1.conv.pre_norm.act: Identity()\n",
            "stages.1.blocks.1.conv.down: Identity()\n",
            "stages.1.blocks.1.conv.conv1_1x1: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.1.blocks.1.conv.norm1.drop: Identity()\n",
            "stages.1.blocks.1.conv.norm1.act: GELUTanh()\n",
            "stages.1.blocks.1.conv.conv2_kxk: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "stages.1.blocks.1.conv.norm2.drop: Identity()\n",
            "stages.1.blocks.1.conv.norm2.act: GELUTanh()\n",
            "stages.1.blocks.1.conv.se.fc1: Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.1.conv.se.bn: Identity()\n",
            "stages.1.blocks.1.conv.se.act: SiLU(inplace=True)\n",
            "stages.1.blocks.1.conv.se.fc2: Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.1.conv.se.gate: Sigmoid()\n",
            "stages.1.blocks.1.conv.conv3_1x1: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.1.blocks.1.conv.drop_path: Identity()\n",
            "stages.1.blocks.1.attn_block.norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_block.attn.qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.1.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.1.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.attn.proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.ls1: Identity()\n",
            "stages.1.blocks.1.attn_block.drop_path1: Identity()\n",
            "stages.1.blocks.1.attn_block.norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_block.mlp.fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.1.attn_block.mlp.act: GELUTanh()\n",
            "stages.1.blocks.1.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.mlp.norm: Identity()\n",
            "stages.1.blocks.1.attn_block.mlp.fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_block.ls2: Identity()\n",
            "stages.1.blocks.1.attn_block.drop_path2: Identity()\n",
            "stages.1.blocks.1.attn_grid.norm1: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_grid.attn.qkv: Linear(in_features=128, out_features=384, bias=True)\n",
            "stages.1.blocks.1.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.1.blocks.1.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.attn.proj: Linear(in_features=128, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.ls1: Identity()\n",
            "stages.1.blocks.1.attn_grid.drop_path1: Identity()\n",
            "stages.1.blocks.1.attn_grid.norm2: LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "stages.1.blocks.1.attn_grid.mlp.fc1: Linear(in_features=128, out_features=512, bias=True)\n",
            "stages.1.blocks.1.attn_grid.mlp.act: GELUTanh()\n",
            "stages.1.blocks.1.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.mlp.norm: Identity()\n",
            "stages.1.blocks.1.attn_grid.mlp.fc2: Linear(in_features=512, out_features=128, bias=True)\n",
            "stages.1.blocks.1.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.1.blocks.1.attn_grid.ls2: Identity()\n",
            "stages.1.blocks.1.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.0.conv.shortcut.pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.2.blocks.0.conv.shortcut.expand: Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.0.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.0.conv.down: Identity()\n",
            "stages.2.blocks.0.conv.conv1_1x1: Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.0.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.0.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.0.conv.conv2_kxk: Conv2dSame(1024, 1024, kernel_size=(3, 3), stride=(2, 2), groups=1024, bias=False)\n",
            "stages.2.blocks.0.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.0.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.0.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.se.bn: Identity()\n",
            "stages.2.blocks.0.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.0.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.0.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.0.conv.drop_path: Identity()\n",
            "stages.2.blocks.0.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.0.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.0.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.ls1: Identity()\n",
            "stages.2.blocks.0.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.0.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.0.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.0.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.0.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_block.ls2: Identity()\n",
            "stages.2.blocks.0.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.0.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.0.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.0.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.0.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.0.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.0.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.0.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.0.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.0.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.0.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.0.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.0.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.1.conv.shortcut: Identity()\n",
            "stages.2.blocks.1.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.1.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.1.conv.down: Identity()\n",
            "stages.2.blocks.1.conv.conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.1.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.1.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.1.conv.conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.1.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.1.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.1.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.1.conv.se.bn: Identity()\n",
            "stages.2.blocks.1.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.1.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.1.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.1.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.1.conv.drop_path: Identity()\n",
            "stages.2.blocks.1.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.1.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.1.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.ls1: Identity()\n",
            "stages.2.blocks.1.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.1.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.1.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.1.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.1.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_block.ls2: Identity()\n",
            "stages.2.blocks.1.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.1.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.1.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.1.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.1.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.1.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.1.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.1.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.1.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.1.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.1.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.1.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.1.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.2.conv.shortcut: Identity()\n",
            "stages.2.blocks.2.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.2.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.2.conv.down: Identity()\n",
            "stages.2.blocks.2.conv.conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.2.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.2.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.2.conv.conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.2.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.2.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.2.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.2.conv.se.bn: Identity()\n",
            "stages.2.blocks.2.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.2.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.2.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.2.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.2.conv.drop_path: Identity()\n",
            "stages.2.blocks.2.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.2.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.2.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.ls1: Identity()\n",
            "stages.2.blocks.2.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.2.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.2.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.2.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.2.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_block.ls2: Identity()\n",
            "stages.2.blocks.2.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.2.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.2.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.2.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.2.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.2.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.2.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.2.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.2.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.2.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.2.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.2.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.2.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.3.conv.shortcut: Identity()\n",
            "stages.2.blocks.3.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.3.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.3.conv.down: Identity()\n",
            "stages.2.blocks.3.conv.conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.3.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.3.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.3.conv.conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.3.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.3.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.3.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.3.conv.se.bn: Identity()\n",
            "stages.2.blocks.3.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.3.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.3.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.3.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.3.conv.drop_path: Identity()\n",
            "stages.2.blocks.3.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.3.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.3.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.ls1: Identity()\n",
            "stages.2.blocks.3.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.3.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.3.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.3.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.3.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_block.ls2: Identity()\n",
            "stages.2.blocks.3.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.3.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.3.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.3.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.3.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.3.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.3.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.3.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.3.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.3.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.3.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.3.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.3.attn_grid.drop_path2: Identity()\n",
            "stages.2.blocks.4.conv.shortcut: Identity()\n",
            "stages.2.blocks.4.conv.pre_norm.drop: Identity()\n",
            "stages.2.blocks.4.conv.pre_norm.act: Identity()\n",
            "stages.2.blocks.4.conv.down: Identity()\n",
            "stages.2.blocks.4.conv.conv1_1x1: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.2.blocks.4.conv.norm1.drop: Identity()\n",
            "stages.2.blocks.4.conv.norm1.act: GELUTanh()\n",
            "stages.2.blocks.4.conv.conv2_kxk: Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "stages.2.blocks.4.conv.norm2.drop: Identity()\n",
            "stages.2.blocks.4.conv.norm2.act: GELUTanh()\n",
            "stages.2.blocks.4.conv.se.fc1: Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.4.conv.se.bn: Identity()\n",
            "stages.2.blocks.4.conv.se.act: SiLU(inplace=True)\n",
            "stages.2.blocks.4.conv.se.fc2: Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.4.conv.se.gate: Sigmoid()\n",
            "stages.2.blocks.4.conv.conv3_1x1: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.2.blocks.4.conv.drop_path: Identity()\n",
            "stages.2.blocks.4.attn_block.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_block.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.4.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.4.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.ls1: Identity()\n",
            "stages.2.blocks.4.attn_block.drop_path1: Identity()\n",
            "stages.2.blocks.4.attn_block.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_block.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.4.attn_block.mlp.act: GELUTanh()\n",
            "stages.2.blocks.4.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.mlp.norm: Identity()\n",
            "stages.2.blocks.4.attn_block.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_block.ls2: Identity()\n",
            "stages.2.blocks.4.attn_block.drop_path2: Identity()\n",
            "stages.2.blocks.4.attn_grid.norm1: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_grid.attn.qkv: Linear(in_features=256, out_features=768, bias=True)\n",
            "stages.2.blocks.4.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.2.blocks.4.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.attn.proj: Linear(in_features=256, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.ls1: Identity()\n",
            "stages.2.blocks.4.attn_grid.drop_path1: Identity()\n",
            "stages.2.blocks.4.attn_grid.norm2: LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "stages.2.blocks.4.attn_grid.mlp.fc1: Linear(in_features=256, out_features=1024, bias=True)\n",
            "stages.2.blocks.4.attn_grid.mlp.act: GELUTanh()\n",
            "stages.2.blocks.4.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.mlp.norm: Identity()\n",
            "stages.2.blocks.4.attn_grid.mlp.fc2: Linear(in_features=1024, out_features=256, bias=True)\n",
            "stages.2.blocks.4.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.2.blocks.4.attn_grid.ls2: Identity()\n",
            "stages.2.blocks.4.attn_grid.drop_path2: Identity()\n",
            "stages.3.blocks.0.conv.shortcut.pool: AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "stages.3.blocks.0.conv.shortcut.expand: Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.pre_norm.drop: Identity()\n",
            "stages.3.blocks.0.conv.pre_norm.act: Identity()\n",
            "stages.3.blocks.0.conv.down: Identity()\n",
            "stages.3.blocks.0.conv.conv1_1x1: Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.3.blocks.0.conv.norm1.drop: Identity()\n",
            "stages.3.blocks.0.conv.norm1.act: GELUTanh()\n",
            "stages.3.blocks.0.conv.conv2_kxk: Conv2dSame(2048, 2048, kernel_size=(3, 3), stride=(2, 2), groups=2048, bias=False)\n",
            "stages.3.blocks.0.conv.norm2.drop: Identity()\n",
            "stages.3.blocks.0.conv.norm2.act: GELUTanh()\n",
            "stages.3.blocks.0.conv.se.fc1: Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.se.bn: Identity()\n",
            "stages.3.blocks.0.conv.se.act: SiLU(inplace=True)\n",
            "stages.3.blocks.0.conv.se.fc2: Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.se.gate: Sigmoid()\n",
            "stages.3.blocks.0.conv.conv3_1x1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.0.conv.drop_path: Identity()\n",
            "stages.3.blocks.0.attn_block.norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_block.attn.qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.0.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.0.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.attn.proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.ls1: Identity()\n",
            "stages.3.blocks.0.attn_block.drop_path1: Identity()\n",
            "stages.3.blocks.0.attn_block.norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_block.mlp.fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.0.attn_block.mlp.act: GELUTanh()\n",
            "stages.3.blocks.0.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.mlp.norm: Identity()\n",
            "stages.3.blocks.0.attn_block.mlp.fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_block.ls2: Identity()\n",
            "stages.3.blocks.0.attn_block.drop_path2: Identity()\n",
            "stages.3.blocks.0.attn_grid.norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_grid.attn.qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.0.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.0.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.attn.proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.ls1: Identity()\n",
            "stages.3.blocks.0.attn_grid.drop_path1: Identity()\n",
            "stages.3.blocks.0.attn_grid.norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.0.attn_grid.mlp.fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.0.attn_grid.mlp.act: GELUTanh()\n",
            "stages.3.blocks.0.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.mlp.norm: Identity()\n",
            "stages.3.blocks.0.attn_grid.mlp.fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.0.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.0.attn_grid.ls2: Identity()\n",
            "stages.3.blocks.0.attn_grid.drop_path2: Identity()\n",
            "stages.3.blocks.1.conv.shortcut: Identity()\n",
            "stages.3.blocks.1.conv.pre_norm.drop: Identity()\n",
            "stages.3.blocks.1.conv.pre_norm.act: Identity()\n",
            "stages.3.blocks.1.conv.down: Identity()\n",
            "stages.3.blocks.1.conv.conv1_1x1: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "stages.3.blocks.1.conv.norm1.drop: Identity()\n",
            "stages.3.blocks.1.conv.norm1.act: GELUTanh()\n",
            "stages.3.blocks.1.conv.conv2_kxk: Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048, bias=False)\n",
            "stages.3.blocks.1.conv.norm2.drop: Identity()\n",
            "stages.3.blocks.1.conv.norm2.act: GELUTanh()\n",
            "stages.3.blocks.1.conv.se.fc1: Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.1.conv.se.bn: Identity()\n",
            "stages.3.blocks.1.conv.se.act: SiLU(inplace=True)\n",
            "stages.3.blocks.1.conv.se.fc2: Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.1.conv.se.gate: Sigmoid()\n",
            "stages.3.blocks.1.conv.conv3_1x1: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "stages.3.blocks.1.conv.drop_path: Identity()\n",
            "stages.3.blocks.1.attn_block.norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_block.attn.qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.1.attn_block.attn.rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.1.attn_block.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.attn.proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_block.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.ls1: Identity()\n",
            "stages.3.blocks.1.attn_block.drop_path1: Identity()\n",
            "stages.3.blocks.1.attn_block.norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_block.mlp.fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.1.attn_block.mlp.act: GELUTanh()\n",
            "stages.3.blocks.1.attn_block.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.mlp.norm: Identity()\n",
            "stages.3.blocks.1.attn_block.mlp.fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_block.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_block.ls2: Identity()\n",
            "stages.3.blocks.1.attn_block.drop_path2: Identity()\n",
            "stages.3.blocks.1.attn_grid.norm1: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_grid.attn.qkv: Linear(in_features=512, out_features=1536, bias=True)\n",
            "stages.3.blocks.1.attn_grid.attn.rel_pos: RelPosBiasTf()\n",
            "stages.3.blocks.1.attn_grid.attn.attn_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.attn.proj: Linear(in_features=512, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_grid.attn.proj_drop: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.ls1: Identity()\n",
            "stages.3.blocks.1.attn_grid.drop_path1: Identity()\n",
            "stages.3.blocks.1.attn_grid.norm2: LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "stages.3.blocks.1.attn_grid.mlp.fc1: Linear(in_features=512, out_features=2048, bias=True)\n",
            "stages.3.blocks.1.attn_grid.mlp.act: GELUTanh()\n",
            "stages.3.blocks.1.attn_grid.mlp.drop1: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.mlp.norm: Identity()\n",
            "stages.3.blocks.1.attn_grid.mlp.fc2: Linear(in_features=2048, out_features=512, bias=True)\n",
            "stages.3.blocks.1.attn_grid.mlp.drop2: Dropout(p=0.0, inplace=False)\n",
            "stages.3.blocks.1.attn_grid.ls2: Identity()\n",
            "stages.3.blocks.1.attn_grid.drop_path2: Identity()\n",
            "norm: Identity()\n",
            "head.global_pool.pool: AdaptiveAvgPool2d(output_size=1)\n",
            "head.global_pool.flatten: Identity()\n",
            "head.norm: LayerNorm2d((512,), eps=1e-05, elementwise_affine=True)\n",
            "head.flatten: Flatten(start_dim=1, end_dim=-1)\n",
            "head.pre_logits.fc: Linear(in_features=512, out_features=512, bias=True)\n",
            "head.pre_logits.act: Tanh()\n",
            "head.drop: Dropout(p=0.0, inplace=False)\n",
            "head.fc: Linear(in_features=512, out_features=1000, bias=True)\n",
            "Enter the layer name up to which you want the submodel: stages.2.blocks.4.attn_block.norm1\n",
            "\n",
            "Submodel up to layer 'stages.2.blocks.4.attn_block.norm1':\n",
            "Sequential(\n",
            "  (stem): Stem(\n",
            "    (conv1): Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (norm1): BatchNormAct2d(\n",
            "      64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "      (drop): Identity()\n",
            "      (act): GELUTanh()\n",
            "    )\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (stages): Sequential(\n",
            "    (0): MaxxVitStage(\n",
            "      (blocks): Sequential(\n",
            "        (0): MaxxVitBlock(\n",
            "          (conv): MbConvBlock(\n",
            "            (shortcut): Downsample2d(\n",
            "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "              (expand): Identity()\n",
            "            )\n",
            "            (pre_norm): BatchNormAct2d(\n",
            "              64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (down): Identity()\n",
            "            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (norm1): BatchNormAct2d(\n",
            "              256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (conv2_kxk): Conv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256, bias=False)\n",
            "            (norm2): BatchNormAct2d(\n",
            "              256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (se): SEModule(\n",
            "              (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (bn): Identity()\n",
            "              (act): SiLU(inplace=True)\n",
            "              (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (gate): Sigmoid()\n",
            "            )\n",
            "            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (drop_path): Identity()\n",
            "          )\n",
            "          (attn_block): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (attn_grid): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (1): MaxxVitBlock(\n",
            "          (conv): MbConvBlock(\n",
            "            (shortcut): Identity()\n",
            "            (pre_norm): BatchNormAct2d(\n",
            "              64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (down): Identity()\n",
            "            (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (norm1): BatchNormAct2d(\n",
            "              256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "            (norm2): BatchNormAct2d(\n",
            "              256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (se): SEModule(\n",
            "              (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (bn): Identity()\n",
            "              (act): SiLU(inplace=True)\n",
            "              (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (gate): Sigmoid()\n",
            "            )\n",
            "            (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (drop_path): Identity()\n",
            "          )\n",
            "          (attn_block): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (attn_grid): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): MaxxVitStage(\n",
            "      (blocks): Sequential(\n",
            "        (0): MaxxVitBlock(\n",
            "          (conv): MbConvBlock(\n",
            "            (shortcut): Downsample2d(\n",
            "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "              (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (pre_norm): BatchNormAct2d(\n",
            "              64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (down): Identity()\n",
            "            (conv1_1x1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (norm1): BatchNormAct2d(\n",
            "              512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (conv2_kxk): Conv2dSame(512, 512, kernel_size=(3, 3), stride=(2, 2), groups=512, bias=False)\n",
            "            (norm2): BatchNormAct2d(\n",
            "              512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (se): SEModule(\n",
            "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (bn): Identity()\n",
            "              (act): SiLU(inplace=True)\n",
            "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (gate): Sigmoid()\n",
            "            )\n",
            "            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (drop_path): Identity()\n",
            "          )\n",
            "          (attn_block): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (attn_grid): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (1): MaxxVitBlock(\n",
            "          (conv): MbConvBlock(\n",
            "            (shortcut): Identity()\n",
            "            (pre_norm): BatchNormAct2d(\n",
            "              128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (down): Identity()\n",
            "            (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (norm1): BatchNormAct2d(\n",
            "              512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "            (norm2): BatchNormAct2d(\n",
            "              512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (se): SEModule(\n",
            "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (bn): Identity()\n",
            "              (act): SiLU(inplace=True)\n",
            "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (gate): Sigmoid()\n",
            "            )\n",
            "            (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (drop_path): Identity()\n",
            "          )\n",
            "          (attn_block): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (attn_grid): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (blocks): Sequential(\n",
            "        (0): MaxxVitBlock(\n",
            "          (conv): MbConvBlock(\n",
            "            (shortcut): Downsample2d(\n",
            "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "              (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (pre_norm): BatchNormAct2d(\n",
            "              128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (down): Identity()\n",
            "            (conv1_1x1): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (norm1): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (conv2_kxk): Conv2dSame(1024, 1024, kernel_size=(3, 3), stride=(2, 2), groups=1024, bias=False)\n",
            "            (norm2): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (se): SEModule(\n",
            "              (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (bn): Identity()\n",
            "              (act): SiLU(inplace=True)\n",
            "              (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (gate): Sigmoid()\n",
            "            )\n",
            "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (drop_path): Identity()\n",
            "          )\n",
            "          (attn_block): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (attn_grid): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (1): MaxxVitBlock(\n",
            "          (conv): MbConvBlock(\n",
            "            (shortcut): Identity()\n",
            "            (pre_norm): BatchNormAct2d(\n",
            "              256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (down): Identity()\n",
            "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (norm1): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "            (norm2): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (se): SEModule(\n",
            "              (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (bn): Identity()\n",
            "              (act): SiLU(inplace=True)\n",
            "              (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (gate): Sigmoid()\n",
            "            )\n",
            "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (drop_path): Identity()\n",
            "          )\n",
            "          (attn_block): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (attn_grid): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (2): MaxxVitBlock(\n",
            "          (conv): MbConvBlock(\n",
            "            (shortcut): Identity()\n",
            "            (pre_norm): BatchNormAct2d(\n",
            "              256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (down): Identity()\n",
            "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (norm1): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "            (norm2): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (se): SEModule(\n",
            "              (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (bn): Identity()\n",
            "              (act): SiLU(inplace=True)\n",
            "              (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (gate): Sigmoid()\n",
            "            )\n",
            "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (drop_path): Identity()\n",
            "          )\n",
            "          (attn_block): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (attn_grid): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (3): MaxxVitBlock(\n",
            "          (conv): MbConvBlock(\n",
            "            (shortcut): Identity()\n",
            "            (pre_norm): BatchNormAct2d(\n",
            "              256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (down): Identity()\n",
            "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (norm1): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "            (norm2): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (se): SEModule(\n",
            "              (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (bn): Identity()\n",
            "              (act): SiLU(inplace=True)\n",
            "              (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (gate): Sigmoid()\n",
            "            )\n",
            "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (drop_path): Identity()\n",
            "          )\n",
            "          (attn_block): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (attn_grid): PartitionAttentionCl(\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): AttentionCl(\n",
            "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (rel_pos): RelPosBiasTf()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (act): GELUTanh()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (conv): MbConvBlock(\n",
            "            (shortcut): Identity()\n",
            "            (pre_norm): BatchNormAct2d(\n",
            "              256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): Identity()\n",
            "            )\n",
            "            (down): Identity()\n",
            "            (conv1_1x1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (norm1): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (conv2_kxk): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "            (norm2): BatchNormAct2d(\n",
            "              1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
            "              (drop): Identity()\n",
            "              (act): GELUTanh()\n",
            "            )\n",
            "            (se): SEModule(\n",
            "              (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (bn): Identity()\n",
            "              (act): SiLU(inplace=True)\n",
            "              (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (gate): Sigmoid()\n",
            "            )\n",
            "            (conv3_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (drop_path): Identity()\n",
            "          )\n",
            "          (attn_block): Sequential(\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "from torchsummary import summary\n",
        "\n",
        "# Your existing code for model extraction and printing layers\n",
        "\n",
        "# Input for layer name\n",
        "layer_name = input(\"Enter the layer name up to which you want the submodel: \")\n",
        "\n",
        "# Extract and print the submodel\n",
        "submodel, found = extract_submodel(model, layer_name)\n",
        "if found:\n",
        "    print(f\"\\nSubmodel up to layer '{layer_name}':\")\n",
        "    print(submodel)\n",
        "\n",
        "    # Print summary of the submodel\n",
        "    summary(submodel, input_size=(3, 224, 224))  # Adjust input size as per your actual input size\n",
        "else:\n",
        "    print(f\"Layer '{layer_name}' not found in the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "IMGM-hptqqzB",
        "outputId": "92d07b73-0143-4b22-b32b-d9c33ded7996"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-588f1cfb7900>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Input for layer name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the layer name up to which you want the submodel: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Extract and print the submodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "from torchsummary import summary\n",
        "\n",
        "# Function to recursively generate options for selecting the layer\n",
        "def generate_layer_options(model, prefix=''):\n",
        "    options = []\n",
        "    for idx, (name, module) in enumerate(model.named_children(), 1):\n",
        "        if len(list(module.children())) > 0:  # If the module has children, recursively generate options\n",
        "            options += generate_layer_options(module, prefix + name + '.')\n",
        "        else:\n",
        "            options.append((f'{prefix + name}', module))\n",
        "    return options\n",
        "\n",
        "# Load your model here (replace 'model' with your actual model)\n",
        "model = timm.create_model('resnet50', pretrained=True)\n",
        "\n",
        "# Generate options for selecting the layer\n",
        "layer_options = generate_layer_options(model)\n",
        "print(\"Options for selecting the layer:\")\n",
        "for idx, (layer_name, _) in enumerate(layer_options, 1):\n",
        "    print(f\"{idx}. {layer_name}\")\n",
        "\n",
        "# Input for selecting the layer\n",
        "selection = int(input(\"Enter the number corresponding to the layer you want to select: \"))\n",
        "\n",
        "# Extract and print the submodel based on the selected layer\n",
        "if 1 <= selection <= len(layer_options):\n",
        "    selected_layer_name, selected_module = layer_options[selection - 1]\n",
        "    if hasattr(selected_module, 'in_features'):\n",
        "        in_features = selected_module.in_features\n",
        "        print(f\"\\nThe selected layer '{selected_layer_name}' has {in_features} input features.\")\n",
        "    else:\n",
        "        print(f\"\\nThe selected layer '{selected_layer_name}' does not have the 'in_features' attribute.\")\n",
        "else:\n",
        "    print(\"Invalid selection. Please select a number within the provided options.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtJ-I-aisdGc",
        "outputId": "e68ae4c6-6ebd-495e-8662-09a4ccd57f74"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Options for selecting the layer:\n",
            "1. conv1\n",
            "2. bn1\n",
            "3. act1\n",
            "4. maxpool\n",
            "5. layer1.0.conv1\n",
            "6. layer1.0.bn1\n",
            "7. layer1.0.act1\n",
            "8. layer1.0.conv2\n",
            "9. layer1.0.bn2\n",
            "10. layer1.0.drop_block\n",
            "11. layer1.0.act2\n",
            "12. layer1.0.aa\n",
            "13. layer1.0.conv3\n",
            "14. layer1.0.bn3\n",
            "15. layer1.0.act3\n",
            "16. layer1.0.downsample.0\n",
            "17. layer1.0.downsample.1\n",
            "18. layer1.1.conv1\n",
            "19. layer1.1.bn1\n",
            "20. layer1.1.act1\n",
            "21. layer1.1.conv2\n",
            "22. layer1.1.bn2\n",
            "23. layer1.1.drop_block\n",
            "24. layer1.1.act2\n",
            "25. layer1.1.aa\n",
            "26. layer1.1.conv3\n",
            "27. layer1.1.bn3\n",
            "28. layer1.1.act3\n",
            "29. layer1.2.conv1\n",
            "30. layer1.2.bn1\n",
            "31. layer1.2.act1\n",
            "32. layer1.2.conv2\n",
            "33. layer1.2.bn2\n",
            "34. layer1.2.drop_block\n",
            "35. layer1.2.act2\n",
            "36. layer1.2.aa\n",
            "37. layer1.2.conv3\n",
            "38. layer1.2.bn3\n",
            "39. layer1.2.act3\n",
            "40. layer2.0.conv1\n",
            "41. layer2.0.bn1\n",
            "42. layer2.0.act1\n",
            "43. layer2.0.conv2\n",
            "44. layer2.0.bn2\n",
            "45. layer2.0.drop_block\n",
            "46. layer2.0.act2\n",
            "47. layer2.0.aa\n",
            "48. layer2.0.conv3\n",
            "49. layer2.0.bn3\n",
            "50. layer2.0.act3\n",
            "51. layer2.0.downsample.0\n",
            "52. layer2.0.downsample.1\n",
            "53. layer2.1.conv1\n",
            "54. layer2.1.bn1\n",
            "55. layer2.1.act1\n",
            "56. layer2.1.conv2\n",
            "57. layer2.1.bn2\n",
            "58. layer2.1.drop_block\n",
            "59. layer2.1.act2\n",
            "60. layer2.1.aa\n",
            "61. layer2.1.conv3\n",
            "62. layer2.1.bn3\n",
            "63. layer2.1.act3\n",
            "64. layer2.2.conv1\n",
            "65. layer2.2.bn1\n",
            "66. layer2.2.act1\n",
            "67. layer2.2.conv2\n",
            "68. layer2.2.bn2\n",
            "69. layer2.2.drop_block\n",
            "70. layer2.2.act2\n",
            "71. layer2.2.aa\n",
            "72. layer2.2.conv3\n",
            "73. layer2.2.bn3\n",
            "74. layer2.2.act3\n",
            "75. layer2.3.conv1\n",
            "76. layer2.3.bn1\n",
            "77. layer2.3.act1\n",
            "78. layer2.3.conv2\n",
            "79. layer2.3.bn2\n",
            "80. layer2.3.drop_block\n",
            "81. layer2.3.act2\n",
            "82. layer2.3.aa\n",
            "83. layer2.3.conv3\n",
            "84. layer2.3.bn3\n",
            "85. layer2.3.act3\n",
            "86. layer3.0.conv1\n",
            "87. layer3.0.bn1\n",
            "88. layer3.0.act1\n",
            "89. layer3.0.conv2\n",
            "90. layer3.0.bn2\n",
            "91. layer3.0.drop_block\n",
            "92. layer3.0.act2\n",
            "93. layer3.0.aa\n",
            "94. layer3.0.conv3\n",
            "95. layer3.0.bn3\n",
            "96. layer3.0.act3\n",
            "97. layer3.0.downsample.0\n",
            "98. layer3.0.downsample.1\n",
            "99. layer3.1.conv1\n",
            "100. layer3.1.bn1\n",
            "101. layer3.1.act1\n",
            "102. layer3.1.conv2\n",
            "103. layer3.1.bn2\n",
            "104. layer3.1.drop_block\n",
            "105. layer3.1.act2\n",
            "106. layer3.1.aa\n",
            "107. layer3.1.conv3\n",
            "108. layer3.1.bn3\n",
            "109. layer3.1.act3\n",
            "110. layer3.2.conv1\n",
            "111. layer3.2.bn1\n",
            "112. layer3.2.act1\n",
            "113. layer3.2.conv2\n",
            "114. layer3.2.bn2\n",
            "115. layer3.2.drop_block\n",
            "116. layer3.2.act2\n",
            "117. layer3.2.aa\n",
            "118. layer3.2.conv3\n",
            "119. layer3.2.bn3\n",
            "120. layer3.2.act3\n",
            "121. layer3.3.conv1\n",
            "122. layer3.3.bn1\n",
            "123. layer3.3.act1\n",
            "124. layer3.3.conv2\n",
            "125. layer3.3.bn2\n",
            "126. layer3.3.drop_block\n",
            "127. layer3.3.act2\n",
            "128. layer3.3.aa\n",
            "129. layer3.3.conv3\n",
            "130. layer3.3.bn3\n",
            "131. layer3.3.act3\n",
            "132. layer3.4.conv1\n",
            "133. layer3.4.bn1\n",
            "134. layer3.4.act1\n",
            "135. layer3.4.conv2\n",
            "136. layer3.4.bn2\n",
            "137. layer3.4.drop_block\n",
            "138. layer3.4.act2\n",
            "139. layer3.4.aa\n",
            "140. layer3.4.conv3\n",
            "141. layer3.4.bn3\n",
            "142. layer3.4.act3\n",
            "143. layer3.5.conv1\n",
            "144. layer3.5.bn1\n",
            "145. layer3.5.act1\n",
            "146. layer3.5.conv2\n",
            "147. layer3.5.bn2\n",
            "148. layer3.5.drop_block\n",
            "149. layer3.5.act2\n",
            "150. layer3.5.aa\n",
            "151. layer3.5.conv3\n",
            "152. layer3.5.bn3\n",
            "153. layer3.5.act3\n",
            "154. layer4.0.conv1\n",
            "155. layer4.0.bn1\n",
            "156. layer4.0.act1\n",
            "157. layer4.0.conv2\n",
            "158. layer4.0.bn2\n",
            "159. layer4.0.drop_block\n",
            "160. layer4.0.act2\n",
            "161. layer4.0.aa\n",
            "162. layer4.0.conv3\n",
            "163. layer4.0.bn3\n",
            "164. layer4.0.act3\n",
            "165. layer4.0.downsample.0\n",
            "166. layer4.0.downsample.1\n",
            "167. layer4.1.conv1\n",
            "168. layer4.1.bn1\n",
            "169. layer4.1.act1\n",
            "170. layer4.1.conv2\n",
            "171. layer4.1.bn2\n",
            "172. layer4.1.drop_block\n",
            "173. layer4.1.act2\n",
            "174. layer4.1.aa\n",
            "175. layer4.1.conv3\n",
            "176. layer4.1.bn3\n",
            "177. layer4.1.act3\n",
            "178. layer4.2.conv1\n",
            "179. layer4.2.bn1\n",
            "180. layer4.2.act1\n",
            "181. layer4.2.conv2\n",
            "182. layer4.2.bn2\n",
            "183. layer4.2.drop_block\n",
            "184. layer4.2.act2\n",
            "185. layer4.2.aa\n",
            "186. layer4.2.conv3\n",
            "187. layer4.2.bn3\n",
            "188. layer4.2.act3\n",
            "189. global_pool.pool\n",
            "190. global_pool.flatten\n",
            "191. fc\n",
            "Enter the number corresponding to the layer you want to select: 76\n",
            "\n",
            "The selected layer 'layer2.3.bn1' does not have the 'in_features' attribute.\n"
          ]
        }
      ]
    }
  ]
}