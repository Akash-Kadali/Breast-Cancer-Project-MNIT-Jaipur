{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8146556,"sourceType":"datasetVersion","datasetId":4817492},{"sourceId":8158384,"sourceType":"datasetVersion","datasetId":4826407}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install \"tensorflow>=1.7.0\"\n!pip install tensorflow-addons\n!pip install tensorflow-hub\n!rm -rf /kaggle/working/*","metadata":{"id":"vq5qLS4d2LmQ","outputId":"0033907d-1402-4773-8e3d-47bc8c7de5ae","execution":{"iopub.status.busy":"2024-04-28T11:57:00.569193Z","iopub.execute_input":"2024-04-28T11:57:00.570132Z","iopub.status.idle":"2024-04-28T11:57:42.410558Z","shell.execute_reply.started":"2024-04-28T11:57:00.570089Z","shell.execute_reply":"2024-04-28T11:57:42.409271Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow>=1.7.0 in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.7.0) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow>=1.7.0)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=1.7.0) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow>=1.7.0) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.2.1\n    Uninstalling keras-3.2.1:\n      Successfully uninstalled keras-3.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\nCollecting tensorflow-addons\n  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (21.3)\nCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow-addons) (3.1.1)\nDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nInstalling collected packages: typeguard, tensorflow-addons\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.1.5\n    Uninstalling typeguard-4.1.5:\n      Successfully uninstalled typeguard-4.1.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires typeguard<5,>=4.1.2, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\nRequirement already satisfied: tensorflow-hub in /opt/conda/lib/python3.10/site-packages (0.16.1)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub) (1.26.4)\nRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub) (3.20.3)\nRequirement already satisfied: tf-keras>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub) (2.15.1)\nRequirement already satisfied: tensorflow<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (21.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, utils\nimport tensorflow_addons as tfa","metadata":{"id":"vmaszhvR2LmY","outputId":"14282fdc-1d84-42b2-c094-313fcfc5b121","scrolled":true,"execution":{"iopub.status.busy":"2024-04-28T11:57:42.412636Z","iopub.execute_input":"2024-04-28T11:57:42.412955Z","iopub.status.idle":"2024-04-28T11:57:54.738450Z","shell.execute_reply.started":"2024-04-28T11:57:42.412927Z","shell.execute_reply":"2024-04-28T11:57:54.737396Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-28 11:57:44.269504: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-28 11:57:44.269612: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-28 11:57:44.418234: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nprint(f\"tensorflow version: {tf.__version__}\")\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D\n\nimport matplotlib.pyplot as plt","metadata":{"id":"Ht481_PZ2LmZ","outputId":"893042a3-52cf-4948-f304-ee79b6924d47","execution":{"iopub.status.busy":"2024-04-28T11:57:54.739879Z","iopub.execute_input":"2024-04-28T11:57:54.740516Z","iopub.status.idle":"2024-04-28T11:57:54.746926Z","shell.execute_reply.started":"2024-04-28T11:57:54.740484Z","shell.execute_reply":"2024-04-28T11:57:54.745998Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"tensorflow version: 2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport math\nimport os\nimport statistics\nfrom keras import layers\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.preprocessing import image\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras.layers import Input, Dense, DepthwiseConv2D,AveragePooling2D, Concatenate, Dropout, Permute,Reshape,Lambda,Activation, Add,Multiply, MaxPooling2D, Conv2D, Flatten, BatchNormalization, GlobalAveragePooling2D,LayerNormalization\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16,ConvNeXtTiny,ResNet50, MobileNet, Xception, EfficientNetB0 , DenseNet169, DenseNet201, DenseNet121, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\nfrom tensorflow.keras.optimizers.legacy import Adam, SGD\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nfrom keras.models import Model\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport scipy\nimport gc\nimport itertools\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom functools import partial\nfrom collections import Counter\nfrom statistics import mean\n\nfrom keras.models import load_model\n#from keras.models import Sequential\nfrom matplotlib import pyplot as plt\nimport h5py\nimport cv2\nimport glob\n\n%matplotlib inline\n","metadata":{"id":"o91Tp0x_sHTl","execution":{"iopub.status.busy":"2024-04-28T11:57:54.749904Z","iopub.execute_input":"2024-04-28T11:57:54.750291Z","iopub.status.idle":"2024-04-28T11:57:55.354682Z","shell.execute_reply.started":"2024-04-28T11:57:54.750258Z","shell.execute_reply":"2024-04-28T11:57:55.353796Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.version.VERSION, tf.config.list_physical_devices()","metadata":{"id":"N-4YPF2w26ll","outputId":"f65040c0-109c-48ec-cb8f-a498425d1b19","execution":{"iopub.status.busy":"2024-04-28T11:57:55.355746Z","iopub.execute_input":"2024-04-28T11:57:55.356002Z","iopub.status.idle":"2024-04-28T11:57:55.545705Z","shell.execute_reply.started":"2024-04-28T11:57:55.355979Z","shell.execute_reply":"2024-04-28T11:57:55.544785Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"('2.15.0',\n [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"},"metadata":{}}]},{"cell_type":"code","source":"A = '/kaggle/input/iw-dataset2/IW/400/A'\nF = '/kaggle/input/iw-dataset2/IW/400/F'\nPT ='/kaggle/input/iw-dataset2/IW/400/PT'\nTA ='/kaggle/input/iw-dataset2/IW/400/TA'\nDC ='/kaggle/input/iw-dataset2/IW/400/DC'\nLC ='/kaggle/input/iw-dataset2/IW/400/LC'\nMC ='/kaggle/input/iw-dataset2/IW/400/MC'\nPC ='/kaggle/input/iw-dataset2/IW/400/PC'","metadata":{"id":"4EWX3Gd8r32a","execution":{"iopub.status.busy":"2024-04-28T11:57:55.546861Z","iopub.execute_input":"2024-04-28T11:57:55.547123Z","iopub.status.idle":"2024-04-28T11:57:55.556490Z","shell.execute_reply.started":"2024-04-28T11:57:55.547102Z","shell.execute_reply":"2024-04-28T11:57:55.555618Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dirlist=[A, F, PT, TA, DC, LC, MC, PC]\nclasses=['A','F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\nfilepaths=[]\nlabels=[]\nfor i,j in zip(dirlist, classes):\n    filelist=os.listdir(i)\n    for f in filelist:\n        filepath=os.path.join (i,f)\n        filepaths.append(filepath)\n        labels.append(j)\nprint ('filepaths: ', len(filepaths), '   labels: ', len(labels))","metadata":{"id":"QNZkBeucr9Mh","outputId":"c71d8c73-1307-4cf6-eaee-135e5329347b","execution":{"iopub.status.busy":"2024-04-28T11:57:55.557511Z","iopub.execute_input":"2024-04-28T11:57:55.557773Z","iopub.status.idle":"2024-04-28T11:57:56.054082Z","shell.execute_reply.started":"2024-04-28T11:57:55.557752Z","shell.execute_reply":"2024-04-28T11:57:56.053192Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"filepaths:  1820    labels:  1820\n","output_type":"stream"}]},{"cell_type":"code","source":"Files=pd.Series(filepaths, name='filepaths')\nLabel=pd.Series(labels, name='labels')\ndf=pd.concat([Files,Label], axis=1)\ndf=pd.DataFrame(np.array(df).reshape(len(filepaths),2), columns = ['filepaths', 'labels'])\ndf.head()","metadata":{"id":"QVgOHhygsAlZ","outputId":"e0d82af8-4980-4a33-835f-8f6f50f66169","execution":{"iopub.status.busy":"2024-04-28T11:57:56.055153Z","iopub.execute_input":"2024-04-28T11:57:56.055455Z","iopub.status.idle":"2024-04-28T11:57:56.075822Z","shell.execute_reply.started":"2024-04-28T11:57:56.055431Z","shell.execute_reply":"2024-04-28T11:57:56.074967Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                           filepaths labels\n0  /kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...      A\n1  /kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...      A\n2  /kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...      A\n3  /kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...      A\n4  /kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...      A","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepaths</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/iw-dataset2/IW/400/A/SOB_B_A-14-...</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df['labels'].value_counts())","metadata":{"id":"1uQkt3MTsD_o","outputId":"d78e99c3-8b2a-4e8b-d18f-3f1234fea612","execution":{"iopub.status.busy":"2024-04-28T11:57:56.077090Z","iopub.execute_input":"2024-04-28T11:57:56.077429Z","iopub.status.idle":"2024-04-28T11:57:56.090470Z","shell.execute_reply.started":"2024-04-28T11:57:56.077400Z","shell.execute_reply":"2024-04-28T11:57:56.089537Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"labels\nDC    788\nF     237\nMC    169\nPC    138\nLC    137\nTA    130\nPT    115\nA     106\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(df, train_size=0.70)\n#train_new, valid = train_test_split(train, train_size=0.90, random_state=0)\n\nprint(f\"train set shape: {train.shape}\")\nprint(f\"test set shape: {test.shape}\")\nprint(f\"validation set shape: {test.shape}\")","metadata":{"id":"pfI-lh99sGr7","outputId":"9e4ed814-a065-4487-9270-8057167fe944","execution":{"iopub.status.busy":"2024-04-28T11:57:56.094751Z","iopub.execute_input":"2024-04-28T11:57:56.095011Z","iopub.status.idle":"2024-04-28T11:57:56.102994Z","shell.execute_reply.started":"2024-04-28T11:57:56.094989Z","shell.execute_reply":"2024-04-28T11:57:56.102158Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"train set shape: (1274, 2)\ntest set shape: (546, 2)\nvalidation set shape: (546, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# train = '/content/drive/MyDrive/fold5/40/train'\n# test = '/content/drive/MyDrive/fold5/40/test'","metadata":{"id":"G5LJCbZ2IooS","execution":{"iopub.status.busy":"2024-04-28T11:57:56.104081Z","iopub.execute_input":"2024-04-28T11:57:56.104369Z","iopub.status.idle":"2024-04-28T11:57:56.111616Z","shell.execute_reply.started":"2024-04-28T11:57:56.104347Z","shell.execute_reply":"2024-04-28T11:57:56.110869Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,\n                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\ntest_datagen = ImageDataGenerator(rescale = 1.0/255.)","metadata":{"id":"BF_mNPBOsQPL","execution":{"iopub.status.busy":"2024-04-28T11:57:56.112591Z","iopub.execute_input":"2024-04-28T11:57:56.112897Z","iopub.status.idle":"2024-04-28T11:57:56.121410Z","shell.execute_reply.started":"2024-04-28T11:57:56.112874Z","shell.execute_reply":"2024-04-28T11:57:56.120554Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Define tand get the number os devices. \nstrategy = tf.distribute.MirroredStrategy()\nprint('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))\n\ntrain_gen = train_datagen.flow_from_dataframe(dataframe=train,\n                                              x_col = 'filepaths', y_col ='labels',\n                                              target_size = (224,224), batch_size = 4 * strategy.num_replicas_in_sync,\n                                              class_mode = 'categorical', shuffle = True)\n\nval_gen = test_datagen.flow_from_dataframe(test,\n                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n                                             class_mode = 'categorical',\n                                            batch_size = 4 * strategy.num_replicas_in_sync, shuffle = False)\n\n\ntest_gen = test_datagen.flow_from_dataframe(test,\n                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n                                             class_mode = 'categorical',\n                                            batch_size = 4, shuffle = False)","metadata":{"id":"4Gl5R4EJsRbN","outputId":"51427aaf-fe28-4df5-a2cf-765ad592e436","execution":{"iopub.status.busy":"2024-04-28T11:57:56.122442Z","iopub.execute_input":"2024-04-28T11:57:56.122668Z","iopub.status.idle":"2024-04-28T11:57:56.894359Z","shell.execute_reply.started":"2024-04-28T11:57:56.122648Z","shell.execute_reply":"2024-04-28T11:57:56.893582Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"DEVICES AVAILABLE: 1\nFound 1274 validated image filenames belonging to 8 classes.\nFound 546 validated image filenames belonging to 8 classes.\nFound 546 validated image filenames belonging to 8 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"def smooth_curve(points, factor=0.9):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points\n\ndef plotmodel(history,name):\n\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(acc) + 1)\n\n    plt.figure(1)\n    plt.plot(epochs,smooth_curve(acc))\n    plt.plot(epochs,smooth_curve(val_acc))\n    plt.ylabel('acc')\n    plt.xlabel('epoch')\n    plt.legend(['train_acc', 'val_acc'], loc='upper left')\n    #plt.savefig('acc_'+name+'_'+mag+'_'+fold+'.png')\n\n    plt.figure(2)\n    plt.plot(epochs,smooth_curve(loss))\n    plt.plot(epochs,smooth_curve(val_loss))\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train_loss', 'val_loss'], loc='upper right')\n   # plt.savefig('loss_'+name+'_'+mag+'_'+fold+'.png')\n\ndef label_smooth(y_true, y_pred):\n    y_true=((1-0.1)*y_true+0.05)\n    return K.categorical_crossentropy(y_true, y_pred)\n","metadata":{"id":"CJBdug_F2Lmc","execution":{"iopub.status.busy":"2024-04-28T11:57:56.895445Z","iopub.execute_input":"2024-04-28T11:57:56.895739Z","iopub.status.idle":"2024-04-28T11:57:56.905976Z","shell.execute_reply.started":"2024-04-28T11:57:56.895715Z","shell.execute_reply":"2024-04-28T11:57:56.905153Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    #plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 3.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"green\" if cm[i, j] > thresh else \"red\", fontdict={'fontsize':'x-large'})\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"id":"LeIVRsgY2Lmc","execution":{"iopub.status.busy":"2024-04-28T11:57:56.907107Z","iopub.execute_input":"2024-04-28T11:57:56.907817Z","iopub.status.idle":"2024-04-28T11:57:56.920643Z","shell.execute_reply.started":"2024-04-28T11:57:56.907786Z","shell.execute_reply":"2024-04-28T11:57:56.919777Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def DefConv_full(input, filters, kernel_size, strides=1):\n    \"\"\"\n    Using DefConv_reduced to implement full DC layer.\n    \"\"\"\n    offsets = layers.Conv2D(filters=2 * kernel_size ** 2,\n                            kernel_size=kernel_size,\n                            strides=strides,\n                            padding='same',\n                            kernel_initializer='random_normal'\n                            )(input)\n    X = DefConvLayer_red(filters=filters,\n                         kernel_size=kernel_size,\n                         strides=strides\n                         )(input, offsets)\n    return X\n\n\n\nclass DefConvLayer_red(Layer):\n\n    def __init__(self, filters,strides, kernel_size=3, **kwargs):\n        assert type(kernel_size) == int, \"expect kernel_size to be of type 'int'\"\n        assert type(strides) == int, \"expect strides to be of type int\"\n        self.N = kernel_size ** 2\n        self.filters = filters\n        self.strides = strides\n\n        super(DefConvLayer_red, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W = self.add_weight(shape=(input_shape[-1], self.N, self.filters),\n                                 # Wdc is of shape [n_C=input_channels, lxl=N, filters=output_channels]\n                                 initializer='RandomNormal',\n                                 dtype='float32',\n                                 trainable=True)\n\n    def call(self, input, offsets):\n        # input of shape: (m=batch_size, n_H, n_W, n_C)\n        # offsets of shape: (m, n_H, n_W, 2*N)\n        # m, n_H, n_W, n_C = input.shape\n        # offsets = super(DefConvLayer, self).call(input) # Conv2D to learn offsets (m, n_H, n_W, 2*N)\n\n        input_offsets = self.BLIN(input, offsets)  # (m, n_H, n_W, n_C, N)\n        # BLIN returns N interpolated values of input at the offsets, for each spatial pixel\n        # replicate the offset input to each of the output channels\n        input_offsets = tf.expand_dims(input_offsets, axis=-1)\n        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, 1, self.filters])  # (m, n_H, n_W, n_C, N, filters)\n\n        new_shape = (1, 1, 1,) + self.W.shape\n        W = tf.reshape(self.W, shape=new_shape)  # (1, 1, 1, n_C, N, filters) to be broadcastable to input_offsets\n\n        output = tf.multiply(input_offsets, W)  # (m, n_H, n_W, n_C, N, filters)\n        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, n_C, filters) reduce along each channel kernel\n        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, filters) reduce along input channels\n        return output\n\n    @tf.function\n    def BLIN(self, input, offsets_in):  # Bi-Linear Interpolation of input feature map values at offset locations\n        \"\"\"\n        'input' shape: (m, n_Hi, n_Wi, n_C)\n        'offsets_in' shape: (m, n_Ho, n_Wo, 2*N)\n        'offsets_in' is the output of the Conv2D layer step aimed at learning the offsets,\n                     possibly smaller spatial size than input's, if strides>1\n        \"\"\"\n        offsets = offsets_in\n        m    = tf.shape(input)[0]\n        n_Hi = tf.shape(input)[1]\n        n_Wi = tf.shape(input)[2]\n        n_C  = tf.shape(input)[3]\n\n        n_Ho = tf.shape(offsets)[1] # also the output spatial shape\n        n_Wo = tf.shape(offsets)[2]\n        N    = tf.shape(offsets)[3] // 2\n\n        # expand the input into (m, n_Hi, n_Wi, n_C, N). this will also be the output shape of this function\n        input_offsets = tf.expand_dims(input, axis=-1) # (m, n_Hi, n_Wi, n_C, N, 1)\n        # replicate N times, to be compatible with the kernel operation later\n        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, N])  # (m, n_Hi, n_Wi, n_C, N)\n\n        # the offset metrices will be replicated n_C times: same (spatial) offsets for each of the input *channels*.\n        offsets = tf.reshape(offsets, (m, n_Ho, n_Wo, 1, N, 2))  # (m, n_Ho, n_Wo, 1, N, 2) add a \"channel\" axis\n        offsets = tf.tile(offsets, [1, 1, 1, n_C, 1, 1])  # (m, n_Ho, n_Wo, n_C, N, 2) replicate for each of the input channels\n\n        # construct a full index grid to be applied onto \"input_offsets\" of size (m, n_H, n_W, n_C, N)\n        (grid_m, grid_i, grid_j, grid_c, grid_N) = tf.meshgrid(tf.range(m), tf.range(n_Hi),\n                                                               tf.range(n_Wi), tf.range(n_C), tf.range(N),\n                                                               indexing='ij')  # (m, n_Hi, n_Wi, n_C, N) a list of 5 metrices with index-like values\n\n        # adjust indices to 'strides' down-sample, and\n        # unroll indices to fit into tf.gather_nd later. (unroll offsets also)\n        ur_grid_m = tf.reshape(grid_m[:, ::self.strides, ::self.strides, :, :], [-1])  # (m*n_Ho*n_Wo*n_C*N, 1); integers\n        ur_grid_i = tf.reshape(grid_i[:, ::self.strides, ::self.strides, :, :], [-1])\n        ur_grid_j = tf.reshape(grid_j[:, ::self.strides, ::self.strides, :, :], [-1])\n        ur_grid_c = tf.reshape(grid_c[:, ::self.strides, ::self.strides, :, :], [-1])\n        ur_grid_N = tf.reshape(grid_N[:, ::self.strides, ::self.strides, :, :], [-1])\n        ur_offsets = tf.reshape(offsets, (-1, 2))  # (m*n_Ho*n_Wo*n_C*N, 2) both i, j\n\n        # spatial indices will be adjusted using 'offsets'\n        coords_i = tf.cast(ur_grid_i, dtype='float32') + ur_offsets[..., 0]\n        coords_j = tf.cast(ur_grid_j, dtype='float32') + ur_offsets[..., 1]\n\n        # Need to think further on how to handle edges,\n        # perhaps assume outside of index values can be zeros instead of hard-clipping.\n        coords_i = tf.clip_by_value(coords_i, 0, tf.cast(n_Hi, dtype='float32')-1)\n        coords_j = tf.clip_by_value(coords_j, 0, tf.cast(n_Wi, dtype='float32')-1)\n        coords_2d = tf.stack([coords_i, coords_j], axis=-1)  # (m*n_Ho*n_Wo*n_C*N, 2); float32\n\n        # generate top and bottom, left and right, nearest \"real\" indices\n        # assuming coords represents (p,q) values where i<=p<=i+1, and j<=q<=j+1:\n        # shape: (m*n_Ho*n_Wo*n_C*N, 2)\n        # note the coordinates themselves (values in coords) are [i,j] within [0:n_Hi-1, 0:n_Wi] range\n        coords_lt = tf.cast(tf.math.floor(coords_2d), dtype='int32')  # nearest (i,j)\n        coords_rb = tf.cast(tf.math.ceil(coords_2d), dtype='int32')  # nearest (i+1, j+1)\n\n        coords_lb = tf.stack((coords_rb[..., 0], coords_lt[..., 1]), axis=-1)  # nearest (i+1, j)\n        coords_rt = tf.stack((coords_lt[..., 0], coords_rb[..., 1]), axis=-1)  # nearest (i, j+1)\n\n        # use the replicated input tensor \"input_offsets\" which holds the input values, to get these values at the specific locations:\n        # these type of Tensors doesn't allow for conversion into numpy-like arrays. to use tf.gather_nd, need to unroll indices\n        # unroll all grid tensors to be used with tf.gather_nd()\n\n        indices_lt = tf.stack([ur_grid_m, coords_lt[..., 0], coords_lt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n        indices_rb = tf.stack([ur_grid_m, coords_rb[..., 0], coords_rb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n        indices_lb = tf.stack([ur_grid_m, coords_lb[..., 0], coords_lb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n        indices_rt = tf.stack([ur_grid_m, coords_rt[..., 0], coords_rt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n\n        vals_lt = tf.gather_nd(input_offsets, indices_lt)\n        vals_rb = tf.gather_nd(input_offsets, indices_rb)\n        vals_lb = tf.gather_nd(input_offsets, indices_lb)\n        vals_rt = tf.gather_nd(input_offsets, indices_rt)\n\n        # calculate the offset from the left-top (i,j) position\n        ur_coords_offset_lt = coords_2d - tf.cast(coords_lt, dtype='float32')  # (m*n_Ho*n_Wo*n_C*N, 2)\n\n        # first linear interpolation (m*n_H*n_W*n_C*N)\n        vals_t = vals_lt + (vals_rt - vals_lt) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), top\n        vals_b = vals_lb + (vals_rb - vals_lb) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), bottom\n\n        # second linear interpolation\n        input_offsets = vals_t + (vals_b - vals_t) * ur_coords_offset_lt[..., 0]  # along the i axis (n_Hi)\n\n        # reshape back to output shape\n        input_offsets = tf.reshape(input_offsets, (m, n_Ho, n_Wo, n_C, N))\n\n        return input_offsets","metadata":{"id":"hwUptDC7WJHS","execution":{"iopub.status.busy":"2024-04-28T11:57:56.922039Z","iopub.execute_input":"2024-04-28T11:57:56.922365Z","iopub.status.idle":"2024-04-28T11:57:56.952582Z","shell.execute_reply.started":"2024-04-28T11:57:56.922341Z","shell.execute_reply":"2024-04-28T11:57:56.951751Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n    \ndef train_model(model,train_gen,val_gen,test_gen,mag,image_size,save_name,lr1,lr2,Epochs1,Epochs2):\n\n    lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n    save_model = ModelCheckpoint('/kaggle/working/400_+{epoch:02d}.h5', \n                             monitor='val_acc', \n                             period=1, \n                             save_best_only=True)\n\n#     from keras.models import load_model\n\n#     # List of model names\n#     model_names = ['10+36.h5', '10+66.h5', '10+56.h5', '10+26.h5', '10+86.h5', '10+46.h5', '10+06.h5']\n#     parallel_model\n    # List to store loaded models\n#     loaded_models = []\n\n#     # Load models in a loop\n#     for model_name in model_names:\n#         # Construct the full path to the model file\n#         model_path = '/kaggle/working/' + model_name\n\n#         # Load the model and append it to the list\n#         loaded_models.append(load_model(model_path))\n\n    # Now loaded_models list contains all the loaded models\n\n\n    for layer in new_base_model.layers:\n        layer.trainable = False\n\n    model.compile(optimizer=Adam(lr=1e-5,decay=1e-6),loss=loss_fun,metrics=['acc'])\n    model.fit_generator(train_gen,\n                        #steps_per_epoch=train_num/batch_size,\n                        validation_data=val_gen,\n                        #validation_steps=test_num/batch_size,\n                        epochs=Epochs1,\n                        workers=8,\n                        callbacks=[lr_decay,save_model])\n\n    for layer in new_base_model.layers:\n        layer.trainable = True\n\n    model.compile(optimizer=Adam(lr=lr2,decay=0.00001),loss=loss_fun,metrics=['acc'])\n    history = model.fit_generator(train_gen,\n                        #steps_per_epoch=train_num/batch_size,\n                        validation_data=val_gen,\n                        #validation_steps=test_num/batch_size,\n                        epochs=Epochs2,\n                        workers=8,\n                        callbacks=[lr_decay,save_model])\n    \n    results =model.evaluate(test_gen)\n    print('Test loss and accuracy: ',results)\n    predictions = model.predict(test_gen)\n    rounded_pred = np.argmax(predictions, axis=-1)\n    cm = confusion_matrix(y_true=test_gen.classes, y_pred=rounded_pred)\n    cm_plot_labels = ['A','F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n    plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n    print(classification_report(y_true=test_gen.classes, y_pred=rounded_pred, target_names=cm_plot_labels))\n\n    return history","metadata":{"id":"mDj2Er1H2Lmf","execution":{"iopub.status.busy":"2024-04-28T11:57:56.954111Z","iopub.execute_input":"2024-04-28T11:57:56.954464Z","iopub.status.idle":"2024-04-28T11:57:56.968901Z","shell.execute_reply.started":"2024-04-28T11:57:56.954434Z","shell.execute_reply":"2024-04-28T11:57:56.968038Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"!pip install -U git+https://github.com/leondgarse/keras_cv_attention_models","metadata":{"id":"COIWAnOotVGZ","outputId":"bf509f2c-e46d-42f7-fad3-8a915138c162","execution":{"iopub.status.busy":"2024-04-28T11:57:56.969836Z","iopub.execute_input":"2024-04-28T11:57:56.970068Z","iopub.status.idle":"2024-04-28T11:58:13.949145Z","shell.execute_reply.started":"2024-04-28T11:57:56.970048Z","shell.execute_reply":"2024-04-28T11:58:13.947988Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/leondgarse/keras_cv_attention_models\n  Cloning https://github.com/leondgarse/keras_cv_attention_models to /tmp/pip-req-build-hys57kal\n  Running command git clone --filter=blob:none --quiet https://github.com/leondgarse/keras_cv_attention_models /tmp/pip-req-build-hys57kal\n  Resolved https://github.com/leondgarse/keras_cv_attention_models to commit 4e9156520cfd700bb78d491983e39160647f6b19\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from keras-cv-attention-models==1.4.2) (9.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from keras-cv-attention-models==1.4.2) (4.66.1)\nCollecting ftfy (from keras-cv-attention-models==1.4.2)\n  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras-cv-attention-models==1.4.2) (2023.12.25)\nRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from keras-cv-attention-models==1.4.2) (4.9.4)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (from keras-cv-attention-models==1.4.2) (2.15.0)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->keras-cv-attention-models==1.4.2) (0.2.13)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (8.1.7)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.1.8)\nRequirement already satisfied: etils>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.6.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (5.9.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.31.0)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.14.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.10.2)\nRequirement already satisfied: array-record>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.5.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow->keras-cv-attention-models==1.4.2) (0.42.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2024.2.0)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (6.1.1)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2024.2.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow->keras-cv-attention-models==1.4.2) (3.1.1)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.62.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.2.2)\nDownloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: keras-cv-attention-models\n  Building wheel for keras-cv-attention-models (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-cv-attention-models: filename=keras_cv_attention_models-1.4.2-py3-none-any.whl size=933481 sha256=5b2409d24853e14c2b47fc7418f1089a5215351720bedfc0943abf18a2decae6\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ghwyllgk/wheels/16/98/1e/847241ad48bd552bd921ea08001f22a1ecab471036f6b09bb4\nSuccessfully built keras-cv-attention-models\nInstalling collected packages: ftfy, keras-cv-attention-models\nSuccessfully installed ftfy-6.2.0 keras-cv-attention-models-1.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras_cv_attention_models import maxvit\nmm = maxvit.MaxViT_Tiny(input_shape=(224, 224, 3), pretrained=\"imagenet\")\n# mm.summary()","metadata":{"id":"fLq_Narsto20","outputId":"df026039-e032-47fa-97ed-19946e5cb4e6","execution":{"iopub.status.busy":"2024-04-28T11:58:13.950918Z","iopub.execute_input":"2024-04-28T11:58:13.951328Z","iopub.status.idle":"2024-04-28T11:58:22.509634Z","shell.execute_reply.started":"2024-04-28T11:58:13.951292Z","shell.execute_reply":"2024-04-28T11:58:22.508858Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/leondgarse/keras_cv_attention_models/releases/download/maxvit/maxvit_tiny_224_imagenet.h5\n126113280/126113280 [==============================] - 0s 0us/step\n>>>> Load pretrained from: /root/.keras/models/maxvit_tiny_224_imagenet.h5\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras.backend as K\ndef SSA(inputs,fltr):\n    shape=K.int_shape(inputs)\n    li=q=k=v=Conv2D(fltr,1,padding='same',activation='relu')(inputs)\n    print(\"Shape of Input of SSA\", inputs)\n    Qshape=K.int_shape(q)\n    Kshape= K.int_shape(k)\n    Vshape= K.int_shape(v)\n    a=Qshape[1]*Qshape[2]\n    q=Reshape((a,Qshape[3]))(q)\n    k=Reshape((a,Kshape[3]))(k)\n    k=Permute((2,1))(k)\n    qk=tf.matmul(q,k)\n    qk=Activation('softmax')(qk)\n    v=Reshape((a,Vshape[3]))(v)\n    qkv=tf.matmul(qk,v)\n    print(qkv.shape)\n    qkv=Reshape((Vshape[1],Vshape[2],Vshape[3]))(qkv)\n    qkv = Conv2D(shape[3], 1, strides=1, padding='same', activation='relu')(qkv)\n    print(\"Shape of Output of SSA\", qkv)\n    return qkv","metadata":{"id":"gfdo3wQDgQWF","execution":{"iopub.status.busy":"2024-04-28T11:58:22.510925Z","iopub.execute_input":"2024-04-28T11:58:22.511518Z","iopub.status.idle":"2024-04-28T11:58:22.520618Z","shell.execute_reply.started":"2024-04-28T11:58:22.511474Z","shell.execute_reply":"2024-04-28T11:58:22.519817Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Conv2D, Add, LayerNormalization\n\ndef CDSA(input, fltr, nh):\n    attn = []\n    print(\"Shape of CDSA Input\", input.shape)\n    feature_split = tf.split(input, num_or_size_splits=nh, axis=3)  # Changed num_splits to nh\n    print(feature_split[0].shape)\n    x = SSA(feature_split[0], fltr)  # Assuming SSA is defined elsewhere\n    attn.append(x)\n    for i in range(1, nh):\n        y = SSA(feature_split[i], fltr)  # Assuming SSA is defined elsewhere\n        attn.append(y)\n    mh_lka_attn = Add()(attn)\n    mh_lka_attn = Conv2D(fltr, 1, strides=1, padding='same', activation='relu')(mh_lka_attn)\n    print(\"Shape of CDSA Output\", mh_lka_attn.shape)\n    return mh_lka_attn","metadata":{"id":"NVDzywSVfVX_","execution":{"iopub.status.busy":"2024-04-28T11:58:22.521681Z","iopub.execute_input":"2024-04-28T11:58:22.521934Z","iopub.status.idle":"2024-04-28T11:58:22.571492Z","shell.execute_reply.started":"2024-04-28T11:58:22.521911Z","shell.execute_reply":"2024-04-28T11:58:22.570524Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def CAL(input,fltr,nh):\n    print(\"Shape of CAL Input\", input.shape)\n    x = DefConv_full(input, fltr, kernel_size=3)\n    rs1 = x = Add()([x,input])\n    x = LayerNormalization(epsilon=1e-6)(x)\n    x = CDSA(x,fltr,nh)\n    rs2 = x = Add()([rs1,x])\n    x = LayerNormalization(epsilon=1e-6)(x)\n    x = Conv2D(fltr, 1, padding='same', activation='relu')(x)\n    x = Add()([rs2,x])\n    print(\"Shape of CAL Output\", x.shape)\n    return x","metadata":{"id":"PKnsju-la_cg","execution":{"iopub.status.busy":"2024-04-28T11:58:22.572778Z","iopub.execute_input":"2024-04-28T11:58:22.573523Z","iopub.status.idle":"2024-04-28T11:58:22.582680Z","shell.execute_reply.started":"2024-04-28T11:58:22.573486Z","shell.execute_reply":"2024-04-28T11:58:22.581838Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"loss_fun= 'categorical_crossentropy'\ngpu_num=2\nk=5\nlr1=0.005\nlr2=0.0001\nimage_size=224\nclasses=8\nratio=8\nfltr=256\nnh=16 # number of splits\nmag='40'","metadata":{"id":"uQqoWozCTBhK","execution":{"iopub.status.busy":"2024-04-28T11:58:22.583757Z","iopub.execute_input":"2024-04-28T11:58:22.584834Z","iopub.status.idle":"2024-04-28T11:58:22.592825Z","shell.execute_reply.started":"2024-04-28T11:58:22.584801Z","shell.execute_reply":"2024-04-28T11:58:22.592009Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import BatchNormalization, Dropout\n\ninput_image = Input(shape=(224, 224, 3))\nmn_input = input_image\n\n# Load the model\nbase_model = maxvit.MaxViT_Tiny(input_shape=(224, 224, 3), pretrained=\"imagenet\")\nnew_base_model = Model(inputs=base_model.input, outputs=base_model.get_layer('stack_3_block_5/grid_ffn_output').output)\nmn_output = new_base_model(mn_input)\nprint(mn_output.shape)\n\nmn_output = Conv2D(fltr, 1, padding='same', activation='relu')(mn_output)\nprint(mn_output.shape)\nmn_output = BatchNormalization()(mn_output)  # Add Batch Normalization\nmn_output = Dropout(0.5)(mn_output)\nnum_splits = 16\nCAL_out = CAL(mn_output,fltr,nh)\nprint(CAL_out.shape)\nCAL_out = GlobalAveragePooling2D()(CAL_out)\nout=Dense(classes,activation='softmax')(CAL_out)\nif gpu_num<1:\n    model=Model(inputs=input_image, outputs=out)\n    #model.summary()\n    parallel_model = multi_gpu_model(model, gpus=gpu_num)\n    parallel_model.summary()\nelse:\n    parallel_model=Model(inputs=input_image, outputs=out)\n    parallel_model.summary()","metadata":{"id":"i--5bFDwR9fx","outputId":"c17c8b05-23d9-4cb6-a988-fbddf33a48fa","execution":{"iopub.status.busy":"2024-04-28T11:58:22.593989Z","iopub.execute_input":"2024-04-28T11:58:22.594258Z","iopub.status.idle":"2024-04-28T11:58:35.249897Z","shell.execute_reply.started":"2024-04-28T11:58:22.594236Z","shell.execute_reply":"2024-04-28T11:58:35.248973Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":">>>> Load pretrained from: /root/.keras/models/maxvit_tiny_224_imagenet.h5\n(None, 14, 14, 256)\n(None, 14, 14, 256)\nShape of CAL Input (None, 14, 14, 256)\nShape of CDSA Input (None, 14, 14, 256)\n(None, 14, 14, 16)\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:0', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_3/Relu:0', description=\"created by layer 'conv2d_3'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:1', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_5/Relu:0', description=\"created by layer 'conv2d_5'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:2', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_7/Relu:0', description=\"created by layer 'conv2d_7'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:3', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_9/Relu:0', description=\"created by layer 'conv2d_9'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:4', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_11/Relu:0', description=\"created by layer 'conv2d_11'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:5', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_13/Relu:0', description=\"created by layer 'conv2d_13'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:6', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_15/Relu:0', description=\"created by layer 'conv2d_15'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:7', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_17/Relu:0', description=\"created by layer 'conv2d_17'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:8', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_19/Relu:0', description=\"created by layer 'conv2d_19'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:9', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_21/Relu:0', description=\"created by layer 'conv2d_21'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:10', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_23/Relu:0', description=\"created by layer 'conv2d_23'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:11', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_25/Relu:0', description=\"created by layer 'conv2d_25'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:12', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_27/Relu:0', description=\"created by layer 'conv2d_27'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:13', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_29/Relu:0', description=\"created by layer 'conv2d_29'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:14', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_31/Relu:0', description=\"created by layer 'conv2d_31'\")\nShape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='tf.split_44/split:15', description=\"created by layer 'tf.split_44'\")\n(None, 196, 256)\nShape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d_33/Relu:0', description=\"created by layer 'conv2d_33'\")\nShape of CDSA Output (None, 14, 14, 256)\nShape of CAL Output (None, 14, 14, 256)\n(None, 14, 14, 256)\nModel: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n                                                                                                  \n model (Functional)          (None, 14, 14, 256)          1263885   ['input_2[0][0]']             \n                                                          6                                       \n                                                                                                  \n conv2d (Conv2D)             (None, 14, 14, 256)          65792     ['model[0][0]']               \n                                                                                                  \n batch_normalization (Batch  (None, 14, 14, 256)          1024      ['conv2d[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n dropout (Dropout)           (None, 14, 14, 256)          0         ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 14, 14, 18)           41490     ['dropout[0][0]']             \n                                                                                                  \n def_conv_layer_red (DefCon  (None, 14, 14, 256)          589824    ['dropout[0][0]',             \n vLayer_red)                                                         'conv2d_1[0][0]']            \n                                                                                                  \n add (Add)                   (None, 14, 14, 256)          0         ['def_conv_layer_red[0][0]',  \n                                                                     'dropout[0][0]']             \n                                                                                                  \n layer_normalization (Layer  (None, 14, 14, 256)          512       ['add[0][0]']                 \n Normalization)                                                                                   \n                                                                                                  \n tf.split_44 (TFOpLambda)    [(None, 14, 14, 16),         0         ['layer_normalization[0][0]'] \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16),                                                 \n                              (None, 14, 14, 16)]                                                 \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 14, 14, 256)          4352      ['tf.split_44[0][0]']         \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 14, 14, 256)          4352      ['tf.split_44[0][1]']         \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 14, 14, 256)          4352      ['tf.split_44[0][2]']         \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 14, 14, 256)          4352      ['tf.split_44[0][3]']         \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][4]']         \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][5]']         \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][6]']         \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][7]']         \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][8]']         \n                                                                                                  \n conv2d_20 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][9]']         \n                                                                                                  \n conv2d_22 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][10]']        \n                                                                                                  \n conv2d_24 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][11]']        \n                                                                                                  \n conv2d_26 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][12]']        \n                                                                                                  \n conv2d_28 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][13]']        \n                                                                                                  \n conv2d_30 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][14]']        \n                                                                                                  \n conv2d_32 (Conv2D)          (None, 14, 14, 256)          4352      ['tf.split_44[0][15]']        \n                                                                                                  \n reshape_133 (Reshape)       (None, 196, 256)             0         ['conv2d_2[0][0]']            \n                                                                                                  \n reshape_137 (Reshape)       (None, 196, 256)             0         ['conv2d_4[0][0]']            \n                                                                                                  \n reshape_141 (Reshape)       (None, 196, 256)             0         ['conv2d_6[0][0]']            \n                                                                                                  \n reshape_145 (Reshape)       (None, 196, 256)             0         ['conv2d_8[0][0]']            \n                                                                                                  \n reshape_149 (Reshape)       (None, 196, 256)             0         ['conv2d_10[0][0]']           \n                                                                                                  \n reshape_153 (Reshape)       (None, 196, 256)             0         ['conv2d_12[0][0]']           \n                                                                                                  \n reshape_157 (Reshape)       (None, 196, 256)             0         ['conv2d_14[0][0]']           \n                                                                                                  \n reshape_161 (Reshape)       (None, 196, 256)             0         ['conv2d_16[0][0]']           \n                                                                                                  \n reshape_165 (Reshape)       (None, 196, 256)             0         ['conv2d_18[0][0]']           \n                                                                                                  \n reshape_169 (Reshape)       (None, 196, 256)             0         ['conv2d_20[0][0]']           \n                                                                                                  \n reshape_173 (Reshape)       (None, 196, 256)             0         ['conv2d_22[0][0]']           \n                                                                                                  \n reshape_177 (Reshape)       (None, 196, 256)             0         ['conv2d_24[0][0]']           \n                                                                                                  \n reshape_181 (Reshape)       (None, 196, 256)             0         ['conv2d_26[0][0]']           \n                                                                                                  \n reshape_185 (Reshape)       (None, 196, 256)             0         ['conv2d_28[0][0]']           \n                                                                                                  \n reshape_189 (Reshape)       (None, 196, 256)             0         ['conv2d_30[0][0]']           \n                                                                                                  \n reshape_193 (Reshape)       (None, 196, 256)             0         ['conv2d_32[0][0]']           \n                                                                                                  \n reshape_132 (Reshape)       (None, 196, 256)             0         ['conv2d_2[0][0]']            \n                                                                                                  \n permute (Permute)           (None, 256, 196)             0         ['reshape_133[0][0]']         \n                                                                                                  \n reshape_136 (Reshape)       (None, 196, 256)             0         ['conv2d_4[0][0]']            \n                                                                                                  \n permute_1 (Permute)         (None, 256, 196)             0         ['reshape_137[0][0]']         \n                                                                                                  \n reshape_140 (Reshape)       (None, 196, 256)             0         ['conv2d_6[0][0]']            \n                                                                                                  \n permute_2 (Permute)         (None, 256, 196)             0         ['reshape_141[0][0]']         \n                                                                                                  \n reshape_144 (Reshape)       (None, 196, 256)             0         ['conv2d_8[0][0]']            \n                                                                                                  \n permute_3 (Permute)         (None, 256, 196)             0         ['reshape_145[0][0]']         \n                                                                                                  \n reshape_148 (Reshape)       (None, 196, 256)             0         ['conv2d_10[0][0]']           \n                                                                                                  \n permute_4 (Permute)         (None, 256, 196)             0         ['reshape_149[0][0]']         \n                                                                                                  \n reshape_152 (Reshape)       (None, 196, 256)             0         ['conv2d_12[0][0]']           \n                                                                                                  \n permute_5 (Permute)         (None, 256, 196)             0         ['reshape_153[0][0]']         \n                                                                                                  \n reshape_156 (Reshape)       (None, 196, 256)             0         ['conv2d_14[0][0]']           \n                                                                                                  \n permute_6 (Permute)         (None, 256, 196)             0         ['reshape_157[0][0]']         \n                                                                                                  \n reshape_160 (Reshape)       (None, 196, 256)             0         ['conv2d_16[0][0]']           \n                                                                                                  \n permute_7 (Permute)         (None, 256, 196)             0         ['reshape_161[0][0]']         \n                                                                                                  \n reshape_164 (Reshape)       (None, 196, 256)             0         ['conv2d_18[0][0]']           \n                                                                                                  \n permute_8 (Permute)         (None, 256, 196)             0         ['reshape_165[0][0]']         \n                                                                                                  \n reshape_168 (Reshape)       (None, 196, 256)             0         ['conv2d_20[0][0]']           \n                                                                                                  \n permute_9 (Permute)         (None, 256, 196)             0         ['reshape_169[0][0]']         \n                                                                                                  \n reshape_172 (Reshape)       (None, 196, 256)             0         ['conv2d_22[0][0]']           \n                                                                                                  \n permute_10 (Permute)        (None, 256, 196)             0         ['reshape_173[0][0]']         \n                                                                                                  \n reshape_176 (Reshape)       (None, 196, 256)             0         ['conv2d_24[0][0]']           \n                                                                                                  \n permute_11 (Permute)        (None, 256, 196)             0         ['reshape_177[0][0]']         \n                                                                                                  \n reshape_180 (Reshape)       (None, 196, 256)             0         ['conv2d_26[0][0]']           \n                                                                                                  \n permute_12 (Permute)        (None, 256, 196)             0         ['reshape_181[0][0]']         \n                                                                                                  \n reshape_184 (Reshape)       (None, 196, 256)             0         ['conv2d_28[0][0]']           \n                                                                                                  \n permute_13 (Permute)        (None, 256, 196)             0         ['reshape_185[0][0]']         \n reshape_184 (Reshape)       (None, 196, 256)             0         ['conv2d_28[0][0]']           \n                                                                                                  \n permute_13 (Permute)        (None, 256, 196)             0         ['reshape_185[0][0]']         \n                                                                                                  \n reshape_188 (Reshape)       (None, 196, 256)             0         ['conv2d_30[0][0]']           \n                                                                                                  \n permute_14 (Permute)        (None, 256, 196)             0         ['reshape_189[0][0]']         \n                                                                                                  \n reshape_192 (Reshape)       (None, 196, 256)             0         ['conv2d_32[0][0]']           \n                                                                                                  \n permute_15 (Permute)        (None, 256, 196)             0         ['reshape_193[0][0]']         \n                                                                                                  \n tf.linalg.matmul_88 (TFOpL  (None, 196, 196)             0         ['reshape_132[0][0]',         \n ambda)                                                              'permute[0][0]']             \n                                                                                                  \n tf.linalg.matmul_90 (TFOpL  (None, 196, 196)             0         ['reshape_136[0][0]',         \n ambda)                                                              'permute_1[0][0]']           \n                                                                                                  \n tf.linalg.matmul_92 (TFOpL  (None, 196, 196)             0         ['reshape_140[0][0]',         \n ambda)                                                              'permute_2[0][0]']           \n                                                                                                  \n tf.linalg.matmul_94 (TFOpL  (None, 196, 196)             0         ['reshape_144[0][0]',         \n ambda)                                                              'permute_3[0][0]']           \n                                                                                                  \n tf.linalg.matmul_96 (TFOpL  (None, 196, 196)             0         ['reshape_148[0][0]',         \n ambda)                                                              'permute_4[0][0]']           \n                                                                                                  \n tf.linalg.matmul_98 (TFOpL  (None, 196, 196)             0         ['reshape_152[0][0]',         \n ambda)                                                              'permute_5[0][0]']           \n                                                                                                  \n tf.linalg.matmul_100 (TFOp  (None, 196, 196)             0         ['reshape_156[0][0]',         \n Lambda)                                                             'permute_6[0][0]']           \n                                                                                                  \n tf.linalg.matmul_102 (TFOp  (None, 196, 196)             0         ['reshape_160[0][0]',         \n Lambda)                                                             'permute_7[0][0]']           \n                                                                                                  \n tf.linalg.matmul_104 (TFOp  (None, 196, 196)             0         ['reshape_164[0][0]',         \n Lambda)                                                             'permute_8[0][0]']           \n                                                                                                  \n tf.linalg.matmul_106 (TFOp  (None, 196, 196)             0         ['reshape_168[0][0]',         \n Lambda)                                                             'permute_9[0][0]']           \n                                                                                                  \n tf.linalg.matmul_108 (TFOp  (None, 196, 196)             0         ['reshape_172[0][0]',         \n Lambda)                                                             'permute_10[0][0]']          \n                                                                                                  \n tf.linalg.matmul_110 (TFOp  (None, 196, 196)             0         ['reshape_176[0][0]',         \n Lambda)                                                             'permute_11[0][0]']          \n                                                                                                  \n tf.linalg.matmul_112 (TFOp  (None, 196, 196)             0         ['reshape_180[0][0]',         \n Lambda)                                                             'permute_12[0][0]']          \n                                                                                                  \n tf.linalg.matmul_114 (TFOp  (None, 196, 196)             0         ['reshape_184[0][0]',         \n Lambda)                                                             'permute_13[0][0]']          \n                                                                                                  \n tf.linalg.matmul_116 (TFOp  (None, 196, 196)             0         ['reshape_188[0][0]',         \n Lambda)                                                             'permute_14[0][0]']          \n                                                                                                  \n tf.linalg.matmul_118 (TFOp  (None, 196, 196)             0         ['reshape_192[0][0]',         \n Lambda)                                                             'permute_15[0][0]']          \n                                                                                                  \n activation (Activation)     (None, 196, 196)             0         ['tf.linalg.matmul_88[0][0]'] \n                                                                                                  \n reshape_134 (Reshape)       (None, 196, 256)             0         ['conv2d_2[0][0]']            \n                                                                                                  \n activation_1 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_90[0][0]'] \n                                                                                                  \n reshape_138 (Reshape)       (None, 196, 256)             0         ['conv2d_4[0][0]']            \n                                                                                                  \n activation_2 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_92[0][0]'] \n                                                                                                  \n reshape_142 (Reshape)       (None, 196, 256)             0         ['conv2d_6[0][0]']            \n                                                                                                  \n activation_3 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_94[0][0]'] \n                                                                                                  \n reshape_146 (Reshape)       (None, 196, 256)             0         ['conv2d_8[0][0]']            \n                                                                                                  \n activation_4 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_96[0][0]'] \n                                                                                                  \n reshape_150 (Reshape)       (None, 196, 256)             0         ['conv2d_10[0][0]']           \n                                                                                                  \n activation_5 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_98[0][0]'] \n                                                                                                  \n reshape_154 (Reshape)       (None, 196, 256)             0         ['conv2d_12[0][0]']           \n                                                                                                  \n activation_6 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_100[0][0]']\n                                                                                                  \n reshape_158 (Reshape)       (None, 196, 256)             0         ['conv2d_14[0][0]']           \n                                                                                                  \n activation_7 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_102[0][0]']\n                                                                                                  \n reshape_162 (Reshape)       (None, 196, 256)             0         ['conv2d_16[0][0]']           \n                                                                                                  \n activation_8 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_104[0][0]']\n                                                                                                  \n reshape_166 (Reshape)       (None, 196, 256)             0         ['conv2d_18[0][0]']           \n                                                                                                  \n activation_9 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_106[0][0]']\n                                                                                                  \n reshape_170 (Reshape)       (None, 196, 256)             0         ['conv2d_20[0][0]']           \n                                                                                                  \n activation_10 (Activation)  (None, 196, 196)             0         ['tf.linalg.matmul_108[0][0]']\n                                                                                                  \n reshape_174 (Reshape)       (None, 196, 256)             0         ['conv2d_22[0][0]']           \n                                                                                                  \n activation_11 (Activation)  (None, 196, 196)             0         ['tf.linalg.matmul_110[0][0]']\n                                                                                                  \n reshape_178 (Reshape)       (None, 196, 256)             0         ['conv2d_24[0][0]']           \n                                                                                                  \n activation_12 (Activation)  (None, 196, 196)             0         ['tf.linalg.matmul_112[0][0]']\n                                                                                                  \n reshape_182 (Reshape)       (None, 196, 256)             0         ['conv2d_26[0][0]']           \n                                                                                                  \n activation_13 (Activation)  (None, 196, 196)             0         ['tf.linalg.matmul_114[0][0]']\n                                                                                                  \n reshape_186 (Reshape)       (None, 196, 256)             0         ['conv2d_28[0][0]']           \n                                                                                                  \n activation_14 (Activation)  (None, 196, 196)             0         ['tf.linalg.matmul_116[0][0]']\n                                                                                                  \n reshape_190 (Reshape)       (None, 196, 256)             0         ['conv2d_30[0][0]']           \n                                                                                                  \n activation_15 (Activation)  (None, 196, 196)             0         ['tf.linalg.matmul_118[0][0]']\n                                                                                                  \n reshape_194 (Reshape)       (None, 196, 256)             0         ['conv2d_32[0][0]']           \n                                                                                                  \n tf.linalg.matmul_89 (TFOpL  (None, 196, 256)             0         ['activation[0][0]',          \n ambda)                                                              'reshape_134[0][0]']         \n                                                                                                  \n tf.linalg.matmul_91 (TFOpL  (None, 196, 256)             0         ['activation_1[0][0]',        \n ambda)                                                              'reshape_138[0][0]']         \n                                                                                                  \n tf.linalg.matmul_93 (TFOpL  (None, 196, 256)             0         ['activation_2[0][0]',        \n ambda)                                                              'reshape_142[0][0]']         \n                                                                                                  \n tf.linalg.matmul_95 (TFOpL  (None, 196, 256)             0         ['activation_3[0][0]',        \n ambda)                                                              'reshape_146[0][0]']         \n                                                                                                  \n tf.linalg.matmul_97 (TFOpL  (None, 196, 256)             0         ['activation_4[0][0]',        \n ambda)                                                              'reshape_150[0][0]']         \n                                                                                                  \n tf.linalg.matmul_99 (TFOpL  (None, 196, 256)             0         ['activation_5[0][0]',        \n ambda)                                                              'reshape_154[0][0]']         \n                                                                                                  \n tf.linalg.matmul_101 (TFOp  (None, 196, 256)             0         ['activation_6[0][0]',        \n Lambda)                                                             'reshape_158[0][0]']         \n                                                                                                  \n tf.linalg.matmul_103 (TFOp  (None, 196, 256)             0         ['activation_7[0][0]',        \n Lambda)                                                             'reshape_162[0][0]']         \n                                                                                                  \n tf.linalg.matmul_105 (TFOp  (None, 196, 256)             0         ['activation_8[0][0]',        \n Lambda)                                                             'reshape_166[0][0]']         \n                                                                                                  \n tf.linalg.matmul_107 (TFOp  (None, 196, 256)             0         ['activation_9[0][0]',        \n Lambda)                                                             'reshape_170[0][0]']         \n                                                                                                  \n tf.linalg.matmul_109 (TFOp  (None, 196, 256)             0         ['activation_10[0][0]',       \n Lambda)                                                             'reshape_174[0][0]']         \n                                                                                                  \n tf.linalg.matmul_111 (TFOp  (None, 196, 256)             0         ['activation_11[0][0]',       \n Lambda)                                                             'reshape_178[0][0]']         \n                                                                                                  \n tf.linalg.matmul_113 (TFOp  (None, 196, 256)             0         ['activation_12[0][0]',       \n Lambda)                                                             'reshape_182[0][0]']         \n                                                                                                  \n tf.linalg.matmul_115 (TFOp  (None, 196, 256)             0         ['activation_13[0][0]',       \n Lambda)                                                             'reshape_186[0][0]']         \n                                                                                                  \n tf.linalg.matmul_117 (TFOp  (None, 196, 256)             0         ['activation_14[0][0]',       \n Lambda)                                                             'reshape_190[0][0]']         \n                                                                                                  \n tf.linalg.matmul_119 (TFOp  (None, 196, 256)             0         ['activation_15[0][0]',       \n Lambda)                                                             'reshape_194[0][0]']         \n                                                                                                  \n reshape_135 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_89[0][0]'] \n                                                                                                  \n reshape_139 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_91[0][0]'] \n                                                                                                  \n reshape_143 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_93[0][0]'] \n                                                                                                  \n reshape_147 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_95[0][0]'] \n                                                                                                  \n reshape_151 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_97[0][0]'] \n                                                                                                  \n reshape_155 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_99[0][0]'] \n                                                                                                  \n reshape_159 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_101[0][0]']\n                                                                                                  \n reshape_163 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_103[0][0]']\n                                                                                                  \n reshape_167 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_105[0][0]']\n                                                                                                  \n reshape_171 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_107[0][0]']\n                                                                                                  \n reshape_175 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_109[0][0]']\n                                                                                                  \n reshape_179 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_111[0][0]']\n                                                                                                  \n reshape_183 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_113[0][0]']\n                                                                                                  \n reshape_187 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_115[0][0]']\n                                                                                                  \n reshape_191 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_117[0][0]']\n                                                                                                  \n reshape_195 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_119[0][0]']\n                                                                                                  \n conv2d_3 (Conv2D)           (None, 14, 14, 16)           4112      ['reshape_135[0][0]']         \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 14, 14, 16)           4112      ['reshape_139[0][0]']         \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 14, 14, 16)           4112      ['reshape_143[0][0]']         \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 14, 14, 16)           4112      ['reshape_147[0][0]']         \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_151[0][0]']         \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_155[0][0]']         \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_159[0][0]']         \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_163[0][0]']         \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_167[0][0]']         \n                                                                                                  \n conv2d_21 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_171[0][0]']         \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_175[0][0]']         \n                                                                                                  \n conv2d_25 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_179[0][0]']         \n                                                                                                  \n conv2d_27 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_183[0][0]']         \n                                                                                                  \n conv2d_29 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_187[0][0]']         \n                                                                                                  \n conv2d_31 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_191[0][0]']         \n                                                                                                  \n conv2d_33 (Conv2D)          (None, 14, 14, 16)           4112      ['reshape_195[0][0]']         \n                                                                                                  \n add_1 (Add)                 (None, 14, 14, 16)           0         ['conv2d_3[0][0]',            \n                                                                     'conv2d_5[0][0]',            \n                                                                     'conv2d_7[0][0]',            \n                                                                     'conv2d_9[0][0]',            \n                                                                     'conv2d_11[0][0]',           \n                                                                     'conv2d_13[0][0]',           \n                                                                     'conv2d_15[0][0]',           \n                                                                     'conv2d_17[0][0]',           \n                                                                     'conv2d_19[0][0]',           \n                                                                     'conv2d_21[0][0]',           \n                                                                     'conv2d_23[0][0]',           \n                                                                     'conv2d_25[0][0]',           \n                                                                     'conv2d_27[0][0]',           \n                                                                     'conv2d_29[0][0]',           \n                                                                     'conv2d_31[0][0]',           \n                                                                     'conv2d_33[0][0]']           \n                                                                                                  \n conv2d_34 (Conv2D)          (None, 14, 14, 256)          4352      ['add_1[0][0]']               \n                                                                                                  \n add_2 (Add)                 (None, 14, 14, 256)          0         ['add[0][0]',                 \n                                                                     'conv2d_34[0][0]']           \n                                                                                                  \n layer_normalization_1 (Lay  (None, 14, 14, 256)          512       ['add_2[0][0]']               \n erNormalization)                                                                                 \n                                                                                                  \n conv2d_35 (Conv2D)          (None, 14, 14, 256)          65792     ['layer_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n add_3 (Add)                 (None, 14, 14, 256)          0         ['add_2[0][0]',               \n                                                                     'conv2d_35[0][0]']           \n                                                                                                  \n global_average_pooling2d (  (None, 256)                  0         ['add_3[0][0]']               \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n dense (Dense)               (None, 8)                    2056      ['global_average_pooling2d[0][\n                                                                    0]']                          \n                                                                                                  \n==================================================================================================\nTotal params: 13545634 (51.67 MB)\nTrainable params: 13515426 (51.56 MB)\nNon-trainable params: 30208 (118.00 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = train_model(parallel_model,train_gen,val_gen,test_gen,mag,image_size,'maxvit',lr1,lr2,4,100)","metadata":{"id":"_6LvLQM-S6Vp","outputId":"fe68a266-09f2-43cb-9b81-00430f4e0e02","execution":{"iopub.status.busy":"2024-04-28T11:58:35.251078Z","iopub.execute_input":"2024-04-28T11:58:35.251379Z","iopub.status.idle":"2024-04-28T16:35:46.406913Z","shell.execute_reply.started":"2024-04-28T11:58:35.251353Z","shell.execute_reply":"2024-04-28T16:35:46.406219Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n/tmp/ipykernel_34/653529243.py:34: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(train_gen,\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/4\n","output_type":"stream"},{"name":"stderr","text":"2024-04-28 11:58:59.945933: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"319/319 [==============================] - ETA: 0s - loss: 2.2992 - acc: 0.2622","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"319/319 [==============================] - 175s 450ms/step - loss: 2.2992 - acc: 0.2622 - val_loss: 1.7358 - val_acc: 0.4176 - lr: 1.0000e-05\nEpoch 2/4\n319/319 [==============================] - 134s 418ms/step - loss: 1.8123 - acc: 0.4050 - val_loss: 1.6266 - val_acc: 0.4341 - lr: 1.0000e-05\nEpoch 3/4\n319/319 [==============================] - 134s 418ms/step - loss: 1.7266 - acc: 0.4082 - val_loss: 1.5721 - val_acc: 0.4725 - lr: 1.0000e-05\nEpoch 4/4\n319/319 [==============================] - 135s 421ms/step - loss: 1.6675 - acc: 0.4349 - val_loss: 1.5129 - val_acc: 0.4780 - lr: 1.0000e-05\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/653529243.py:46: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  history = model.fit_generator(train_gen,\n2024-04-28 12:08:43.275756: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"319/319 [==============================] - 204s 529ms/step - loss: 1.5140 - acc: 0.4819 - val_loss: 1.3616 - val_acc: 0.5330 - lr: 1.0000e-04\nEpoch 2/100\n319/319 [==============================] - 161s 503ms/step - loss: 1.2305 - acc: 0.5675 - val_loss: 1.8472 - val_acc: 0.3681 - lr: 1.0000e-04\nEpoch 3/100\n319/319 [==============================] - 157s 490ms/step - loss: 1.0963 - acc: 0.6240 - val_loss: 0.7540 - val_acc: 0.7198 - lr: 1.0000e-04\nEpoch 4/100\n319/319 [==============================] - 154s 483ms/step - loss: 1.0382 - acc: 0.6287 - val_loss: 0.9454 - val_acc: 0.7015 - lr: 1.0000e-04\nEpoch 5/100\n319/319 [==============================] - 161s 505ms/step - loss: 0.9743 - acc: 0.6484 - val_loss: 0.9751 - val_acc: 0.6557 - lr: 1.0000e-04\nEpoch 6/100\n319/319 [==============================] - 155s 484ms/step - loss: 0.9689 - acc: 0.6695 - val_loss: 0.8494 - val_acc: 0.7161 - lr: 1.0000e-04\nEpoch 7/100\n319/319 [==============================] - 156s 489ms/step - loss: 0.9342 - acc: 0.6743 - val_loss: 0.6925 - val_acc: 0.7674 - lr: 1.0000e-04\nEpoch 8/100\n319/319 [==============================] - 162s 506ms/step - loss: 0.8629 - acc: 0.7135 - val_loss: 2.3411 - val_acc: 0.5311 - lr: 1.0000e-04\nEpoch 9/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.8645 - acc: 0.6954 - val_loss: 1.2847 - val_acc: 0.6575 - lr: 1.0000e-04\nEpoch 10/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.8233 - acc: 0.6954 - val_loss: 0.7747 - val_acc: 0.7491 - lr: 1.0000e-04\nEpoch 11/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.6933 - acc: 0.7465 - val_loss: 1.0074 - val_acc: 0.6813 - lr: 1.0000e-04\nEpoch 12/100\n319/319 [==============================] - 156s 489ms/step - loss: 0.6994 - acc: 0.7645 - val_loss: 0.7533 - val_acc: 0.7802 - lr: 1.0000e-04\nEpoch 13/100\n319/319 [==============================] - 157s 490ms/step - loss: 0.7186 - acc: 0.7527 - val_loss: 0.5139 - val_acc: 0.8278 - lr: 1.0000e-04\nEpoch 14/100\n319/319 [==============================] - 156s 489ms/step - loss: 0.6731 - acc: 0.7637 - val_loss: 0.5715 - val_acc: 0.8004 - lr: 1.0000e-04\nEpoch 15/100\n319/319 [==============================] - 156s 488ms/step - loss: 0.6248 - acc: 0.7755 - val_loss: 0.7257 - val_acc: 0.7692 - lr: 1.0000e-04\nEpoch 16/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.6114 - acc: 0.7849 - val_loss: 0.8759 - val_acc: 0.7564 - lr: 1.0000e-04\nEpoch 17/100\n319/319 [==============================] - 156s 487ms/step - loss: 0.5203 - acc: 0.8226 - val_loss: 0.6557 - val_acc: 0.7912 - lr: 1.0000e-04\nEpoch 18/100\n319/319 [==============================] - 161s 504ms/step - loss: 0.5695 - acc: 0.8038 - val_loss: 0.7637 - val_acc: 0.8022 - lr: 1.0000e-04\nEpoch 19/100\n319/319 [==============================] - 162s 506ms/step - loss: 0.5745 - acc: 0.8100 - val_loss: 0.8601 - val_acc: 0.7784 - lr: 1.0000e-04\nEpoch 20/100\n319/319 [==============================] - 156s 489ms/step - loss: 0.4750 - acc: 0.8281 - val_loss: 0.5445 - val_acc: 0.8462 - lr: 1.0000e-04\nEpoch 21/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.4899 - acc: 0.8352 - val_loss: 0.6862 - val_acc: 0.8095 - lr: 1.0000e-04\nEpoch 22/100\n319/319 [==============================] - 162s 507ms/step - loss: 0.4345 - acc: 0.8524 - val_loss: 0.4963 - val_acc: 0.8333 - lr: 1.0000e-04\nEpoch 23/100\n319/319 [==============================] - 155s 486ms/step - loss: 0.4296 - acc: 0.8469 - val_loss: 0.7414 - val_acc: 0.8260 - lr: 1.0000e-04\nEpoch 24/100\n319/319 [==============================] - 156s 489ms/step - loss: 0.4169 - acc: 0.8595 - val_loss: 0.4717 - val_acc: 0.8553 - lr: 1.0000e-04\nEpoch 25/100\n319/319 [==============================] - 155s 483ms/step - loss: 0.4486 - acc: 0.8477 - val_loss: 0.7933 - val_acc: 0.7747 - lr: 1.0000e-04\nEpoch 26/100\n319/319 [==============================] - 156s 489ms/step - loss: 0.4142 - acc: 0.8564 - val_loss: 0.4534 - val_acc: 0.8626 - lr: 1.0000e-04\nEpoch 27/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.3849 - acc: 0.8697 - val_loss: 0.6617 - val_acc: 0.8297 - lr: 1.0000e-04\nEpoch 28/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.3565 - acc: 0.8846 - val_loss: 0.5976 - val_acc: 0.8535 - lr: 1.0000e-04\nEpoch 29/100\n319/319 [==============================] - 156s 489ms/step - loss: 0.3497 - acc: 0.8830 - val_loss: 0.4159 - val_acc: 0.8718 - lr: 1.0000e-04\nEpoch 30/100\n319/319 [==============================] - 162s 506ms/step - loss: 0.3077 - acc: 0.8878 - val_loss: 0.7712 - val_acc: 0.8004 - lr: 1.0000e-04\nEpoch 31/100\n319/319 [==============================] - 162s 506ms/step - loss: 0.3289 - acc: 0.8878 - val_loss: 0.6700 - val_acc: 0.8187 - lr: 1.0000e-04\nEpoch 32/100\n319/319 [==============================] - 157s 490ms/step - loss: 0.3152 - acc: 0.8901 - val_loss: 0.4676 - val_acc: 0.8755 - lr: 1.0000e-04\nEpoch 33/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.2937 - acc: 0.8956 - val_loss: 0.4602 - val_acc: 0.8571 - lr: 1.0000e-04\nEpoch 34/100\n319/319 [==============================] - 162s 506ms/step - loss: 0.2581 - acc: 0.9160 - val_loss: 0.5464 - val_acc: 0.8590 - lr: 1.0000e-04\nEpoch 35/100\n319/319 [==============================] - 162s 506ms/step - loss: 0.3054 - acc: 0.8893 - val_loss: 0.4077 - val_acc: 0.8736 - lr: 1.0000e-04\nEpoch 36/100\n319/319 [==============================] - 154s 483ms/step - loss: 0.2168 - acc: 0.9199 - val_loss: 0.9936 - val_acc: 0.7747 - lr: 1.0000e-04\nEpoch 37/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.2383 - acc: 0.9215 - val_loss: 0.4978 - val_acc: 0.8553 - lr: 1.0000e-04\nEpoch 38/100\n319/319 [==============================] - 154s 481ms/step - loss: 0.2149 - acc: 0.9192 - val_loss: 0.7915 - val_acc: 0.7692 - lr: 1.0000e-04\nEpoch 39/100\n319/319 [==============================] - 157s 490ms/step - loss: 0.2339 - acc: 0.9215 - val_loss: 0.5460 - val_acc: 0.8333 - lr: 1.0000e-04\nEpoch 40/100\n319/319 [==============================] - 155s 484ms/step - loss: 0.2247 - acc: 0.9246 - val_loss: 0.3941 - val_acc: 0.8608 - lr: 1.0000e-04\nEpoch 41/100\n319/319 [==============================] - 155s 484ms/step - loss: 0.2015 - acc: 0.9349 - val_loss: 1.1959 - val_acc: 0.6996 - lr: 1.0000e-04\nEpoch 42/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.2265 - acc: 0.9192 - val_loss: 0.7244 - val_acc: 0.8114 - lr: 1.0000e-04\nEpoch 43/100\n319/319 [==============================] - 154s 483ms/step - loss: 0.2109 - acc: 0.9286 - val_loss: 0.4037 - val_acc: 0.8645 - lr: 1.0000e-04\nEpoch 44/100\n319/319 [==============================] - 163s 509ms/step - loss: 0.1875 - acc: 0.9372 - val_loss: 0.3182 - val_acc: 0.8956 - lr: 1.0000e-04\nEpoch 45/100\n319/319 [==============================] - 155s 484ms/step - loss: 0.1771 - acc: 0.9364 - val_loss: 0.4594 - val_acc: 0.8828 - lr: 1.0000e-04\nEpoch 46/100\n319/319 [==============================] - 155s 484ms/step - loss: 0.2114 - acc: 0.9270 - val_loss: 0.3453 - val_acc: 0.8864 - lr: 1.0000e-04\nEpoch 47/100\n319/319 [==============================] - 154s 483ms/step - loss: 0.1644 - acc: 0.9356 - val_loss: 0.4222 - val_acc: 0.8956 - lr: 1.0000e-04\nEpoch 48/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.1132 - acc: 0.9592 - val_loss: 0.4039 - val_acc: 0.8810 - lr: 1.0000e-04\nEpoch 49/100\n319/319 [==============================] - 154s 483ms/step - loss: 0.1959 - acc: 0.9372 - val_loss: 0.4381 - val_acc: 0.8608 - lr: 1.0000e-04\nEpoch 50/100\n319/319 [==============================] - 155s 483ms/step - loss: 0.1485 - acc: 0.9411 - val_loss: 0.3986 - val_acc: 0.8919 - lr: 1.0000e-04\nEpoch 51/100\n319/319 [==============================] - ETA: 0s - loss: 0.1712 - acc: 0.9451\nEpoch 51: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n319/319 [==============================] - 161s 503ms/step - loss: 0.1712 - acc: 0.9451 - val_loss: 0.6088 - val_acc: 0.8315 - lr: 1.0000e-04\nEpoch 52/100\n319/319 [==============================] - 161s 504ms/step - loss: 0.1414 - acc: 0.9513 - val_loss: 0.5786 - val_acc: 0.8370 - lr: 8.0000e-05\nEpoch 53/100\n319/319 [==============================] - 155s 486ms/step - loss: 0.1330 - acc: 0.9427 - val_loss: 0.3405 - val_acc: 0.9011 - lr: 8.0000e-05\nEpoch 54/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.0732 - acc: 0.9710 - val_loss: 0.4109 - val_acc: 0.8516 - lr: 8.0000e-05\nEpoch 55/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.0870 - acc: 0.9694 - val_loss: 0.4953 - val_acc: 0.8846 - lr: 8.0000e-05\nEpoch 56/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.1461 - acc: 0.9466 - val_loss: 0.5361 - val_acc: 0.8645 - lr: 8.0000e-05\nEpoch 57/100\n319/319 [==============================] - ETA: 0s - loss: 0.0934 - acc: 0.9662\nEpoch 57: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n319/319 [==============================] - 156s 488ms/step - loss: 0.0934 - acc: 0.9662 - val_loss: 0.3546 - val_acc: 0.9048 - lr: 8.0000e-05\nEpoch 58/100\n319/319 [==============================] - 154s 483ms/step - loss: 0.1002 - acc: 0.9662 - val_loss: 0.4443 - val_acc: 0.8810 - lr: 6.4000e-05\nEpoch 59/100\n319/319 [==============================] - 156s 488ms/step - loss: 0.0932 - acc: 0.9623 - val_loss: 0.4077 - val_acc: 0.8846 - lr: 6.4000e-05\nEpoch 60/100\n319/319 [==============================] - 155s 484ms/step - loss: 0.0731 - acc: 0.9741 - val_loss: 0.3730 - val_acc: 0.9011 - lr: 6.4000e-05\nEpoch 61/100\n319/319 [==============================] - 155s 484ms/step - loss: 0.0564 - acc: 0.9757 - val_loss: 0.3866 - val_acc: 0.9011 - lr: 6.4000e-05\nEpoch 62/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.0853 - acc: 0.9678 - val_loss: 0.4277 - val_acc: 0.9011 - lr: 6.4000e-05\nEpoch 63/100\n319/319 [==============================] - 156s 488ms/step - loss: 0.0947 - acc: 0.9623 - val_loss: 0.3986 - val_acc: 0.9121 - lr: 6.4000e-05\nEpoch 64/100\n319/319 [==============================] - ETA: 0s - loss: 0.0928 - acc: 0.9686\nEpoch 64: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n319/319 [==============================] - 155s 484ms/step - loss: 0.0928 - acc: 0.9686 - val_loss: 0.7323 - val_acc: 0.8480 - lr: 6.4000e-05\nEpoch 65/100\n319/319 [==============================] - 161s 505ms/step - loss: 0.0717 - acc: 0.9757 - val_loss: 0.3776 - val_acc: 0.9103 - lr: 5.1200e-05\nEpoch 66/100\n319/319 [==============================] - 161s 505ms/step - loss: 0.0567 - acc: 0.9765 - val_loss: 0.3188 - val_acc: 0.9084 - lr: 5.1200e-05\nEpoch 67/100\n319/319 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.9710\nEpoch 67: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n319/319 [==============================] - 154s 483ms/step - loss: 0.0606 - acc: 0.9710 - val_loss: 0.3240 - val_acc: 0.9048 - lr: 5.1200e-05\nEpoch 68/100\n319/319 [==============================] - 161s 503ms/step - loss: 0.0440 - acc: 0.9843 - val_loss: 0.3391 - val_acc: 0.9029 - lr: 4.0960e-05\nEpoch 69/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.0453 - acc: 0.9812 - val_loss: 0.3164 - val_acc: 0.9176 - lr: 4.0960e-05\nEpoch 70/100\n319/319 [==============================] - 161s 503ms/step - loss: 0.0495 - acc: 0.9819 - val_loss: 0.4165 - val_acc: 0.9066 - lr: 4.0960e-05\nEpoch 71/100\n319/319 [==============================] - 154s 481ms/step - loss: 0.0401 - acc: 0.9843 - val_loss: 0.3417 - val_acc: 0.9011 - lr: 4.0960e-05\nEpoch 72/100\n319/319 [==============================] - 161s 503ms/step - loss: 0.0326 - acc: 0.9898 - val_loss: 0.3544 - val_acc: 0.9084 - lr: 4.0960e-05\nEpoch 73/100\n319/319 [==============================] - 161s 503ms/step - loss: 0.0280 - acc: 0.9890 - val_loss: 0.3300 - val_acc: 0.9176 - lr: 4.0960e-05\nEpoch 74/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.0502 - acc: 0.9796 - val_loss: 0.3851 - val_acc: 0.9011 - lr: 4.0960e-05\nEpoch 75/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.0697 - acc: 0.9765 - val_loss: 0.3573 - val_acc: 0.8974 - lr: 4.0960e-05\nEpoch 76/100\n319/319 [==============================] - ETA: 0s - loss: 0.0420 - acc: 0.9835\nEpoch 76: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n319/319 [==============================] - 161s 503ms/step - loss: 0.0420 - acc: 0.9835 - val_loss: 0.4215 - val_acc: 0.8919 - lr: 4.0960e-05\nEpoch 77/100\n319/319 [==============================] - 155s 483ms/step - loss: 0.0330 - acc: 0.9851 - val_loss: 0.3096 - val_acc: 0.9011 - lr: 3.2768e-05\nEpoch 78/100\n319/319 [==============================] - 156s 488ms/step - loss: 0.0326 - acc: 0.9867 - val_loss: 0.3236 - val_acc: 0.8938 - lr: 3.2768e-05\nEpoch 79/100\n319/319 [==============================] - 156s 488ms/step - loss: 0.0255 - acc: 0.9882 - val_loss: 0.3385 - val_acc: 0.8993 - lr: 3.2768e-05\nEpoch 80/100\n319/319 [==============================] - 156s 488ms/step - loss: 0.0258 - acc: 0.9882 - val_loss: 0.3447 - val_acc: 0.9103 - lr: 3.2768e-05\nEpoch 81/100\n319/319 [==============================] - 163s 509ms/step - loss: 0.0418 - acc: 0.9827 - val_loss: 0.3597 - val_acc: 0.9084 - lr: 3.2768e-05\nEpoch 82/100\n319/319 [==============================] - ETA: 0s - loss: 0.0399 - acc: 0.9819\nEpoch 82: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n319/319 [==============================] - 155s 484ms/step - loss: 0.0399 - acc: 0.9819 - val_loss: 0.3448 - val_acc: 0.9084 - lr: 3.2768e-05\nEpoch 83/100\n319/319 [==============================] - 157s 490ms/step - loss: 0.0221 - acc: 0.9906 - val_loss: 0.3288 - val_acc: 0.9212 - lr: 2.6214e-05\nEpoch 84/100\n319/319 [==============================] - 154s 480ms/step - loss: 0.0293 - acc: 0.9874 - val_loss: 0.3508 - val_acc: 0.9194 - lr: 2.6214e-05\nEpoch 85/100\n319/319 [==============================] - 154s 482ms/step - loss: 0.0447 - acc: 0.9835 - val_loss: 0.3721 - val_acc: 0.8956 - lr: 2.6214e-05\nEpoch 86/100\n319/319 [==============================] - ETA: 0s - loss: 0.0243 - acc: 0.9867\nEpoch 86: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n319/319 [==============================] - 154s 482ms/step - loss: 0.0243 - acc: 0.9867 - val_loss: 0.3050 - val_acc: 0.9158 - lr: 2.6214e-05\nEpoch 87/100\n319/319 [==============================] - 153s 479ms/step - loss: 0.0220 - acc: 0.9906 - val_loss: 0.3415 - val_acc: 0.9084 - lr: 2.0972e-05\nEpoch 88/100\n319/319 [==============================] - 154s 480ms/step - loss: 0.0371 - acc: 0.9851 - val_loss: 0.3882 - val_acc: 0.9011 - lr: 2.0972e-05\nEpoch 89/100\n319/319 [==============================] - ETA: 0s - loss: 0.0317 - acc: 0.9843\nEpoch 89: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n319/319 [==============================] - 153s 479ms/step - loss: 0.0317 - acc: 0.9843 - val_loss: 0.3269 - val_acc: 0.9084 - lr: 2.0972e-05\nEpoch 90/100\n319/319 [==============================] - 153s 480ms/step - loss: 0.0181 - acc: 0.9922 - val_loss: 0.3310 - val_acc: 0.9121 - lr: 1.6777e-05\nEpoch 91/100\n319/319 [==============================] - 161s 504ms/step - loss: 0.0207 - acc: 0.9867 - val_loss: 0.3294 - val_acc: 0.9212 - lr: 1.6777e-05\nEpoch 92/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.0140 - acc: 0.9937 - val_loss: 0.3459 - val_acc: 0.9139 - lr: 1.6777e-05\nEpoch 93/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.0138 - acc: 0.9953 - val_loss: 0.4917 - val_acc: 0.9103 - lr: 1.6777e-05\nEpoch 94/100\n319/319 [==============================] - 155s 484ms/step - loss: 0.0193 - acc: 0.9914 - val_loss: 0.3464 - val_acc: 0.9139 - lr: 1.6777e-05\nEpoch 95/100\n319/319 [==============================] - 162s 505ms/step - loss: 0.0335 - acc: 0.9874 - val_loss: 0.4150 - val_acc: 0.9048 - lr: 1.6777e-05\nEpoch 96/100\n319/319 [==============================] - ETA: 0s - loss: 0.0232 - acc: 0.9867\nEpoch 96: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n319/319 [==============================] - 155s 483ms/step - loss: 0.0232 - acc: 0.9867 - val_loss: 0.4091 - val_acc: 0.9066 - lr: 1.6777e-05\nEpoch 97/100\n319/319 [==============================] - 155s 485ms/step - loss: 0.0183 - acc: 0.9898 - val_loss: 0.4241 - val_acc: 0.9048 - lr: 1.3422e-05\nEpoch 98/100\n319/319 [==============================] - 155s 484ms/step - loss: 0.0200 - acc: 0.9890 - val_loss: 0.3747 - val_acc: 0.9084 - lr: 1.3422e-05\nEpoch 99/100\n319/319 [==============================] - ETA: 0s - loss: 0.0271 - acc: 0.9882\nEpoch 99: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n319/319 [==============================] - 157s 491ms/step - loss: 0.0271 - acc: 0.9882 - val_loss: 0.3751 - val_acc: 0.9029 - lr: 1.3422e-05\nEpoch 100/100\n319/319 [==============================] - 154s 483ms/step - loss: 0.0183 - acc: 0.9906 - val_loss: 0.3716 - val_acc: 0.9121 - lr: 1.0737e-05\n137/137 [==============================] - 35s 251ms/step - loss: 0.3716 - acc: 0.9121\nTest loss and accuracy:  [0.37160229682922363, 0.9120879173278809]\n137/137 [==============================] - 40s 247ms/step\nConfusion matrix, without normalization\n[[ 34   0   0   0   2   0   0   0]\n [  0 230   1   9   3   2   0   0]\n [  0   0  80   0   0   0   0   1]\n [  0  11   0  18   2   0   0   0]\n [  0   4   0   0  48   1   0   2]\n [  0   0   1   0   0  32   0   0]\n [  3   0   6   0   0   0  27   0]\n [  0   0   0   0   0   0   0  29]]\n              precision    recall  f1-score   support\n\n           A       0.92      0.94      0.93        36\n           F       0.94      0.94      0.94       245\n          PT       0.91      0.99      0.95        81\n          TA       0.67      0.58      0.62        31\n          DC       0.87      0.87      0.87        55\n          LC       0.91      0.97      0.94        33\n          MC       1.00      0.75      0.86        36\n          PC       0.91      1.00      0.95        29\n\n    accuracy                           0.91       546\n   macro avg       0.89      0.88      0.88       546\nweighted avg       0.91      0.91      0.91       546\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAc8AAAHpCAYAAADkjbcAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABy9ElEQVR4nO3deXhM598G8PvMTGay70hCJIgsSqlu9q2EopRWtbRE0bcLWmptf4i9VbW2qFZRpVpVFK2itlpqKWIPYl9DyCKRSWbO8/4RGSKLnJg17s915SLnPDPn+zjH3Gd9RhJCCBAREVGxqWxdABERkaNheBIRESnE8CQiIlKI4UlERKQQw5OIiEghhicREZFCDE8iIiKFGJ5EREQKMTyJiIgUYngSWdnJkycRHR0NLy8vSJKEFStWmPX9z549C0mSMH/+fLO+ryNr0qQJmjRpYusyqBRheNJjKSEhAf/3f/+HypUrw9nZGZ6enqhfvz6mTZuGO3fuWHTZ3bt3x6FDhzBu3DgsXLgQzzzzjEWXZ00xMTGQJAmenp4F/juePHkSkiRBkiRMmjRJ8ftfvnwZsbGxOHDggBmqJSo5ja0LILK2NWvWoFOnTtDpdOjWrRuqV6+OrKwsbNu2DYMGDcKRI0cwZ84ciyz7zp072LlzJz799FP06dPHIssICQnBnTt34OTkZJH3fxiNRoOMjAysWrUKr732Wp55ixYtgrOzMzIzM0v03pcvX8aoUaMQGhqKWrVqFft169atK9HyiArD8KTHypkzZ/D6668jJCQEGzduRGBgoGneBx98gFOnTmHNmjUWW/7169cBAN7e3hZbhiRJcHZ2ttj7P4xOp0P9+vXx008/5QvPxYsXo02bNli2bJlVasnIyICrqyu0Wq1VlkePD562pcfKxIkTcfv2bcydOzdPcOYKCwvDhx9+aPrdYDBgzJgxqFKlCnQ6HUJDQ/HJJ59Ar9fneV1oaCjatm2Lbdu24bnnnoOzszMqV66MH374wdQmNjYWISEhAIBBgwZBkiSEhoYCyDndmfv3+8XGxkKSpDzT1q9fjwYNGsDb2xvu7u6IiIjAJ598Yppf2DXPjRs3omHDhnBzc4O3tzfat2+PY8eOFbi8U6dOISYmBt7e3vDy8kKPHj2QkZFR+D/sA7p06YI///wTycnJpml79uzByZMn0aVLl3ztb968iYEDB6JGjRpwd3eHp6cnXnzxRcTFxZnabN68Gc8++ywAoEePHqbTv7n9bNKkCapXr47//vsPjRo1gqurq+nf5cFrnt27d4ezs3O+/rds2RI+Pj64fPlysftKjyeGJz1WVq1ahcqVK6NevXrFat+rVy+MGDECtWvXxpQpU9C4cWNMmDABr7/+er62p06dwquvvooWLVrgyy+/hI+PD2JiYnDkyBEAQMeOHTFlyhQAwBtvvIGFCxdi6tSpiuo/cuQI2rZtC71ej9GjR+PLL79Eu3btsH379iJft2HDBrRs2RKJiYmIjY3FgAEDsGPHDtSvXx9nz57N1/61115DWloaJkyYgNdeew3z58/HqFGjil1nx44dIUkSfvvtN9O0xYsXIzIyErVr187X/vTp01ixYgXatm2LyZMnY9CgQTh06BAaN25sCrKoqCiMHj0aAPDOO+9g4cKFWLhwIRo1amR6n6SkJLz44ouoVasWpk6diqZNmxZY37Rp01CmTBl0794dRqMRAPDNN99g3bp1mDFjBoKCgordV3pMCaLHREpKigAg2rdvX6z2Bw4cEABEr1698kwfOHCgACA2btxomhYSEiIAiK1bt5qmJSYmCp1OJz7++GPTtDNnzggA4osvvsjznt27dxchISH5ahg5cqS4/7/plClTBABx/fr1QuvOXca8efNM02rVqiXKli0rkpKSTNPi4uKESqUS3bp1y7e8t99+O897dujQQfj5+RW6zPv74ebmJoQQ4tVXXxUvvPCCEEIIo9EoAgICxKhRowr8N8jMzBRGozFfP3Q6nRg9erRp2p49e/L1LVfjxo0FADF79uwC5zVu3DjPtL/++ksAEGPHjhWnT58W7u7u4uWXX35oH4mEEIJHnvTYSE1NBQB4eHgUq/0ff/wBABgwYECe6R9//DEA5Ls2Wq1aNTRs2ND0e5kyZRAREYHTp0+XuOYH5V4rXblyJWRZLtZrrly5ggMHDiAmJga+vr6m6U8++SRatGhh6uf93n333Ty/N2zYEElJSaZ/w+Lo0qULNm/ejKtXr2Ljxo24evVqgadsgZzrpCpVzseR0WhEUlKS6ZT0vn37ir1MnU6HHj16FKttdHQ0/u///g+jR49Gx44d4ezsjG+++abYy6LHG8OTHhuenp4AgLS0tGK1P3fuHFQqFcLCwvJMDwgIgLe3N86dO5dnesWKFfO9h4+PD27dulXCivPr3Lkz6tevj169eqFcuXJ4/fXX8csvvxQZpLl1RkRE5JsXFRWFGzduID09Pc/0B/vi4+MDAIr60rp1a3h4eODnn3/GokWL8Oyzz+b7t8wlyzKmTJmCqlWrQqfTwd/fH2XKlMHBgweRkpJS7GWWL19e0c1BkyZNgq+vLw4cOIDp06ejbNmyxX4tPd4YnvTY8PT0RFBQEA4fPqzodQ/esFMYtVpd4HQhRImXkXs9LpeLiwu2bt2KDRs24K233sLBgwfRuXNntGjRIl/bR/Eofcml0+nQsWNHLFiwAMuXLy/0qBMAxo8fjwEDBqBRo0b48ccf8ddff2H9+vV44oknin2EDeT8+yixf/9+JCYmAgAOHTqk6LX0eGN40mOlbdu2SEhIwM6dOx/aNiQkBLIs4+TJk3mmX7t2DcnJyaY7Z83Bx8cnz52puR48ugUAlUqFF154AZMnT8bRo0cxbtw4bNy4EZs2bSrwvXPrjI+Pzzfv+PHj8Pf3h5ub26N1oBBdunTB/v37kZaWVuBNVrl+/fVXNG3aFHPnzsXrr7+O6OhoNG/ePN+/SXF3ZIojPT0dPXr0QLVq1fDOO+9g4sSJ2LNnj9nen0o3hic9VgYPHgw3Nzf06tUL165dyzc/ISEB06ZNA5Bz2hFAvjtiJ0+eDABo06aN2eqqUqUKUlJScPDgQdO0K1euYPny5Xna3bx5M99rcwcLePDxmVyBgYGoVasWFixYkCeMDh8+jHXr1pn6aQlNmzbFmDFj8NVXXyEgIKDQdmq1Ot9R7dKlS3Hp0qU803JDvqAdDaWGDBmC8+fPY8GCBZg8eTJCQ0PRvXv3Qv8die7HQRLosVKlShUsXrwYnTt3RlRUVJ4Rhnbs2IGlS5ciJiYGAFCzZk10794dc+bMQXJyMho3bozdu3djwYIFePnllwt9DKIkXn/9dQwZMgQdOnRAv379kJGRgVmzZiE8PDzPDTOjR4/G1q1b0aZNG4SEhCAxMREzZ85EhQoV0KBBg0Lf/4svvsCLL76IunXromfPnrhz5w5mzJgBLy8vxMbGmq0fD1KpVPjf//730HZt27bF6NGj0aNHD9SrVw+HDh3CokWLULly5TztqlSpAm9vb8yePRseHh5wc3PD888/j0qVKimqa+PGjZg5cyZGjhxpenRm3rx5aNKkCYYPH46JEycqej96DNn4bl8imzhx4oTo3bu3CA0NFVqtVnh4eIj69euLGTNmiMzMTFO77OxsMWrUKFGpUiXh5OQkgoODxbBhw/K0ESLnUZU2bdrkW86Dj0gU9qiKEEKsW7dOVK9eXWi1WhERESF+/PHHfI+q/P3336J9+/YiKChIaLVaERQUJN544w1x4sSJfMt48HGODRs2iPr16wsXFxfh6ekpXnrpJXH06NE8bXKX9+CjMPPmzRMAxJkzZwr9NxUi76MqhSnsUZWPP/5YBAYGChcXF1G/fn2xc+fOAh8xWblypahWrZrQaDR5+tm4cWPxxBNPFLjM+98nNTVVhISEiNq1a4vs7Ow87fr37y9UKpXYuXNnkX0gkoRQcAcAERER8ZonERGRUgxPIiIihRieRERECjE8iYiIFGJ4EhERKcTwJCIiUuixGyRBlmVcvnwZHh4eZh3qi4iIHJ8QAmlpaQgKCjJ9009BHrvwvHz5MoKDg21dBhER2bELFy6gQoUKhc5/7MIz97sct+47Afdifq+jPSrv62rrEqiUkOXSMU6KSsUzSfTo0lJTEVYp+KHf+/vYhWfuqVp3Dw+4e3jauJqS8/RkeJJ5MDyJ8nvYZT3eMERERKQQw5OIiEghhicREZFCDE8iIiKFGJ5EREQKMTyJiIgUYngSEREpxPAkIiJSiOGpgN+Y/6H8q60RWjscVUL9UDmyAoKb14XvpPFQ3Ux66OvLDngfVQPcUDXADU5nEqxQcQlcvAhNr7ehqxgEnZsOurBQaAZ8BNy6ZevKio99sK2kJKi//w7aTh3hHFUVLl6ucCnjDV3ThlDPmwvIsq0rLD5HXg+52AeLkIQQpWN4kWJKTU2Fl5cX9p28oniEobBgb2TWqIWs8EgY/ctAlZEB5/92wzluHwwBgbiwZjMM5QseC9Ft3R8I6tYJsps7VOm3cXbnQWRXqlLifgT7mX+EISkhAdpG9SAlJsLYrj1ERCSkPbuh3rwJckQEsrZsB/z8zL5cc2IflDP3CEOaObOh7fs+5MBAyI2bQgQHQ0q8BvWK5ZBSUmDo8AqyfvoFMPMXM5h7hCFuS/bB2n1ITU1FOT8vpKSkwNOz8IxgeCogZWZCODvnm+43IRa+075AcvfeuP751Hzz1Teuo2LT53CnXiOoE6/Bdec/dhmeTq1bQr1+HbKnTIexT1/TdM3AAdBMmwJD7/+DYeZssy/XnNgH5cwdnqpNGyGlp8PYug1w/7dSXL0K5wbPQ3XhAvRLlsLY4RXzLtfM4cltyT5Yuw8Mz0I8SngWRnvkIEJeqIuMRk1x6ZfV+eYH9ngdznt34dyWvQjs2dUuw1NKSIAuMgxyaCiy4hPyfuilpUEXHAgIAf3lRMDNzazLNhf2oWSsObat5vPx0I74H7Lf+wDZU2eY9b3NGZ7cluyDLfpQ3PDkNU8zcFv3JwBAH1U93zyPJQvh/ucqJH4xA7Kv/Z4eUW3eBACQm0fn3UABwMMDcr36kDIyoNr1rw2qKx72wQFonO7+ad/fSVEa1gP7YOHarL7EUsB75lT4fjEO/iMGo0L7FvD/fDT01arjVt+P87TTXDiPMsMHI/XV15Heqq2Nqi0e6UQ8AECEhxc4X4RVvdvuhNVqUop9sHMGAzSLFgIAjNGtbFxM0UrDemAfLMu+d//slM+sadBcTzT9nt60Ba5N/wZG/zL3GskyyvV7B8LNDdfHTrJBlQqlpOT86elV8Hyvu9NTkq1STomwD3bN6dOhUB05DGOr1pCjW9q6nKKVhvXAPlgUjzxL4MyhMzh5NR2nD53G5e9/gtP5s6jYvB50B/eb2nh/MwOuO//BtUlfQfb2sWG1RLan+Wo6nKZOhhwRCf28H2xdDtEjY3g+AmOZckhv3Q6XlvwO1a2bKNe3NwDAKeEk/D4bhZTX30JGc/s+PWWSuweXmlLw/Nw9QC9vq5RTIuyDXdLM/Arajz+CHFUNmes2Ar6+ti7p4UrDemAfLMohw3Pnzp1Qq9Vo06aNrUsBABiCKyIrPBK6+GNQJd2A9sRxqPR6eC1ZaBoUIffHdec/AIDQuk+iaoAb3P5cZePqc4jwCACFXzuQTp28267gaw/2gH2wP5rpU6Ht3w/yE9VzgjMgwNYlFUtpWA/sg2U55DXPuXPnom/fvpg7dy4uX76MoKAgW5cEzdUrOX9Rq5EdXBEpXboX2M5tw1poEq8h7aWOkD08kB1c0YpVFk5u0hQAoNqwLmcEmAduCVft2A7h6gr5+To2qvDh2Af7opn0ObSfDoNcsxYy/1gH+PvbuqRiKw3rgX2wLIc78rx9+zZ+/vlnvPfee2jTpg3mz59vleU6JZyEqqBTB7IMvwmx0Ny4jjvP1oHs7YOs6jWROHlmgT9ZVXL2kJI+ic35vXpNq9T/MKJKFRhbREN19izUM7/OM08zamTOQ+9d37Lb58EA9sGeaMaPgfbTYTDWfhqZazc4VHACpWM9sA+W5XCDJHz//feYNWsW9uzZg9WrV+Ojjz7CyZMnIRUy1Jder4derzf9npqaiuDgYMWDJHjP+Qp+40ci87m6yK4YCqOPL9TXE+Gycxu0587AULYcLi1dg6yIqCLfp3yHVnY5SAJQwDBYkVGQdu+CevMmyOHhyNq6w/GG8mIfHsrcgySoFy6ArlcPCLUahvf73Ltudf8yQ0Jh7BZj1uVafHg+bks2Ye0+lNoRhurXr4/XXnsNH374IQwGAwIDA7F06VI0adKkwPaxsbEYNWpUvulKw1N77Ai8fpgLl907oLlyGaqUZMiubsiuHIb05q2Q3Os9yD4PvxHCnsMTAHDhAjSxI6BetxZISgICA2Fs3wGG4SMBHwe5a5h9UMTc4ek0JhZOY0cX2cbYqDH06zeZdbnmDk8A3JbshRX7UCrDMz4+HtWrV8elS5dQtmxZAECfPn2QkpKChQsXFvgacx152huLhSc9dqw5PJ8lWSQ86bFT3PB0qBuG5s6dC4PBkOcGISEEdDodvvrqK3gVcHpIp9NBp9NZs0wiIirlHOaGIYPBgB9++AFffvklDhw4YPqJi4tDUFAQfvrpJ1uXSEREjwmHOfJcvXo1bt26hZ49e+Y7wnzllVcwd+5cvPvuuzaqjoiIHicOc+Q5d+5cNG/evMBTs6+88gr27t2LgwcP2qAyIiJ63DjMkeeqVYWPxPPcc8/Bge57IiIiB+cwR55ERET2guFJRESkEMOTiIhIIYYnERGRQgxPIiIihRieRERECjE8iYiIFGJ4EhERKcTwJCIiUojhSUREpBDDk4iISCGGJxERkUIMTyIiIoUYnkRERAoxPImIiBRieBIRESnE8CQiIlJIY+sCbKW8rys8PV1tXUaJ+Tzbx9YlPLKbu2fYuoRHps+WbV3CI3PSlI59aFkWti7hkalUkq1LoGIqHf9riIiIrIjhSUREpBDDk4iISCGGJxERkUIMTyIiIoUYnkRERAoxPImIiBRieBIRESnE8CQiIlKI4UlERKQQw5OIiEihx3ZsW4u4eBGa2BFQr1sLJCUBgYEwtnsZhuEjAR8fq5UhnDJhDDoNudxZCM8kCJd0QFZDSvWD+nwk1OeiIOHeGJrCJQ2GqvsgeydCuKYBTnogyxlSuhfU56OgvhAOSagLXJYx+DgMlQ9BeNwEhApSij80J5+C+lqolXqbl2rZr1D/swVSXBxUB+MgpaXB8EZXZC9YaJN6SkQIaOfPhXb+XKiPHQWEgDEiClkxbyPr7d6Ayv73eZ0+GQL1f/9BOnUC0o0bgIsL5IohMLZrj+z3+gB+frYusWhJSVCvXA71n39AdfgQpMuXAK0WcvUaMHSLgbF7D4dYDwDs5nPpkdhhHyQhhOOPpqxAamoqvLy8cC0pBZ6enmZ7XykhAdpG9SAlJsLYrj1ERCSkPbuh3rwJckQEsrZsN+sHRlEDwxtCD8NQawtwxxWqG+Uh3fEAdBkwBp0GnLKgulQFTntamgLU6H8J2c//AdWtcpDSPYEsHaDNhLHcecD1NlTXy8NpRztIIu+HRfYT22GsegDIcIf6chVAZYSxwklAq4cmriE0Z54ssg+WGBhe98xTUB2Mg3B3hyhfAar44xYNT0sMDO/a4y1of/kJcpmyyG7zEuDiCs2mDVAfP4asN95Exnfzzbo8SwwM7+qug/xUbchRURBlykJKT4dq9y6o/9sLOSgImVt3QgQHm3WZ5hxSXTNnNrR934ccGAi5cVOI4GBIidegXrEcUkoKDB1eQdZPvwCSeQdyN/fA8Nb+XLIEa/chNTUV5fy8kJJSdEbwyNNMNH3fh5SYiOwp02Hs09c0XQwcAM20KdAM/xSGmbOtUot02xtO/7aG6mponiNMzdE60Df+FXL5BMiXTucEHgBVUgB0a3rlaQsAGsmI7HqrIJe5BDkwAerLVU3zZN8rMFY9AOm2J7RbOkHKdgYAqE89hawmv8BQfQdU10KhyjDfDkpxZE+aDFG+AkRYGFRbt0DXoplVl/+onH5fAe0vP8EYWgm3t+yE8PfPmZGVBbcunaD96Udkv9Qe2e072LbQh8i4kQI4O+eb7jTiU2g/nwCniROQNWOmDSorHrlqOPTLVsLYuk3eI8zR4+Hc4Hloli+DccVvMHZ4xXZFFoM9fS6VlL32wUHOO9g3KSEB6vXrIIeGwvj+B3nmGUaOgnBzg3rRQiA93Sr1qG9UgPpqpXxhKOndoDn7BABA9r90b7pQ52ubO111pRIAQLin5JlnCD2Ss6wTz5iCEwBUGZ5Qn64BqI0wVjxmng4pIDdpClG1qtmPCKzF6fcVAAB9v/73ghMAtFpkDh+V89fZX9ugMoUKCE4AML76GgBAdeqUNatRTG7aDMa2L+U/NRsQAEPv/wMAqLZstn5hCtjb51JJ2HMfGJ5moNq8CQAgN4/O/5/NwwNyvfqQMjKg2vWvDap7gKzK+2cRBGTI5c4BAKTUvKdF5DIXAQDqaxXzvU59LSSnzX0BTcUjXbsKAJBDK+WbZ6xUGQCg2bENyMqyal3mol6zCgAg16hh40oegcbp7p/2feLOoT6XCmHPfbDvte8gpBPxAAARHl7gfBFWFVi/DtKJE0CzF6xZWt46JBnG4JxaVYn5Q09o78BQ+RAAAWgzIZe9AOGeAtWFqlBfvfdhLtTZgEs6kO0ESe+W732kdK+cdu7JFulHaSb8co42VefO5punPnMaACAZDFCdOQ05ItKapZWIZvIkSOm3IaWkQLXvP6i3b4OxxpPIGjTU1qWVjMEAzaKc6+fG6FY2LqZojvK5VBR77gPD0xxS7p7S9PQqeL7X3ekpyVYppzCGajshvG5CdTUE6gLDMxPGyD33TQDUJ2tBc7RO3oZOd496DNqCF5R9d7qT3gxVP16yW7WGdukS6GZMRfarnSF8fe/OyIbzuFGmdlLyLRtVqIzT1C+hunbN9LshuhX0380DypSxYVUl5/TpUKiOHIaxVWvI0S1tXU7RHORzqUh23AeG52PCUDku5wafNB84/de8wDaq2z5wXvEBBGTAJR3GwNMwRO2G7HcF2p1t81zbJMvI7tQZ2T/9CKcN6+DxdA1kt20H6Jyh2fw3pKtXIAdXhOrCeYd5TOLO+Ss5f7l2Dep/d0D76TC4PF8b+uWrID9V27bFKaT5ajqcpk6GHBEJ/bwfbF0O2Zhj/A+0d7l7P6kpBc/P3Xvy8rZKOQ8yVDoIw5PbIKX6QLut/UNDUIIK0h0PaE7XhNOBJhC+12CI2n2vQe6RpaaQ6265R6bZOjNU/5hRq5H+60rcGT0ewr8MtIt+gHbxD5CrhOH23/9AuHsAAESZsjYuVKFy5WBs3wGZa/6ClJQE3dvdbV2RIpqZX0H78UeQo6ohc91GIPeMgD2z88+lYrHjPjhkeMbExECSpHw/p2x0B58IjwCAnPPuBZBOnbzbruDz9pZkqBIHQ81/IKX4Qrvt5QKvURZFdfeGoDx35xqdgDtugFM2hC7/XW7CLWeDlm57l7zwx5mTE/QfD0bangNIuZmOlMtJSP/5N8ghoVAlnITs71/gDUWOQISEQI6qBtXRI8CNG7Yup1g006dC278f5Ceq5wRnQICtSyoWe/5cKi577oNDhicAtGrVCleuXMnzU6mSbT5Q5CZNAQCqDesA+YGH5tPSoNqxHcLVFfLzdQp4teUYqu6DocY2SMn+0G5/GVKWq+L3EC53w1HkffRDdb0CAOQMpPAA4907dFU3yiteHhVOu/RnSFlZyO70uq1LeSSqK5dz/qIueNQqe6KZ9Dm0gwZArlkrJzjLOs4Rv71+Lilhz31w2PDU6XQICAjI86O20X9GUaUKjC2ioTp7FuqZeZ/B04waCSk9HcaubwFuyo76HoUhYg8MT+yEdKsMtNvbQ8pyKbSt7HU95zrnA4Q6C4Ya/wAAVFdD88zLfV7UGL4Xwinz3nu5psJY+RBgVEN9PsoMPXkMpabmm6SOOwDn/w2B7OODzI8H26Co4pNOnLh3Ou1+sgynEZ/mjBRTt57dDw2nGT8G2k+HwVj7aWSu3QDc/9ytA7DHzyWl7LkPpf6GIb1eD73+3l2fqQV8MJmDYcZMqBrVg1P/flBt+hsiMgrS7l1Qb94EOTwchjHjLLLcghiDj+dco5QlqJKCYKhyMF8bKcMDmrvhZojcA9n3ClQ3A3KG8jNoIFxuQy53HtDqISUFQHMi780dqpuBUJ+qCWNYHPRNf743PF/5U6bh+aw9uhAAqFaugPr3lTl9vPvMpGrXTjj17AEAEP5+MHw+yep1KeH+UkvAxQXGatUh3N2hjj8Ozdo/ABcX3F66AiIwyNYlFkm99g9oh38CuV4DyKGhEH5+OUPbbd2a84hNQAD0s+bYuswiqRcugHbUSAi1GnL9BnD6enq+NnJIKIzdYqxfnAL29LlUUvbaB4cNz9WrV8Pd3d30+4svvoilS5fmazdhwgSMGjUq33RzE1WqQP/v3nuDF//5BxAYCEPfD60+eLHsdncHQSVgDIsrsI10I8gUnuqz1QCDE4TPNcj+lwG1AcjWQZVcBqpLYVCfj8o3ri0AOB1uACnVD8ZKh2EMPQIICVJKGWj22XBg+LgD0CxckHfa6dNQnc55RlIOCbH78Mx++RU4/foLtEsWAXfuQA4qj6y3eyNz4BCI8hVsXd5DGV9oDkPCKah2bIcmbj+QnAy4uUGuGo6srm8i+4N+dn/DjersGQCAZDTCaca0AtsYGzW2+/C0p8+lkrLXPjjkwPAxMTG4dOkSZs2aZZrm5uaGwMDAfG0LOvIMDg42+8Dw1lbUwPCOwhIDw1ubJQaGtzZLDAxvC445IGNe5h4YnpQr9QPDu7m5ISws7KHtdDoddDo+MkFEROZTOnY5iYiIrIjhSUREpBDDk4iISCGHvOY5f/58W5dARESPMR55EhERKcTwJCIiUojhSUREpBDDk4iISCGGJxERkUIMTyIiIoUYnkRERAoxPImIiBRieBIRESnE8CQiIlKI4UlERKQQw5OIiEghhicREZFCDE8iIiKFGJ5EREQKMTyJiIgUYngSEREppLF1AVQyt/Z8ZesSHtnygxdtXcIj6/BkBVuXQGRXhBC2LuGRFLd+HnkSEREpxPAkIiJSiOFJRESkEMOTiIhIIYYnERGRQgxPIiIihRieRERECjE8iYiIFGJ4EhERKcTwJCIiUojhSUREpBDD05wuXoSm19vQVQyCzk0HXVgoNAM+Am7dsnVlxecgfdh/7W9M2NkFfdY/i+5rwvDh3/Uxde+7OHHzvwLbn7i5F5/v6obea6uj+5owDNncAn+e/g6yMFq58mJykPVQJPbBPjh4H1TLfoXTR32hbdoIzn5ecNGq4NT9LVuXBUk4+ii+CqWmpsLLywvXklLg6elptveVEhKgbVQPUmIijO3aQ0REQtqzG+rNmyBHRCBry3bAz89sy7MEa/ehpAPD/3R0PFYlzIK7kw+eCWwJD60vrqWfxX9X10MWBrz31FQ0qNDR1H7v1b8wde//wUmlQ92gl+Cm9ca+qxtwJT0BzwW2wUfPzC5xHywxMDy3JfvAPpSMuSNF98xTUB2Mg3B3hyhfAar44zC80RXZCxaadTm5UlNTEeDvjZSUojOC36piJpq+70NKTET2lOkw9ulrmi4GDoBm2hRohn8Kw8ySf0hbgyP0ITkzEasTvoGXrgw+a7wOXjp/07wjN3Zg3M7OWBr/pSk8M7LT8F3cEKgkNYbX+wWVvWsCADpFDMS4na9j95U12HFpJeqVb2+T/hTEEdbDw7AP9qE09CF70mSI8hUgwsKg2roFuhbNbF0SAB55muU9pYQE6CLDIIeGIis+AVDddzY8LQ264EBACOgvJwJubmZZprnZog8lOfI8dWs/Rmxrh6fLtcDHz32fb37PP6MghMD3rY8DADafX4I5cYPQsMKreO+pKXnaHrmxHeN2vo5I3+cxov6vJeqDuY88uS3ZB/ah5CwZKaotm6Fr0cwujjx5zdMMVJs3AQDk5tF5N1AA8PCAXK8+pIwMqHb9a4PqisdR+hDgFgqNSouE5Dik6m/mmXcs6V/cMdxG9TINTNOO3NgBAKhZtnG+94r0fR46tQtO3voP2Ua9ZQsvJkdZD0VhH+xDaeiDPWN4moF0Ih4AIMLDC5wvwqrebXfCajUp5Sh9cNf64I2oYUjRX8fgzc3wbdwQLDn2GabtfQ+f/fsmavg3RM8nPzO1v3I7AQAQ4FY533upVRqUcQ2GURiQmHHean0oiqOsh6KwD/ahNPTBnvGapzmkpOT86elV8Hyvu9NTkq1STok4UB9erNwL/i4VMCduIDadX2yaXs4tFI2CO+W5DpphSAMAuDp5FPherpqc0zLp2akWrFgBB1oPhWIf7ENp6IMdY3iSw1l1ahZ+Pv45WlbqgejQGHjryuLy7VNYcvwzfL2/H86lHkWXap/aukwiKsV42tYccvfgUlMKnp+7B+jlbZVySsRB+nD0xk78dGw8ni7XAm89MRLl3EKg07igkncNDHjmO/g6B2BNwhxcSz8HAHDV5BxxZmSnFfh+GYacI043J/M9tvRIHGQ9FIl9sA+loQ92jOFpBiI8AkDh1w6kUyfvtiv42oM9cJQ+7L+2AQBQzb9evnk6jQuqeNeCgIxzKUcAAIHuVQAAV9NP52tvlA24nnEBakmDsq4VLVh18TnKeigK+2AfSkMf7JndhWdMTAwkSYIkSdBqtQgLC8Po0aPx5ptvmqYX9BMaGmqzmuUmTQEAqg3rAFnOOzMtDaod2yFcXSE/X8cG1RWPo/QhW84CAKTqkwqcn5qVM12tcgIAPHE3ZOMSt+Rre/zmLuiNd1DV52k4qXWWKFcxR1kPRWEf7ENp6IM9s7vwBIBWrVrhypUrOHnyJD7++GPExsaiatWquHLliukHAObNm2f6fc+ePTarV1SpAmOLaKjOnoV65td55mlGjYSUng5j17fs9nkwwHH6EOn3HABg4/nFuHnnSp55B65twombe+Gk0iHc9xkAwHOBbeCh9cXOy7/jdHKcqW2WMRO/HP8CANA81PZDfeVylPVQFPbBPpSGPtgzuxskISYmBsnJyVixYoVpWnR0NNLS0rBz507TNEmSsHz5crz88stFvp9er4def+8ZvtTUVAQHB1t+eL7IKEi7d0G9eRPk8HBkbd3heEN5WbgPJRkkQRYyPvv3TRy+8Q9cNO54JqAVvHVlcOn2Sey/9jcEBN56IhYvVu5pes2eK2sx7b93c4bnK98O7k7e+O/qetPwfB8+PQuSJJWoD1YZno/bkk2wDyVj7khRrVwB9e8rAQDStatQr/sLcuXKkOs3zFmevx8Mn08y2/KKO0iCQ4Rn+/btcfHiRfz3371Bv4sbnrGxsRg1alS+6eYOTwDAhQvQxI6Aet1aICkJCAyEsX0HGIaPBHx8zLssS7FiH0o6tq1Bzsb6swuw89LvuHT7JPTGO3B38kYV71poWakHnixgQIT4m3uw4uQMnLy1D9nGTAS4haJxcGe0qvw2VJK6xH2wRHgC4LZkL9gHxcwdKZrRsXAaO7rQ+XJICPQnz5hteaUiPIUQ+Pvvv9G2bVv07dsXX3zxhamdvR15knIlDU97YrHwJHJQdhYpijn0wPCrV6+Gu7s7srOzIcsyunTpgtjY2BK9l06ng05nHzeDEBFR6WCX4dm0aVPMmjULWq0WQUFB0GjsskwiInpM2WUqubm5ISwszNZlEBERFcguH1UhIiKyZwxPIiIihezutO38+fOL1c7R7+giIiLHxSNPIiIihRieRERECjE8iYiIFGJ4EhERKcTwJCIiUojhSUREpBDDk4iISCGGJxERkUIMTyIiIoUYnkRERAoxPImIiBRieBIRESnE8CQiIlKI4UlERKQQw5OIiEghhicREZFCdvdl2FQ8GXqDrUt4ZB2erGDrEh5ZcnqWrUt4ZJ4uTrYuwSxUKsnWJRAASXLs9VDc+nnkSUREpBDDk4iISCGGJxERkUIMTyIiIoUYnkRERAoxPImIiBRieBIRESnE8CQiIlKI4UlERKQQw5OIiEghhicREZFCDE9zungRml5vQ1cxCDo3HXRhodAM+Ai4dcvWlZk4LV8G148/hEeLJvAJ9IWvuxPcenYruHF2NnRfT4fbuz3hWfdp+Pi4wtfdCbr5c61btFIOsB50K3+Dx6CP4PtiM5QN9keAtw5e78QU/gK9Hq7fzoJvs/ooWzkIZcv7wv+5J+ExuD9U589Zre5iSUqC+vvvoO3UEc5RVeHi5QqXMt7QNW0I9by5gCzbusLic4Bt6aHYB4vgwPBmIiUkQNuoHqTERBjbtYeIiIS0Zzc0M6ZBtW4tsrZsB/z8bF0mXCaOh+bQQQh3d8hBFaBOO15oWyk9HW5DPgYAyGXLQS4XAPXFC9YqtUQcZT24fzEBTocPQnZ3hxxUHqq0+MIbGwzwbd8K2n93wBAegTuvvAbodHDa9x/c5syEy5JFSFq3BcbIKOt1oAiaZUuh7fs+5MBAyI2bQgQHQ0q8BvWK5dC92xuGv9Yi66dfADsfQNxRtqWisA+WwyNPM9H0fR9SYiKyp0xH9rIVMIz/DNnrN8LwYX+o4uOhGf6prUsEAGR89iWSDxzFrSs3kT71qyLbCldXpP22CrdOnUfy6YvIeivGOkU+AkdZD2njv8D1/w4j8cINpH45o8i2utUrof13B/SNm+LGvweQ9sVUpI39HDf/2IDbgz+FKjUFbjOmWKnyh5OrhkO/bCUyT19A1oIfkT12ArLmfI87B49BDg6GZvkyqFf8ZusyH8pRtqWisA+Ww/A0AykhAer16yCHhsL4/gd55hlGjoJwc4N60UIgPd1GFd5XT+MmkMOqFm+vX6tFdnQriIBAyxdmBo60HrIaNYGxSvHWg+bsGQCAPvpFQJX3v2xm65cAAKob181fZAnJTZvB2PalfLUiIACG3v8HAFBt2Wz9whRwpG2pMOyDZTE8zUC1eRMAQG4enf8Dw8MDcr36kDIyoNr1rw2qe3yU1vVguHs6Vrfhr3zXC3V//QEAyGrSzOp1lYjm7neHauz7ilFp2JbYBwvXZvUllkLSiZzrVSI8vMD5Iqzq3XYnrFbT46i0rgd9y9bIfOll6Db9Db96teExZAA8hg+Fz0st4T5pAtLfeR8Zvd+zdZkPZzBAs2ghAMAY3crGxRStNGxL7INlFWv37/fffy/2G7Zr167ExTislJScPz29Cp7vdXd6SrJVynlsldb1IElI/mEJ3D8bC7dJE+B0/Jhplr5xU2R2et3uj+QAwOnToVAdOQxjq9aQo1vaupyilYZtiX2wqGL9j3v55ZeL9WaSJMFoND5KPUT0oMxMeL37NnQb/kLqpGnQt34JwsUVTrt2wHPIAPi2fgHJ8xdD38Z+d1w1X02H09TJkCMioZ/3g63LIXpkxTptK8tysX4e2+DM3ftJTSl4fu7ek5e3Vcp5bJXS9eA+5Qu4rFiG2/8bhTs9ekMuFwDh6YmsFq2QvGAJpOxseA4daOsyC6WZ+RW0H38EOaoaMtdtBHx9bV3Sw5WGbYl9sKhHuuaZmZlprjocmgiPAFD4eXfp1Mm77Qo+b0/mUVrXg+mmoIZN8s0z1HgSsrcP1BfOQbqZZOXKHk4zfSq0/ftBfqJ6TnAGBNi6pGIpDdsS+2BZisPTaDRizJgxKF++PNzd3XH69GkAwPDhwzF3bslHnpEkqcif2NhYU9vIyEjodDpcvXq1xMszJ7lJUwCAasO6/KOnpKVBtWM7hKsr5Ofr2KC6x0epXQ9ZegCFPI6i10O6nZbzdyetFYt6OM2kz6EdNAByzVo5wVm2rK1LKrbSsC2xD5alODzHjRuH+fPnY+LEidBq7/1nrV69Or777rsSF3LlyhXTz9SpU+Hp6Zln2sCBOaeltm3bhjt37uDVV1/FggULSrw8cxJVqsDYIhqqs2ehnvl1nnmaUSMhpafD2PUtwM3NRhU+HkrresiuWx8A4Db5c0CvzzPP/bMxkAwGZNV+BsLDwxblFUgzfgy0nw6DsfbTyFy7AfD3t3VJipSGbYl9sCxJCCGUvCAsLAzffPMNXnjhBXh4eCAuLg6VK1fG8ePHUbduXdwyw1iD8+fPx0cffYTk5OR883r06IGAgAA0btwYH374IeLjixjWrACpqanw8vLCtaQUeHp6PnKtufINIRUZBWn3Lqg3b4IcHo6srTvMOoRUht5Qotc5rVoJ7eqVOTVfuwbthnUwVqoMQ72cD2jZzx93xk80tXf+ciLUJ3KG8FMfjIPm0EFk16kLuUoYAMBQtz70MT1LVIurzvx3iFp7PSSnZ5XodbrVK+G8ZhUAQJV4Fbq/18MQWgnZdRsAAGQ/P6SN/Txn/uVL8GvRCOpLF2GoGIKs5tEQzi5w2rUT2v/2QLi44ObKtch+rmR7354uTiV6XWHUCxdA16sHhFoNw/t97l23uo8cEgpjtxizLlelMu9wf9beliyBfVAuNTUV5fy8kJJSdEYoDk8XFxccP34cISEhecLz6NGjeO6553D79u1HLr6w8ExLS0NgYCB27dqFyMhIlC9fHkuXLkXDhg0LfS+9Xg/9fXvrqampCA4ONnt4AgAuXIAmdgTU69YCSUlAYCCM7TvAMHwk4ONj1kWVNDxdxo2Gy4Qxhc43VgxBytFTpt89Wr0Ap21bC22v7/oW0r/5vkS1WCI8AVh1PZQ0PN0njIH752MLnW8MDsH1Q/eu80g3rsN96iTo1v0J9bmzgCxDLhcIfaMmSP/oYxjDI0tUB2D+8HQaEwunsaOLbGNs1Bj69ZvMulxzhycAq25LFsM+KGKx8Hz66afRv39/vPnmm3nCc/To0Vi/fj3++eefRy6+sPD89ttvMXPmTOzfvx8ATG3mz59f6HvFxsZi1KhR+aZbJDytqKThaU8sFp5WVNLwtCfmDk9bsUh40mOnuOGp+NNrxIgR6N69Oy5dugRZlvHbb78hPj4eP/zwA1avXv1IRT/M999/jzfffNP0+5tvvonGjRtjxowZ8Cjkes+wYcMwYMAA0++5R55EREQlpfiGofbt22PVqlXYsGED3NzcMGLECBw7dgyrVq1CixYtLFEjAODo0aP4999/MXjwYGg0Gmg0GtSpUwcZGRlYsmRJoa/T6XTw9PTM80NERPQoSnTerGHDhli/fr25aynS3Llz0ahRI3z9dd47rubNm4e5c+eid+/eVq2HiIgeXyW+6LR3714cO5Yzxma1atXw9NNPm62oB2VnZ2PhwoUYPXo0qlevnmder169MHnyZBw5cgRPPPGExWogIiLKpTg8L168iDfeeAPbt2+Ht7c3ACA5ORn16tXDkiVLUKFCBXPXiN9//x1JSUno0KFDvnlRUVGIiorC3LlzMXnyZLMvm4iI6EGK77Zt1aoVkpOTsWDBAkRE5AydFB8fjx49esDT0xNr1661SKHmYqnnPK2Nd9vaB95taz94ty2Zg8Xutt2yZQt27NhhCk4AiIiIwIwZM4p83pKIiKi0UHy3bXBwMLKzs/NNNxqNCAoKMktRRERE9kxxeH7xxRfo27cv9u7da5q2d+9efPjhh5g0aZJZiyMiIrJHxbrm6ePjA0m6dz0hPT0dBoMBmrvfXp/7dzc3N9y8edNy1ZoBr3naD17ztA+85kl0j1mveU6dOtVcdRERETm8YoVn9+7dLV0HERGRw3ik82aZmZnIysp72sqRT4USEREVh+IbhtLT09GnTx+ULVsWbm5u8PHxyfNDRERU2ikOz8GDB2Pjxo2YNWsWdDodvvvuO4waNQpBQUH44YcfLFEjERGRXVF82nbVqlX44Ycf0KRJE/To0QMNGzZEWFgYQkJCsGjRInTt2tUSdRIREdkNxUeeN2/eROXKlQHkXN/MfTSlQYMG2Lp1q3mrIyIiskOKw7Ny5co4c+YMACAyMhK//PILgJwj0tyB4omIiEozxeHZo0cPxMXFAQCGDh2Kr7/+Gs7Ozujfvz8GDRpk9gKJiIjsjeJvVXnQuXPn8N9//yEsLAxPPvmkueqyGI4wZD84wpB94AhDRPdY7FtVHhQSEoKQkJBHfRsiIiKHUazwnD59erHfsF+/fiUuhoiIyBEU67RtpUqVivdmkoTTp08/clGWVFpO2xqMsq1LeGQateJL7mQBxy6l2roEs4gM8rB1CY/s/i/gcFSy/EhXAm0uNTUVgWW8zXPaNvfuWiIiIirB3bZERESPO4YnERGRQgxPIiIihRieRERECjE8iYiIFCpReP7zzz948803UbduXVy6dAkAsHDhQmzbts2sxREREdkjxeG5bNkytGzZEi4uLti/fz/0ej0AICUlBePHjzd7gURERPZGcXiOHTsWs2fPxrfffgsnp3tjYtavXx/79u0za3FERET2SHF4xsfHo1GjRvmme3l5ITk52Rw1ERER2TXF4RkQEIBTp07lm75t2zbTl2QTERGVZorDs3fv3vjwww+xa9cuSJKEy5cvY9GiRRg4cCDee+89S9ToOC5ehKbX29BVDILOTQddWCg0Az4Cbt2ydWUloln8I9yd1XB3VkPz/Xe2Lqf4SsN6cNA++Cz/GU+FeuGpUC/4LVmQb74qLRXlvp6EiBcboEaNiniyRjAiW9ZF4JdjoUm6YYOKC6da9iucPuoLbdNGcPbzgotWBafub9m6LOUcdFsCACQlQf39d9B26gjnqKpw8XKFSxlv6Jo2hHreXEC23Rjfir+SbOjQoZBlGS+88AIyMjLQqFEj6HQ6DBw4EH379rVEjQ5BSkiAtlE9SImJMLZrDxERCWnPbmhmTINq3VpkbdkO+PnZusxiky5cgK5/Pwh3d0i3b9u6nGIrDevBUfvgdPkiKowYBKObO9Tp+bcZVWoKIl5uBufTp5D+5FO42akrAMB993YEzPgCvr8uRvzvm2EoU9bapRfIacI4qA7GQbi7Q5SvACn+uK1LUsxRt6VcmmVLoe37PuTAQMiNm0IEB0NKvAb1iuXQvdsbhr/WIuunXwAbDKiv+MhTkiR8+umnuHnzJg4fPox///0X169fx5gxYyxRn8PQ9H0fUmIisqdMR/ayFTCM/wzZ6zfC8GF/qOLjoRn+qa1LLD4hoHunJ4SvH7J7/5+tq1GkNKwHh+yDEAgZ9D6MPj640bVHgU38f5oP59OnkNTpTZz4fTMujZiASyMmIH71ViS90gXaK5fgv3ielQsvXPakycg8Eo/MpBRkfzXT1uWUiENuS/eRq4ZDv2wlMk9fQNaCH5E9dgKy5nyPOwePQQ4Ohmb5MqhX/GaT2ko8SIJWq0W1atXw3HPPwd3d3Zw1ORwpIQHq9esgh4bC+P4HeeYZRo6CcHODetFCID3dRhUq4/T1DKg3b0TmnLmAq5utyym20rAeHLUPZebNhvuOrTj3xUzILgVvM9rzZwEAKS+0yjcvpcWLAADNTfs5dSs3aQpRtapNjmrMwVG3pfvJTZvB2PYlQPVAVAUEwHB3x161ZbP1C0MJwrNp06Zo1qxZoT+PI9XmTQAAuXl0/pXs4QG5Xn1IGRlQ7frXBtUpIx0/Bu3/hiG7Tz/IDfPfVW3PSsN6cMQ+6E7FI+jzWFzv8R7Sn69faLvM8CgAgOemv/LN8/o7Z1pa/SYWqfFx5IjbkiKau49KahRffTQLxeFZq1Yt1KxZ0/RTrVo1ZGVlYd++fahRo4YlarR70ol4AIAIDy9wvgirerfdCavVVCIGA5zf7g4RXBFZo8fZuhrFSsN6cLg+GAwI7f8OsspXwOXBI4psmtS5G24//Tz8f16I8PbNUH7MJyg/5hOEt2sC79W/4fKg4UiJbmOlwks/h9uWlDAYoFm0EABgjM5/JsMaFEf2lClTCpweGxuL2w50Y4lZpaTk/OnpVfB8r7vTU5KtUk5JaceNgerAftzZuBVwcbF1OcqVhvXgYH0ImP45XI4cxImlf0E4F73NCGdnnFq8ChVGDYH/4nlwi/vPNO9W6/ZIiW5r6XIfLw62LSnh9OlQqI4chrFVa8jRLW1Sg9kGhn/zzTfx/fffm+vtyMpUu3fBaeIEZH80AHKdurYuhxyA6/69CPj6SyT27oOMp597aHv1rZuo0q0jvNatwZkZ3+Pg/jM4uP8Mzsz4Hu67dyL85RfgeuC/h74PPd40X02H09TJkCMioZ/3g83qMFt47ty5E87OzuZ6O8eSuweXmlLw/Nw9QC9vq5SjmMEA554xEFXDkTVytK2rKTlHXw+A4/TBYEDIx/+HzEphuDLgf8V6Sfmxn8Jj1zacnzANyS+9AqOPL4w+vkh+6RVcGD8V6vTbCJpQ9KlfUsBRtiUFNDO/gvbjjyBHVUPmuo2Ar6/talH6go4dO+b5XQiBK1euYO/evRg+fLjZCnMkIjwCQOHXDqRTJ++2K/jag83dvg3VyZza3b1cC2zi/P7/Ae//H7L69EPWpIJP3duaw68HOE4f1Om34Xw6Z6SxWhEFP5dZcWg/VBzaD4k93sOlkZ/Ba+NaAMDtug3ztU27O8318AHLFPwYcpRtqbg006dCO2gA5CeqI3PtBqCsbZ8HVhyeXl55z5+rVCpERERg9OjRiI6OVlxATEwMFizIGYlEo9HA19cXTz75JN544w3ExMRAdd9dYvv378f48eOxdetWpKSkIDg4GE2aNMGgQYMQbsMNQG7SFACg2rAuZ8SL++9sS0uDasd2CFdXyM/XsVGFD6HTITvm7QJnqQ7sh/rAfhjrNYAcHm6/fUApWA9wnD7IOh1udC54tB3Xw3FwPXIQt5+ti8zKYUiv/SwAQMrKApDzOEqWu0ee1+Q+oiLu+7IJejSOsi0Vh2bS59B+OgxyzVrI/GMd4O9v65KUhafRaESPHj1Qo0YN+Pj4mK2IVq1aYd68eTAajbh27RrWrl2LDz/8EL/++it+//13aDQarF69Gq+88gpatmyJRYsWoUqVKkhMTMTSpUsxfPhw/Pzzz2arRylRpQqMLaKhXr8O6plfw9jn3khLmlEjIaWn5zyT5Ganz0y6uEA/+9sCZ2nHjIL6wH5kv/kWDG/3snJhyjj8eoDj9EE4u+DC518VOC9gygS4HjmIm6+8gaTXu5um3362Lrw2r0fA1M9xftLMex/mRiMCp0wAAKTVb2zx2h8XjrItPYxm/BhoR42EsfbT0K/5y6anau+nKDzVajWio6Nx7Ngxs4anTqdDQEAAAKB8+fKoXbs26tSpgxdeeAHz589Hly5d0KNHD7Ru3RrLly83va5SpUp4/vnn7eLbXAwzZkLVqB6c+veDatPfEJFRkHbvgnrzJsjh4TCMcbxHPxxRaVgPpaEPBbk8dBTc/tsNv99+guvhA0irl/Mcscf2LXA5eRzZvn64PMh+rnmqVq6A+veVAADp2tWcabt2wqlnzghKwt8Phs8n2ay+4nD0bUm9cAG0o0ZCqNWQ6zeA09fT87WRQ0Jh7BZj9doUn7atXr06Tp8+jUqVKlmiHpNmzZqhZs2a+O233+Dn54cbN25g8ODBBbb19vYu9H30er3pC7sBIDU11dylAsjZy9P/uxea2BFQr1sL/PkHEBgIQ98PYRg+EjDjzgYVrjSsh9LQh4JkRj6B+D+2otysqfDYtunuUHwSsoLK43r3d3Dtvf7IDgiydZkmqrgD0CzMO7i96vRpqE6fBgDIISF2H56Ovi2pzp4BAEhGI5xmTCuwjbFRY5uEpySEEEpesHbtWgwbNgxjxozB008/DbcHDvk9PT0VFRATE4Pk5GSsWLEi37zXX38dBw8eRExMDIYMGYKbN28qPuKNjY3FqFGj8k2/lpSiuFZ7YjDa7tsEzEWjNtvN3vQIjl2yzA6ltUUGeTy8kZ2THHQowPvJsqJIsTupqakILOONlJSiM6LYn16jR49Geno6Wrdujbi4OLRr1w4VKlSAj48PfHx84O3tbdZTuUDOnbySJEFhvucxbNgwpKSkmH4uXLhgxgqJiOhxVOzTtqNGjcK7776LTZs2WbKePI4dO4ZKlSqZ7qQ9fvw46tZV9gC/TqeDTqezRHlERPSYKnZ45h79NW5snbvhNm7ciEOHDqF///6Ijo6Gv78/Jk6cmOeGoVzJyclFXvckIiIyJ0U3DFnqfLxer8fVq1fzPKoyYcIEtG3bFt26dYNarcZ3332HTp06oV27dujXrx/CwsJw48YN/PLLLzh//jyWLFlikdqIiIgepCg8w8PDHxqgN2/eVFzE2rVrERgYCI1GAx8fH9SsWRPTp09H9+7dTYMktG/fHjt27MCECRPQpUsXpKamIjg4GM2aNcPYsWMVL5OIiKikin23rUqlwtSpU/ONMPSg7t27Fznf1lJTU+Hl5cW7be0A77a1D7zb1n7wblvbK+7dtoqOPF9//XWUtfF4gkRERLZW7F3/0rBHREREZA7FDs9HedaSiIioNCn2aVtZdvxrbERERObAOzaIiIgUYngSEREpxPAkIiJSiOFJRESkEMOTiIhIIYYnERGRQgxPIiIihRieRERECjE8iYiIFGJ4EhERKcTwJCIiUojhSUREpBDDk4iISCFFX4ZN9kOjdvz9ntLwNXel4Xtuo8p72roEs7h4846tS3hkFXxdbF3CI1OpHPv/RHHrd/xPYCIiIitjeBIRESnE8CQiIlKI4UlERKQQw5OIiEghhicREZFCDE8iIiKFGJ5EREQKMTyJiIgUYngSEREpxPA0p4sXoen1NnQVg6Bz00EXFgrNgI+AW7dsXVnxOXgfVMt+hdNHfaFt2gjOfl5w0arg1P0tW5elnIOvBwAO0we/Mf9D0CutEfJUVVQO8UWliPIIfqEOfCaNg+pmUp62TqdPwXvGlwjq+CJCnqqKKhW8EPpEKAK6dYLLti026sFDOMh6KJId9kESpWGAUQVSU1Ph5eWFa0kp8PQ035ieUkICtI3qQUpMhLFde4iISEh7dkO9eRPkiAhkbdkO+PmZbXmWYO0+WGLT0z3zFFQH4yDc3SHKV4Aq/jgMb3RF9oKFZl8WYJmxbbktlUxJx7atUsEL+hq1kBUeCaN/WUgZ6XDetxvOB/bBEBCIi39sgaF8BQBAuXe6wWPlr9BHRCHzubqQvX3hlHACbn+tgWQ04vrYSUjp/X6J+2DusW25LSmXmpqKcn5eSEkpOiM4MLyZaPq+DykxEdlTpsPYp69puhg4AJppU6AZ/ikMM2fbsMKHKw19yJ40GaJ8BYiwMKi2boGuRTNbl6RYaVgPjtSH06euQTg755vuO34kfKd9AZ/pX+D659MAABnNWuBW3wHIqlErT1vnHf+g/Gtt4T/6E9xu1wHGcoHWKP2hHGk9FMZe+8AjTzOQEhKgiwyDHBqKrPgEQHXf2fC0NOiCAwEhoL+cCLi5mWWZ5maLPlh601Nt2Qxdi2YOdeTJbankzP2tKtojB1GxWR1kNGqGy0tXP7R90GsvwXXL37gydzHS275comWa88iT21LJFPfIk9c8zUC1eRMAQG4enXflAoCHB+R69SFlZEC1618bVFc8paEPpUFpWA+loQ8A4PbXHwAAfbXqxWovnO6eyFOrLVWSIqVhPdhzHxieZiCdiAcAiPDwAueLsKp3252wWk1KlYY+lAalYT04ah+8Z06F7xdj4T98MMq3aw6/z0dDX60GbvX9+KGv1Vw4D5d/NkN2ccWdug0sX2wxOOp6uJ8994HXPM0hJSXnT0+vgud73Z2ekmyVckqkNPShNCgN68FB++A9cyo01xNNv6c3a4HEaXMg+5cp+oV6Pcq93wMqvR43RoyD7O1j4UqLyUHXQx523AceeRIRATh7+CxOXcvAmUNncGXeT3A6dxbBzetCd3B/4S8yGlGuT0+47N6JtPavIvn9j6xWL9kWw9Mccvd+UlMKnp+79+TlbZVySqQ09KE0KA3rwcH7YCxbDumt2+Pyz6ugvnUTZfv0LqShEeXefxsev/+GtHav4NrM7wELPLpUYg6+HgDYdR8YnmYgwiMAFH7eXTp18m67gs/b24PS0IfSoDSsh9LQBwAwBFdEVngkdPFHoUq6kXdmdjbKvdsdHiuWIq1jZ1ybPR/Q2NdVsNKwHuy5D3YVnjExMXj55ZcLnb9//3506tQJ5cqVg7OzM6pWrYrevXvjhI0veMtNmgIAVBvWAbKcd2ZaGlQ7tkO4ukJ+vo4Nqiue0tCH0qA0rIfS0Idc6qtX7/7lvjtos7IQ0KsrPH7/DamvdcW1r+fazR229ysN68Ge+2BX4VmU1atXo06dOtDr9Vi0aBGOHTuGH3/8EV5eXhg+fLhNaxNVqsDYIhqqs2ehnvl1nnmaUSMhpafD2PUtu32WCigdfSgNSsN6cKQ+OCWchKqgU4KyDN/xI6G5kYg7z9a5dxOQXo/AHp3hvnY1Urp0R+K0b/I/QmEnHGk9FMae+2BXgyTExMQgOTkZK1asyDM9IyMDISEhaNCgAZYvX57vdcnJyfD29i7WMqw2PF9kFKTdu6DevAlyeDiytu5wvGGwLNwHS2x6qpUroP59JQBAunYV6nV/Qa5cGXL9hjnL9PeD4fNJZlueVYbn47ZULCUZJMHrm6/gN34EMp+rh+yKIZB9/KC+fg0uO7fB6dwZGMqWw6Vf/0B2RBQAoOyH78BzyY8w+vkjJaZ3gdc479RrhDv1G5WoDxYfno/b0kMVd5AEhwjP5cuXo2PHjtixYwfq1q2r6D31ej30er3p99TUVAQHB5s9PAEAFy5AEzsC6nVrgaQkIDAQxvYdYBg+EvCxk9vXH8aKfbDEpqcZHQunsaMLnS+HhEB/8ozZlmeJ8ATAbakEShKe2mNH4PnDd3DZtQOaK5ehSkmG7OqG7CphyGjeCsm93ofs42tqX75DS7js+KfI97w58BPcHPQ/xbUA5g9PANyWFCpV4Tlx4kQMGTIEN2/ehI/Cf6jY2FiMGjUq33SLhCcpYkebXolZLDxJMXMPz2cLFglPUqRUDc/3KB+yw4YNQ0pKiunnwoULZqyMiIgeRw4RnuF3b0M+fvy44tfqdDp4enrm+SEiInoUDhGe0dHR8Pf3x8SJEwucn5ycbN2CiIjosWZfT/UCSElJwYEDB/JM8/Pzw3fffYdOnTqhXbt26NevH8LCwnDjxg388ssvOH/+PJYsWWKbgomI6LFjd+G5efNmPPXUU3mm9ezZE9999x127NiBCRMmoEuXLqa7Zps1a4axY8faqFoiInoc2dXdttZgqec8SbnSsOnxblv7wbttyRxK1d22RERE9oThSUREpBDDk4iISCGGJxERkUIMTyIiIoUYnkRERAoxPImIiBRieBIRESnE8CQiIlKI4UlERKQQw5OIiEghhicREZFCDE8iIiKFGJ5EREQKMTyJiIgUYngSEREpxPAkIiJSSGPrAmzFKAsYZWHrMkpMrZJsXcIjMxgd998/l5PG8ddDaVHB18XWJTyyq8mZti7hkQV4O9u6BKvgkScREZFCDE8iIiKFGJ5EREQKMTyJiIgUYngSEREpxPAkIiJSiOFJRESkEMOTiIhIIYYnERGRQgxPIiIihRieZuL0yRA4t2wOlyoV4erlCtcAPzg/VxtOY0cBSUm2Lq/4Ll6Eptfb0FUMgs5NB11YKDQDPgJu3bJ1ZYqoN/0N59c6wi00CO5eLnCrVAEuL7WCeu0fti6teErDemAfrEJ1MwnuC+ehTPfXUP7ZJ1Ax2AcVK5dDQJtmcP9xPiDLedr79+mN0DIuRf6U6/iibTpTGDtcD5IQwvEHGFUgNTUVXl5euHw9GZ6enmZ7X1d3HeSnakOOioIoUxZSejpUu3dB/d9eyEFByNy6EyI42GzLs8TYtlJCArSN6kFKTISxXXuIiEhIe3ZDvXkT5IgIZG3ZDvj5mW152Qb54Y1KQPfJEGinTIJcvgIMLVtB+PlDunEd6v37YGz6AvTjPzfbspw05t//tPZ6sAT2oWRKMratx/xv4TeoHwzlApDZoDEM5YOhvp4ItzUroUpNQXrbl3H9+8WAlPOZ4frH79AePljge7ktXQyns2dwM3Y8Uj/oX6I+mHtsW2uvh9TUVJTz80JKSkqRGcHwNJfMTMA5/0bjNOJTaD+fgOx33kXWjJlmW5wlwtOpdUuo169D9pTpMPbpa5quGTgAmmlTYOj9fzDMnG225VkiPJ2+/xbOH7yL7De7IfPrbwCt9oGFZgNOTuZbngXC09rrwRLYh5IpSXg6/7MZUkY67rR4EVDd2x7V164isGVDaC5dROL3i5HxUoci30eVkowKNSpDMhpx4WACZD9/xbUA5g9Pa68HhmchLBaehVAdjIPLs0/B2Kw5Mv9cZ7b3NXd4SgkJ0EWGQQ4NRVZ8Qp7/hEhLgy44EBAC+suJgJubWZZp9vDU6+FWNQRwdkH64fj8wWkB5g5PW6wHc2MfSs7c36riNWUifMaPRGrPd3HzsylFtvX4dib8PvkYtzt0wo05P5R4meYMT1ush+KGJ695Wph6zSoAgFyjho0rKZpq8yYAgNw8Ou8GCgAeHpDr1YeUkQHVrn9tUF3xqP9eD9X16zC07wCoVFD/uQbaSRPh9NV0qP7daevyiqU0rAf2wX4Ip5xvnRSah3/7pMeP8wAAt7v1tGhNStjzemB4mplm8iQ4jYmFdmB/ODdrBG3sCBhrPImsQUNtXVqRpBPxAAARHl7gfBFW9W67E1arSSn1f3sBAMLZGa51noZrx3bQDR8G50H94da0AVxaNIV0/bqNqyxaaVgP7IOdMBjg/stiAMCdZtFFNtXt+Rfao4eRXaUqMhs0tkZ1xWLP6+Gx/TJsS3Ga+iVU166ZfjdEt4L+u3lAmTI2rKoYUlJy/vT0Kni+193pKclWKackpOuJAJBzs1BUNWRs2AJjzVpQnT0D3bBB0GxYD+eunXFn3UYbV1qEUrAe2Af74DPmf9AeO4KM5q2Q2axFkW3df/geAJD2Vg9rlFZ8drweeORpZnfOX0G6Xkb6+SvI/GUZVGdOw+X52lDt32fr0kq/3FvyNRrc+XUFjPUbAO7ukKvXwJ2ff4NcvgI0/2xxmFO4RCXlMedreM2chqyqEbgxc26RbaXUFLj9vgxCq8Xt19+yUoWOj+FpKeXKwdi+AzLX/AUpKQm6t7vbuqKi5e7BpaYUPD93D9DL2yrllIS4W5tc8ymIkNC8M11dYWiRc+pKvXePdQtTohSsB/bBtjy+mwW/TwciKyIK15avhezjW2R796U/QZWRgfQ27Ut8h63F2PF6YHhamAgJgRxVDaqjR4AbN2xdTqFEeASAwq8dSKdO3m1X8LUHeyDfrU14F3KKx9sHACDduWOtkhQrDeuBfbAdz9kz4DdsALKinsDV5WthLBfw0Nd4LLx7o1D3XpYuTzF7Xg82Dc+YmBhIkoR3330337wPPvgAkiQhJibGNO3q1avo27cvKleuDJ1Oh+DgYLz00kv4+++/rVi1cqorl3P+olbbtpAiyE2aAgBUG9blG5EEaWlQ7dgO4eoK+fk6NqiueIxNXoCQJKiOHcvfBwCqo4cBAHJoqJUrK77SsB7YB9vwnD4JvsMHQ1+9Jq4uXwu5TNmHvkb7325ojxzMuVGofiMrVKmMPa8Hmx95BgcHY8mSJbhz39FAZmYmFi9ejIoVK5qmnT17Fk8//TQ2btyIL774AocOHcLatWvRtGlTfPDBB7Yo3UQ6ceLe6YP7yTKcRnyaMzJG3XqAj4/1iysmUaUKjC2ioTp7FuqZX+eZpxk1ElJ6Ooxd37Lb5/KAnKN8Q5u2UF04D6evpueZp96wDur16yC8vWGIbmWjCh+uVKwH9sHqvL6cAN8xw6GvWRvXfvuj2KdfPXJvFOr2tiXLKzF7Xg82HSQhJiYGycnJSEhIwNChQ9G1a1cAwOLFi/H555+jUqVK8Pb2xvz589G6dWscPHgQ8fHxcHvgHyo5ORne3t7FWqYlBknQTJ8K7fBPINdrADk0FMLPD1LiNai3boXqzGnIAQHIXLsBIqqaWZYHWGl4vsgoSLt3Qb15E+TwcGRt3WH3w/NJFy/CtWkDqC5egKHpC5Br1oJ09gw0q1YCkoTMHxbD0OEVsy3PKsPzWXg9WAL7UDIlGSTBbcmPKNO3N4RajdRe70EUcGeqITgEt9/IezOQlJaK4OqVIRkNuBB3ymzXOy0+PJ+F14NDjDCUG56NGzfGmjVrsGHDBgBA8+bN0bZtW2zevBne3t6YPHky/P39MW7cOAwbNkzRMvR6PfR6ven31NRUBAcHmzU8pSOH4TRnNlQ7tkN16SKQnAy4uUGuGg7ji62R/UE/wLfoi/ZKWSI8AQAXLkATOwLqdWtzBrQPDISxfQcYho80+5Gzpca2la5fh3b8GGjWrIJ09QqEpyeM9Roga9BQyM8+Z9ZlWSI8AVh1PVgM+6BYScLTe+JYeH8xrsg2mfUa4urKvCOcecybA7/BHz7yiEIPMnd4ArDqenCo8Pz2228RHByM+PicB2IjIyNx4cIF9OrVC97e3nj//ffx/PPP47fffkOHDkWPz/ig2NhYjBo1Kt90aw3PZykWC08rslR4WpPFwpMeS+Yens8WLBKeVlTc8LSLQRLKlCmDNm3aYP78+RBCoE2bNvD3v3cK4VHyfdiwYRgwYIDp99wjTyIiopKyi/AEgLfffht9+vQBAHz9dd4Lw1WrVoUkSTh+/Lji99XpdNDpdGapkYiICLCDu21ztWrVCllZWcjOzkbLli3zzPP19UXLli3x9ddfIz09Pd9rk5OTrVQlERGRHYWnWq3GsWPHcPToUagLeB7y66+/htFoxHPPPYdly5bh5MmTOHbsGKZPn466devaoGIiInpc2c1pWwBFXpytXLky9u3bh3HjxuHjjz/GlStXUKZMGTz99NOYNWuWFaskIqLHHb8M20Hxblv7wLttyZx4t63t8cuwiYiILIThSUREpBDDk4iISCGGJxERkUIMTyIiIoUYnkRERAoxPImIiBRieBIRESnE8CQiIlKI4UlERKQQw5OIiEghhicREZFCDE8iIiKFGJ5EREQKMTyJiIgUYngSEREpxPAkIiJSSGPrAmxFrZKgVkm2LuOx5qThvhvR/QK8nW1dwiO7fOuOrUt4JGlpxaufn15EREQKMTyJiIgUYngSEREpxPAkIiJSiOFJRESkEMOTiIhIIYYnERGRQgxPIiIihRieRERECjE8iYiIFGJ4mtPFi9D0ehu6ikHQuemgCwuFZsBHwK1btq6s+NgH+8A+2Af2wSpUN5Pg8eM8lOveGcHPVUdoRV+EVglAUNsX4LFoPiDL+V4j3U6Dz/iRqFCvFkKDfRBSNQgBr7WD89ZNVqlZEkIIqyzJTqSmpsLLywvXklLg6elptveVEhKgbVQPUmIijO3aQ0REQtqzG+rNmyBHRCBry3bAz89sy7ME9sE+sA/2gX0omZKMbesx/1uUGfwhDOUCcKd+YxgqBENz/Rpc1/wOdWoKbrd9GYlzFwFSznjkquRbCHqpObTxx5AVWQ13GjWFlH4bbmvXQJ10A9enzERa15gS1Z+WlopaVQKQklJ0RjA8zcSpdUuo169D9pTpMPbpa5quGTgAmmlTYOj9fzDMnG225VkC+2Af2Af7wD6UTEnC0/mfzVBlpCOjxYuA6t4JUfW1qyjfqhE0ly7i2tzFSH/pZQCA36cD4fXtTKS3aY9r3y4ENDnfcaK6nogK0Q2gupmECzvjYAyqoLgWhmchLBGeUkICdJFhkENDkRWfkGflIy0NuuBAQAjoLycCbm5mWaa5sQ/2gX2wD+xDyZn7W1W8p06E7/hYpPR8F0kTJgMAKj4VDs2li7iwdS+yI6vlae/5zVfwHz4YNwf/D8kDP1G8vOKGJ695moFqc845drl5dN4NFAA8PCDXqw8pIwOqXf/aoLriYR/sA/tgH9gH+yE0Tjl/0dz7Bk114jUAgCGkUr72hpBQAIDLP5stWhfD0wykE/EAABEeXuB8EVb1brsTVqtJKfbBPrAP9oF9sBMGAzyWLgYAZDRtYZps9M25Tqs5fzbfSzTncqY5nbJsvxie5pCSkvOnp1fB873uTk9Jtko5JcI+2Af2wT6wD3bBd8xwaI8dQUbzlrjT7F54ZrRoBQDwmTgWMBpN01U3rsPrmxkAALWF+6V5eBMiIiLr8vx2JrxnTUNW1Qgkfj03z7xbQ4bDddMGuK9aDm2zOrjTsAmkjHS4rV0DQ0AgcPECxIOnqs2MR57mkLsHl5pS8PzcPUAvb6uUUyLsg31gH+wD+2BTnnNnwf/TgciKiMKV3/6E7OObZ76xXCAu/fUPUt7+P0i30+A5bw5c16/F7fav4Np3i3La+JexaI088jQDER4BoPBrB9Kpk3fbFXztwR6wD/aBfbAP7IPt5N4tmxX1BC7/ugZymbIFtjOWLYekz6Yg6bMpeaY7/7MZAKCv9bRF67SrI8+YmBhIkgRJkqDVahEWFobRo0fDYDAAAIQQmDNnDp5//nm4u7vD29sbzzzzDKZOnYqMjAyb1S03aQoAUG1Yl38kjLQ0qHZsh3B1hfx8HRtUVzzsg31gH+wD+2AbXtO/hP/wwdBXfxKXf/uz0OAsiscvOTcY3e74mrnLy8OuwhMAWrVqhStXruDkyZP4+OOPERsbiy+++AIA8NZbb+Gjjz5C+/btsWnTJhw4cADDhw/HypUrsW7dOpvVLKpUgbFFNFRnz0I98+s88zSjRkJKT4ex61t2+zwYwD7YC/bBPrAP1uf95QT4jR0Ofc2ncGXZH5D9/AtvLMuQbt/ON9n9l8Vw/2URMp+tg4zW7SxYrZ0NkhATE4Pk5GSsWLHCNC06OhppaWno378/OnfujBUrVqB9+/Z5XieEMA1+8DBWG54vMgrS7l1Qb94EOTwcWVt3ON5QXuyDTbAP9oF9KJmSDJLgvuRHlO33DoRajdRe70H2yP/ZnF0xBLdffwsAIN2+jZDqobjTqBmyQysDKhWcd++E895dyAqPxJVfV8MYEFSi+h1yhKGCwrN9+/a4ePEiKlSogPj4eBw/flzRe+r1euj1etPvqampCA4ONnt4AgAuXIAmdgTU69YCSUlAYCCM7TvAMHwk4ONj3mVZCvtgH9gH+8A+KFaS8PSZOBY+k8YX2eZOvYa4suKvnF+ys+E/qC+cd+2E5sqlnEmVqiC9/StIeacPhKur4hpyOXx4CiHw999/o23btujbty/WrFmDqlWrYuXKlYreMzY2FqNGjco33SLhSUT0mDP38HzW5rDD861evRru7u5wdnbGiy++iM6dOyM2NhYlzfhhw4YhJSXF9HPhwgUzV0xERI8bu3tUpWnTppg1axa0Wi2CgoKguTueYXh4uOJTtgCg0+mg0+nMXSYRET3G7O7I083NDWFhYahYsaIpOAGgS5cuOHHiRIGnbYUQSEkp5EFgIiIiM7O78CzMa6+9hs6dO+ONN97A+PHjsXfvXpw7dw6rV69G8+bNsWmTdb49nIiIyO5O2xZGkiQsXrwYc+bMwffff49x48ZBo9GgatWq6NatG1q2bGnrEomI6DFhV3fbWoOlnvMkIiLebUtERESFYHgSEREpxPAkIiJSiOFJRESkEMOTiIhIIYYnERGRQgxPIiIihRieRERECjE8iYiIFGJ4EhERKcTwJCIiUojhSUREpBDDk4iISCGGJxERkUIMTyIiIoUYnkRERAppbF2AteV+93daaqqNKyEiKn3S0hz7y7Bvp6UBuJcVhXnswjPt7j9MWKVgG1dCRET2Ki0tDV5eXoXOl8TD4rWUkWUZly9fhoeHByRJssgyUlNTERwcjAsXLsDT09Miy7A09sE+sA/2gX2wD9bogxACaWlpCAoKgkpV+JXNx+7IU6VSoUKFClZZlqenp8NupLnYB/vAPtgH9sE+WLoPRR1x5uINQ0RERAoxPImIiBRieFqATqfDyJEjodPpbF1KibEP9oF9sA/sg32wpz48djcMERERPSoeeRIRESnE8CQiIlKI4UlERKQQw5OIiEghhic9FmRZtnUJRFSKMDwpj4yMDFuXYFaXLl0CgCKH2SIiUoqfKGbk6Ec3//33H5588kmcP3/e1qWYRVxcHCpXrozVq1fbupQSefApstL0VJmj98XR63dkBoMBQggYDAab1sHwfETHjx/Hp59+inPnzllsoHlriIuLQ9OmTfHSSy+hYsWKti7nkcXFxaFu3boYOHAg2rZta+tyFDty5AheeOEF/Pbbb9i3bx8AmLYvR9xJu3TpEpYtW4bJkycjPT3d4f6vXL16FVu3bsWSJUsAwOHqv19uX9auXWvrUhQ7deoUhg8fjnfeeQc7duyw6f8FhucjyM7ORrdu3TBhwgS0aNECgwcPxtKlS/O0MRqNNqqu+A4ePIh69eqhb9++mDJliml6VlaWDasquRMnTqBRo0Z47733MG7cOACOc6SQW+fEiROxefNm7Nu3D2+88QbGjBmDvXv3Arh3CtpR+nT48GG89NJLWLZsGa5fv27rchQ7cuQIOnbsiBkzZuDff//FnTuO+32VR44cQfv27TF58mTMnj0b2dnZti6p2A4dOoRmzZrh9u3bCA8PR/369W17OUbQI5k4caKYPHmyWLdunRg5cqTw8fERb775ppg5c6aQZdnU7v6/25Pz588Lf39/8dprr+WZPmXKFDFw4EBhMBhsVFnJ7N+/X3h6egpJksSUKVNEcnKyrUtSJCsrSwghxIEDB0SjRo3EH3/8If7++29Rp04d0apVK/HSSy+JQ4cOiaSkJCGE/W5XuY4dOyZ8fHzEJ598Iq5fv27rchQ7cuSI8Pb2Fp988ok4e/asrct5JPf35cqVK7YuR5GEhAQRGBgoBg8enGe6Lbd/hucj2rRpk/D09BR79uwRQghx+fJlERsbK1xdXUWdOnXEnDlzRHx8vI2rLNyZM2fEs88+K9q1aye2bdsmhBBiwoQJwtPTU2zatMm2xSm0b98+4eLiIiZOnCjmzJkjJEkS48ePd5gAPXz4sBg9erRISUkR165dE507dxazZ88WQghx69YtcfbsWSFJkqhZs6Zo1qyZ+Ouvv8TFixdtXHXh0tPTRbt27USPHj3yTLf3wM+VnJwsmjRpIt5777080x2l/vvdunVLNGvWTHzwwQd5ptt7X2RZFrIsixEjRogOHTqYdhrtAcPTDAYOHCi6du0q7ty5I4QQonPnziIyMlJ0795dNGrUSDg5OYkvv/zSxlUW7sSJE6JVq1aiXbt2onfv3qJs2bLir7/+snVZily9elVUq1ZNDB061DRt6tSpDhOgBw4cMNWaa/bs2cLHx0dcu3ZNCCFETEyMCA4OFt98843o06ePkCRJdOrUSaSlpdmq7CIlJSWJqKgosXDhwgLnP/jBbW8f5GfPnhVRUVHizz//LHC+vdd/v7Nnz4oqVaqIP/74QxiNxnzz7bl2IYRo0qSJeOuttwqcl9uftLQ002ewNTA8zWDp0qWibt26wmg0ip49e4py5cqJw4cPCyGEOH78uJg2bZrpd3sVHx8vWrRoIVxcXMSkSZNsXY4iV65cEbNmzRK9evUSJ0+ezDNv2rRpdh+gR44cES4uLmLkyJFCiHsfZFlZWeLVV18VP/zwg3jjjTdEuXLlxMGDB02v27hxo0hISLBFycVy+PBhodPpxPr16wttk52dLT7//HORkZFhxcqKZ/369UKSJHHixIlC22RmZooFCxZYsaqS+f3334UkSeLmzZtCCFFggGZkZIg//vjD2qU9VHZ2tqhdu7b48MMPTb8XZPjw4WL37t1Wq4vhaSaNGjUSKpVKBAUFiQMHDti6nBI5deqUiI6OFi+++KL4559/TNPtea80Li5OhISEiFq1agmtVisiIyPFTz/9lKfN/QGakpJio0oLdujQIeHv7y+ioqJM0+7/cBg8eLCQJEmEhYXZ/Q7Yg06dOiWcnZ3F2LFjhRAFb0d//fWXePXVV+3y6HnHjh1CrVaLpUuXCiEKDpxffvlFdOnSxXSt2p6cOXNGrFy5UgiRsxOv0+nEN998U+h9DAsXLhQNGza0ix2ZixcviiVLlogff/xRHDlyRMTGxopy5crl+Wy9f31cuHBBNG/eXOzcudNqNTI8H1HuB8KaNWtEeHi4WL58eZ7pjib3FG7Lli1N10DtVVxcnHB1dRWDBw8Wly5dEqtXrxbNmjUTTz31lDh16lSe/1zTpk0TTk5OYvjw4XYToAcOHBCurq6iSZMmIigoSPTr1880L/fDOC0tTTzzzDNiwIABtiqz2NLT08X169fFxo0bTddiBw4cKNzc3MSOHTuEEPd2DHL/fwwZMkR07dpVpKen26boh6hXr56oXr26uHXrlhBC5Aue/v37iz59+thdeF66dMm0U7ZkyRJhMBhEzZo1xTPPPFPoTtjgwYNFnz59Cj2ys5a4uDhRuXJlUa1aNaFWq0X16tXFG2+8IWrUqCE6dOggjhw5ku81sbGxok6dOiIxMdFqdTI8zeTq1asiLCxM/O9//7N1KY/sxIkTom3btqJOnTpW3ZNTIvcu4U6dOuWZPmfOHOHm5iaOHTsmhMi7E/PZZ58JHx8fcePGDavWWpA9e/YIJycnERsbKwwGg/jmm2+Ev79/ngDV6/UiOztbDBs2TLRt29ZuQr8g8fHxolu3biIyMlI4OzsLT09P0aVLF/HVV1+Jtm3bCg8PD/HXX3+ZQvLChQti6NChokyZMuLo0aM2rl7ku1aWu+O1cuVKUbZsWVG7dm1x7tw50/ykpCTxySefiMDAQHH8+HGr1locmzZtEiqVSjz77LOibdu24vfffxcHDhwQ5cqVE82aNRP//vuvqW1ycrIYMmSIKF++vOn/ja08uEO8atUq0bJlS9GoUSPx1ltvCV9fX9GgQQPx559/iuvXr4tt27aJ9957T3h7e4u4uDir1srwNKOFCxcKNzc3sWvXLluX8siOHTsmXn311TwfGPbk/ruE7z/FvG7dOuHv75/nP9L9R6C513xsbcuWLXmCMjk5ucAAFeLezUQPno62F3FxcSIwMFC8++67Yv78+eLYsWNi0KBBIjIyUkRGRoqRI0eKzp07C0mSxLPPPiueffZZUa9ePVGpUiWxb98+W5cvLl68KDp16iQ2btxompa7zdy5c0fMmzdPhIaGCl9fX/Hqq6+Kjh07iubNm4vy5cvbRf2Fefvtt0WtWrXEK6+8Ipo2bSoWLFgg1q5dKwICAkTZsmVF69atxRtvvCGio6NFUFCQzftS2A7xzJkzha+vr7h8+bL4+uuvxTPPPCMkSRI+Pj4iIiJC1K1b1+rBKQTD06wuXrwomjRpIi5cuGDrUsxCr9fbuoQi5Z5ijo6OFkePHhVpaWmiTJky+Z4FE+LeEag9nk7PrSklJaXQAB04cKBdHKE9KPdIYdiwYflO9y1evFg8//zz4vnnnxc7duwQ8+fPF++++6546623xHfffSfOnDljm6IfkJCQIOrWrSvatGmT51JF7ilavV4vjh8/Lj744APRunVrER0dLcaOHStOnTplq5KLlJmZKYTIuZQUExMj1q5dKzp27CiaNGkili5dKhITE0W/fv1Es2bNRMuWLcWYMWPsoi9F7RB7e3ubjorPnTsn1q9fL+bPny/27NljszNJDE8zs+at0pQToC+++KJo3Lix8PHxER999JFpXkE3eNi7+wP0/uuc9rgjU9CRgizLeUJ09uzZwsvLS8yZM0cIYb/rpLBr/Q9e47SHkCnI+fPnxW+//ZZnWmJiooiMjBRfffWVuHbtmujYsaNo0KCBWLVqlY2qfDglO8S2xvAkh3fixAnRrFkzERISIrZs2WKabo9HmcWRkpIivv32WyFJkl1+aOQq7EhBiLz/9o0aNRIdOnTIN93eFBagsiyLO3fuiI8++kh06tRJZGRk2FU/zp8/L/z8/IQkSaJ169bi559/Ng3M8vvvv4uGDRuKxMREcfToUdGxY0fxwgsvmHZmhLC/deIoO8Qc25YcXtWqVfHNN98gKioK48ePx/bt2wE47uDdnp6e6NSpE+bNm4eePXvaupxChYaGYtGiRcjKysLYsWOxbdu2AtupVCq4uLgAsO91UrVqVUyfPh2SJGHMmDGm7Sg7OxuDBg3CjBkz8Mknn8DFxcWu+iHLMipVqoQ6derg6tWrWL9+PaKjozFnzhzcuXMHXl5e2Lt3L6KiojBmzBhIkoRVq1YhNTUVgP2tk6pVq2LatGlQq9Xw9PREhw4dTPPsqVZJCAcZXZroIU6ePIkBAwbgxo0bmDJlCurUqWPrkh6JEMKuPiwKc/LkSfTr1w9CCAwfPhz169cHkPOhfvnyZbzzzjvo3Lkzunfv7hB9ur8/Q4cOxZ9//okZM2Zg+/bteOqpp2xdXoFOnjyJoUOHQpZldOvWDZIkYdq0afD29sbKlSvx3HPPYevWrdBqtYiPj4ebmxsqVKhg67KLdOrUKfTt2zffdmU3bHjUS2R29n6XcGl1/ynP+0/hDhkyRNSsWdPhbqLLfVzLx8dHaLVa8d9//9m6pIc6fvy4ePHFF0V0dLSIj48Xt2/fFjt37hRt27Y1DZFob6doH8aeH5vjkSeVOllZWdBqtbYu47Fz/xHbhAkTsH79eowZMwbbtm1DzZo1bV2eYvHx8Rg8eDDGjx+PJ554wtblFMvJkyfRp08fAMCIESPs72itBI4fP47hw4fjyy+/tKvvGmZ4EpHZ5J463717N27duoWdO3fi6aeftnVZJZadnQ0nJydbl6HI/Tsx//vf/9CgQQNbl/TI7HGHmDcMEZHZVK1aFZMmTUKdOnWwf/9+hw5OAA4XnMC9G5+cnJwwaNAg/Pvvv7Yu6ZHZW3ACPPIkIgtwxCO20sZeT3eWFgxPIqJSyh5Pd5YWDE8iIiKFeM2TiIhIIYYnERGRQgxPIiIihRieRERECjE8iYiIFGJ4EhERKcTwJHIAMTExePnll02/N2nSBB999JHV69i8eTMkSUJycnKhbSRJwooVK4r9nrGxsahVq9Yj1XX27FlIkoQDBw480vsQFRfDk6iEYmJiIEkSJEmCVqtFWFgYRo8eDYPBYPFl//bbbxgzZkyx2hYn8IhIGY2tCyByZK1atcK8efOg1+vxxx9/4IMPPoCTkxOGDRuWr605R3vx9fU1y/sQUcnwyJPoEeh0OgQEBCAkJATvvfcemjdvjt9//x3AvVOt48aNQ1BQECIiIgAAFy5cwGuvvQZvb2/4+vqiffv2OHv2rOk9jUYjBgwYAG9vb/j5+WHw4MF4cCCwB0/b6vV6DBkyBMHBwdDpdAgLC8PcuXNx9uxZNG3aFADg4+MDSZIQExMDIOfLqidMmIBKlSrBxcUFNWvWxK+//ppnOX/88QfCw8Ph4uKCpk2b5qmzuIYMGYLw8HC4urqicuXKGD58OLKzs/O1++abbxAcHAxXV1e89tprSElJyTP/u+++Q1RUFJydnREZGYmZM2cqroXIXBieRGbk4uKCrKws0+9///034uPjsX79eqxevRrZ2dlo2bIlPDw88M8//2D79u1wd3dHq1atTK/78ssvMX/+fHz//ffYtm0bbt68ieXLlxe53G7duuGnn37C9OnTcezYMXzzzTdwd3dHcHAwli1bBiDn+ymvXLmCadOmAQAmTJiAH374AbNnz8aRI0fQv39/vPnmm9iyZQuAnJDv2LEjXnrpJRw4cAC9evXC0KFDFf+beHh4YP78+Th69CimTZuGb7/9FlOmTMnT5tSpU/jll1+watUqrF27Fvv378f7779vmr9o0SKMGDEC48aNw7FjxzB+/HgMHz4cCxYsUFwPkVnY5Cu4iUqB7t27i/bt2wshhJBlWaxfv17odDoxcOBA0/xy5coJvV5ves3ChQtFRESEkGXZNE2v1wsXFxfx119/CSGECAwMFBMnTjTNz87OFhUqVDAtSwghGjduLD788EMhhBDx8fECgFi/fn2BdW7atEkAELdu3TJNy8zMFK6urmLHjh152vbs2VO88cYbQgghhg0bJqpVq5Zn/pAhQ/K914MAiOXLlxc6/4svvhBPP/206feRI0cKtVotLl68aJr2559/CpVKJa5cuSKEEKJKlSpi8eLFed5nzJgxom7dukIIIc6cOSMAiP379xe6XCJz4jVPokewevVquLu7Izs7G7Iso0uXLoiNjTXNr1GjRp7rnHFxcTh16hQ8PDzyvE9mZiYSEhKQkpKCK1eu4PnnnzfN02g0eOaZZ/Kdus114MABqNVqNG7cuNh1nzp1ChkZGWjRokWe6VlZWXjqqacAAMeOHctTBwDUrVu32MvI9fPPP2P69OlISEjA7du3YTAY4OnpmadNxYoVUb58+TzLkWUZ8fHx8PDwQEJCAnr27InevXub2hgMBnh5eSmuh8gcGJ5Ej6Bp06aYNWsWtFotgoKCoNHk/S/l5uaW5/fbt2/j6aefxqJFi/K9V5kyZUpUg4uLi+LX3L59GwCwZs2aPKEF5FzHNZedO3eia9euGDVqFFq2bAkvLy8sWbIEX375peJav/3223xhrlarzVYrkRIMT6JH4ObmhrCwsGK3r127Nn7++WeULVs239FXrsDAQOzatQuNGjUCkHOE9d9//6F27doFtq9RowZkWcaWLVvQvHnzfPNzj3yNRqNpWrVq1aDT6XD+/PlCj1ijoqJMNz/l+vfffx/eyfvs2LEDISEh+PTTT03Tzp07l6/d+fPncfnyZQQFBZmWo1KpEBERgXLlyiEoKAinT59G165dFS2fyFJ4wxCRFXXt2hX+/v5o3749/vnnH5w5cwabN29Gv379cPHiRQDAhx9+iM8++wwrVqzA8ePH8f777xf5jGZoaCi6d++Ot99+GytWrDC95y+//AIACAkJgSRJWL16Na5fv47bt2/Dw8MDAwcORP/+/bFgwQIkJCRg3759mDFjhukmnHfffRcnT57EoEGDEB8fj8WLF2P+/PmK+lu1alWcP38eS5YsQUJCAqZPn17gzU/Ozs7o3r074uLi8M8//6Bfv3547bXXEBAQAAAYNWoUJkyYgOnTp+PEiRM4dOgQ5s2bh8mTJyuqh8hcGJ5EVuTq6oqtW7eiYsWK6NixI6KiotCzZ09kZmaajkQ//vhjvPXWW+jevTvq1q0LDw8PdOjQocj3nTVrFl599VW8//77iIyMRO/evZGeng4AKF++PEaNGoWhQ4eiXLly6NOnDwBgzJgxGD58OCZMmICoqCi0atUKa9asQaVKlQDkXIdctmwZVqxYgZo1a2L27NkYP368ov62a9cO/fv3R58+fVCrVi3s2LEDw4cPz9cuLCwMHTt2ROvWrREdHY0nn3wyz6MovXr1wnfffYd58+ahRo0aaNy4MebPn2+qlcjaJFHYXQhERERUIB55EhERKcTwJCIiUojhSUREpBDDk4iISCGGJxERkUIMTyIiIoUYnkRERAoxPImIiBRieBIRESnE8CQiIlKI4UlERKTQ/wPpkK7iSUy0aAAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"code","source":"# import tensorflow_hub as hub\n# from keras.models import load_model\n# from sklearn.metrics import classification_report, confusion_matrix\n# import numpy as np\n\n# # Define your custom object\n# custom_obj = {'DefConvLayer_red': DefConvLayer_red}\n\n# # Define function to load saved model with custom objects\n# def load_saved_model_with_custom_objects(model_path, custom_objects):\n#     model = load_model(model_path, custom_objects=custom_objects)\n#     return model\n\n# # List of model names\n# model_names = [\n#     '40_+34.h5', '40_+20.h5', '40_+04.h5', '40_+69.h5', '40_+25.h5',\n#     '40_+01.h5', '40_+55.h5', '40_+17.h5', '40_+48.h5', '40_+23.h5',\n#     '40_+81.h5', '40_+14.h5', '40_+52.h5', '40_+40.h5', '40_+82.h5',\n#     '40_+27.h5', '40_+05.h5'\n# ]\n\n# # Load and evaluate each model\n# for i, model_name in enumerate(model_names, start=1):\n#     model_path = f'/kaggle/working/{model_name}'  # Update the path according to your model directory\n#     model = load_saved_model_with_custom_objects(model_path, custom_obj)  # Load the model\n#     results = model.evaluate(test_gen)  # Evaluate the model on the test generator\n#     print(f'Model {i} - Test loss and accuracy: {results}')\n    \n#     # Make predictions\n#     predictions = model.predict(test_gen)\n#     rounded_pred = np.argmax(predictions, axis=-1)\n    \n#     # Calculate confusion matrix\n#     cm = confusion_matrix(y_true=test_gen.classes, y_pred=rounded_pred)\n    \n#     # Plot confusion matrix\n#     cm_plot_labels = ['A','F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n#     plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title=f'Confusion Matrix - Model {i}')\n    \n#     # Print classification report\n#     print(f'Classification Report - Model {i}:')\n#     print(classification_report(y_true=test_gen.classes, y_pred=rounded_pred, target_names=cm_plot_labels))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:35:46.408293Z","iopub.execute_input":"2024-04-28T16:35:46.408785Z","iopub.status.idle":"2024-04-28T16:35:46.415668Z","shell.execute_reply.started":"2024-04-28T16:35:46.408759Z","shell.execute_reply":"2024-04-28T16:35:46.414508Z"},"trusted":true},"execution_count":26,"outputs":[]}]}