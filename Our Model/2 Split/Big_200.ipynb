{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8146556,
          "sourceType": "datasetVersion",
          "datasetId": 4817492
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 8158384,
          "datasetId": 4826407
        }
      ],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"tensorflow>=1.7.0\"\n",
        "!pip install tensorflow-addons\n",
        "!pip install tensorflow-hub\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vq5qLS4d2LmQ",
        "outputId": "8e54c750-6ed3-41f2-edf5-e68c07c39a91",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow>=1.7.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.7.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.2.2)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (3.20.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (2.15.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.2.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, utils\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "vmaszhvR2LmY",
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(f\"tensorflow version: {tf.__version__}\")\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ht481_PZ2LmZ",
        "outputId": "79a3ea08-f0db-45e3-dc1d-fa24cf7e1ab1",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "import statistics\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Dense, DepthwiseConv2D,AveragePooling2D, Concatenate, Dropout, Permute,Reshape,Lambda,Activation, Add,Multiply, MaxPooling2D, Conv2D, Flatten, BatchNormalization, GlobalAveragePooling2D,LayerNormalization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16,ConvNeXtTiny,ResNet50, MobileNet, Xception, EfficientNetB0 , DenseNet169, DenseNet201, DenseNet121, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import gc\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from functools import partial\n",
        "from collections import Counter\n",
        "from statistics import mean\n",
        "\n",
        "from keras.models import load_model\n",
        "#from keras.models import Sequential\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "o91Tp0x_sHTl",
        "trusted": true
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION, tf.config.list_physical_devices()"
      ],
      "metadata": {
        "id": "N-4YPF2w26ll",
        "outputId": "d957a6ef-1bf5-4297-c618-e4b77c5ee3d9",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.15.0',\n",
              " [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              "  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = '/content/drive/MyDrive/Breast Cancer Project/IW/200/A'\n",
        "F = '/content/drive/MyDrive/Breast Cancer Project/IW/200/F'\n",
        "PT ='/content/drive/MyDrive/Breast Cancer Project/IW/200/PT'\n",
        "TA ='/content/drive/MyDrive/Breast Cancer Project/IW/200/TA'\n",
        "DC ='/content/drive/MyDrive/Breast Cancer Project/IW/200/DC'\n",
        "LC ='/content/drive/MyDrive/Breast Cancer Project/IW/200/LC'\n",
        "MC ='/content/drive/MyDrive/Breast Cancer Project/IW/200/MC'\n",
        "PC ='/content/drive/MyDrive/Breast Cancer Project/IW/200/PC'"
      ],
      "metadata": {
        "id": "4EWX3Gd8r32a",
        "trusted": true
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirlist=[A, F, PT, TA, DC, LC, MC, PC]\n",
        "classes=['A','F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n",
        "filepaths=[]\n",
        "labels=[]\n",
        "for i,j in zip(dirlist, classes):\n",
        "    filelist=os.listdir(i)\n",
        "    for f in filelist:\n",
        "        filepath=os.path.join (i,f)\n",
        "        filepaths.append(filepath)\n",
        "        labels.append(j)\n",
        "print ('filepaths: ', len(filepaths), '   labels: ', len(labels))"
      ],
      "metadata": {
        "id": "QNZkBeucr9Mh",
        "outputId": "61d38675-abec-47aa-aea7-728af6c3b700",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepaths:  2013    labels:  2013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Files=pd.Series(filepaths, name='filepaths')\n",
        "Label=pd.Series(labels, name='labels')\n",
        "df=pd.concat([Files,Label], axis=1)\n",
        "df=pd.DataFrame(np.array(df).reshape(len(filepaths),2), columns = ['filepaths', 'labels'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QVgOHhygsAlZ",
        "outputId": "783a7a18-3ded-466f-b2ca-2711d9f734a4",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           filepaths labels\n",
              "0  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "1  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "2  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "3  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "4  /content/drive/MyDrive/Breast Cancer Project/I...      A"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ff7ad7c-c159-487e-8b5e-331a320e088e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepaths</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ff7ad7c-c159-487e-8b5e-331a320e088e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ff7ad7c-c159-487e-8b5e-331a320e088e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ff7ad7c-c159-487e-8b5e-331a320e088e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a8dc11d-7230-46d0-9d4e-4fef6f33c729\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a8dc11d-7230-46d0-9d4e-4fef6f33c729')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a8dc11d-7230-46d0-9d4e-4fef6f33c729 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2013,\n  \"fields\": [\n    {\n      \"column\": \"filepaths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2013,\n        \"samples\": [\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/200/DC/SOB_M_DC-14-17901-200-004.png\",\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/200/TA/SOB_B_TA-14-19854C-200-015.png\",\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/200/PT/SOB_B_PT-14-22704-200-035.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"F\",\n          \"LC\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['labels'].value_counts())"
      ],
      "metadata": {
        "id": "1uQkt3MTsD_o",
        "outputId": "92c2ca3c-26d2-4fce-bd63-71d5ec5b83e1",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels\n",
            "DC    896\n",
            "F     264\n",
            "MC    196\n",
            "LC    163\n",
            "TA    140\n",
            "PC    135\n",
            "A     111\n",
            "PT    108\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, train_size=0.70)\n",
        "#train_new, valid = train_test_split(train, train_size=0.90, random_state=0)\n",
        "\n",
        "print(f\"train set shape: {train.shape}\")\n",
        "print(f\"test set shape: {test.shape}\")\n",
        "print(f\"validation set shape: {test.shape}\")"
      ],
      "metadata": {
        "id": "pfI-lh99sGr7",
        "outputId": "c5748593-11e9-4f4b-b5c6-29dc7bda7a02",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set shape: (1409, 2)\n",
            "test set shape: (604, 2)\n",
            "validation set shape: (604, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train = '/content/drive/MyDrive/fold5/40/train'\n",
        "# test = '/content/drive/MyDrive/fold5/40/test'"
      ],
      "metadata": {
        "id": "G5LJCbZ2IooS",
        "trusted": true
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)"
      ],
      "metadata": {
        "id": "BF_mNPBOsQPL",
        "trusted": true
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tand get the number os devices.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(dataframe=train,\n",
        "                                              x_col = 'filepaths', y_col ='labels',\n",
        "                                              target_size = (224,224), batch_size = 4 * strategy.num_replicas_in_sync,\n",
        "                                              class_mode = 'categorical', shuffle = True)\n",
        "\n",
        "val_gen = test_datagen.flow_from_dataframe(test,\n",
        "                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n",
        "                                             class_mode = 'categorical',\n",
        "                                            batch_size = 4 * strategy.num_replicas_in_sync, shuffle = False)\n",
        "\n",
        "\n",
        "test_gen = test_datagen.flow_from_dataframe(test,\n",
        "                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n",
        "                                             class_mode = 'categorical',\n",
        "                                            batch_size = 4, shuffle = False)"
      ],
      "metadata": {
        "id": "4Gl5R4EJsRbN",
        "outputId": "dd3241dc-8be7-472f-f474-fbba0eb149d6",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICES AVAILABLE: 1\n",
            "Found 1409 validated image filenames belonging to 8 classes.\n",
            "Found 604 validated image filenames belonging to 8 classes.\n",
            "Found 604 validated image filenames belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "\n",
        "def plotmodel(history,name):\n",
        "\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.plot(epochs,smooth_curve(acc))\n",
        "    plt.plot(epochs,smooth_curve(val_acc))\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
        "    #plt.savefig('acc_'+name+'_'+mag+'_'+fold+'.png')\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.plot(epochs,smooth_curve(loss))\n",
        "    plt.plot(epochs,smooth_curve(val_loss))\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "   # plt.savefig('loss_'+name+'_'+mag+'_'+fold+'.png')\n",
        "\n",
        "def label_smooth(y_true, y_pred):\n",
        "    y_true=((1-0.1)*y_true+0.05)\n",
        "    return K.categorical_crossentropy(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "CJBdug_F2Lmc",
        "trusted": true
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    #plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 3.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"green\" if cm[i, j] > thresh else \"red\", fontdict={'fontsize':'x-large'})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "LeIVRsgY2Lmc",
        "trusted": true
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DefConv_full(input, filters, kernel_size, strides=1):\n",
        "    \"\"\"\n",
        "    Using DefConv_reduced to implement full DC layer.\n",
        "    \"\"\"\n",
        "    offsets = layers.Conv2D(filters=2 * kernel_size ** 2,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=strides,\n",
        "                            padding='same',\n",
        "                            kernel_initializer='random_normal'\n",
        "                            )(input)\n",
        "    X = DefConvLayer_red(filters=filters,\n",
        "                         kernel_size=kernel_size,\n",
        "                         strides=strides\n",
        "                         )(input, offsets)\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "class DefConvLayer_red(Layer):\n",
        "\n",
        "    def __init__(self, filters,strides, kernel_size=3, **kwargs):\n",
        "        assert type(kernel_size) == int, \"expect kernel_size to be of type 'int'\"\n",
        "        assert type(strides) == int, \"expect strides to be of type int\"\n",
        "        self.N = kernel_size ** 2\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "\n",
        "        super(DefConvLayer_red, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], self.N, self.filters),\n",
        "                                 # Wdc is of shape [n_C=input_channels, lxl=N, filters=output_channels]\n",
        "                                 initializer='RandomNormal',\n",
        "                                 dtype='float32',\n",
        "                                 trainable=True)\n",
        "\n",
        "    def call(self, input, offsets):\n",
        "        # input of shape: (m=batch_size, n_H, n_W, n_C)\n",
        "        # offsets of shape: (m, n_H, n_W, 2*N)\n",
        "        # m, n_H, n_W, n_C = input.shape\n",
        "        # offsets = super(DefConvLayer, self).call(input) # Conv2D to learn offsets (m, n_H, n_W, 2*N)\n",
        "\n",
        "        input_offsets = self.BLIN(input, offsets)  # (m, n_H, n_W, n_C, N)\n",
        "        # BLIN returns N interpolated values of input at the offsets, for each spatial pixel\n",
        "        # replicate the offset input to each of the output channels\n",
        "        input_offsets = tf.expand_dims(input_offsets, axis=-1)\n",
        "        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, 1, self.filters])  # (m, n_H, n_W, n_C, N, filters)\n",
        "\n",
        "        new_shape = (1, 1, 1,) + self.W.shape\n",
        "        W = tf.reshape(self.W, shape=new_shape)  # (1, 1, 1, n_C, N, filters) to be broadcastable to input_offsets\n",
        "\n",
        "        output = tf.multiply(input_offsets, W)  # (m, n_H, n_W, n_C, N, filters)\n",
        "        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, n_C, filters) reduce along each channel kernel\n",
        "        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, filters) reduce along input channels\n",
        "        return output\n",
        "\n",
        "    @tf.function\n",
        "    def BLIN(self, input, offsets_in):  # Bi-Linear Interpolation of input feature map values at offset locations\n",
        "        \"\"\"\n",
        "        'input' shape: (m, n_Hi, n_Wi, n_C)\n",
        "        'offsets_in' shape: (m, n_Ho, n_Wo, 2*N)\n",
        "        'offsets_in' is the output of the Conv2D layer step aimed at learning the offsets,\n",
        "                     possibly smaller spatial size than input's, if strides>1\n",
        "        \"\"\"\n",
        "        offsets = offsets_in\n",
        "        m    = tf.shape(input)[0]\n",
        "        n_Hi = tf.shape(input)[1]\n",
        "        n_Wi = tf.shape(input)[2]\n",
        "        n_C  = tf.shape(input)[3]\n",
        "\n",
        "        n_Ho = tf.shape(offsets)[1] # also the output spatial shape\n",
        "        n_Wo = tf.shape(offsets)[2]\n",
        "        N    = tf.shape(offsets)[3] // 2\n",
        "\n",
        "        # expand the input into (m, n_Hi, n_Wi, n_C, N). this will also be the output shape of this function\n",
        "        input_offsets = tf.expand_dims(input, axis=-1) # (m, n_Hi, n_Wi, n_C, N, 1)\n",
        "        # replicate N times, to be compatible with the kernel operation later\n",
        "        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, N])  # (m, n_Hi, n_Wi, n_C, N)\n",
        "\n",
        "        # the offset metrices will be replicated n_C times: same (spatial) offsets for each of the input *channels*.\n",
        "        offsets = tf.reshape(offsets, (m, n_Ho, n_Wo, 1, N, 2))  # (m, n_Ho, n_Wo, 1, N, 2) add a \"channel\" axis\n",
        "        offsets = tf.tile(offsets, [1, 1, 1, n_C, 1, 1])  # (m, n_Ho, n_Wo, n_C, N, 2) replicate for each of the input channels\n",
        "\n",
        "        # construct a full index grid to be applied onto \"input_offsets\" of size (m, n_H, n_W, n_C, N)\n",
        "        (grid_m, grid_i, grid_j, grid_c, grid_N) = tf.meshgrid(tf.range(m), tf.range(n_Hi),\n",
        "                                                               tf.range(n_Wi), tf.range(n_C), tf.range(N),\n",
        "                                                               indexing='ij')  # (m, n_Hi, n_Wi, n_C, N) a list of 5 metrices with index-like values\n",
        "\n",
        "        # adjust indices to 'strides' down-sample, and\n",
        "        # unroll indices to fit into tf.gather_nd later. (unroll offsets also)\n",
        "        ur_grid_m = tf.reshape(grid_m[:, ::self.strides, ::self.strides, :, :], [-1])  # (m*n_Ho*n_Wo*n_C*N, 1); integers\n",
        "        ur_grid_i = tf.reshape(grid_i[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_j = tf.reshape(grid_j[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_c = tf.reshape(grid_c[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_N = tf.reshape(grid_N[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_offsets = tf.reshape(offsets, (-1, 2))  # (m*n_Ho*n_Wo*n_C*N, 2) both i, j\n",
        "\n",
        "        # spatial indices will be adjusted using 'offsets'\n",
        "        coords_i = tf.cast(ur_grid_i, dtype='float32') + ur_offsets[..., 0]\n",
        "        coords_j = tf.cast(ur_grid_j, dtype='float32') + ur_offsets[..., 1]\n",
        "\n",
        "        # Need to think further on how to handle edges,\n",
        "        # perhaps assume outside of index values can be zeros instead of hard-clipping.\n",
        "        coords_i = tf.clip_by_value(coords_i, 0, tf.cast(n_Hi, dtype='float32')-1)\n",
        "        coords_j = tf.clip_by_value(coords_j, 0, tf.cast(n_Wi, dtype='float32')-1)\n",
        "        coords_2d = tf.stack([coords_i, coords_j], axis=-1)  # (m*n_Ho*n_Wo*n_C*N, 2); float32\n",
        "\n",
        "        # generate top and bottom, left and right, nearest \"real\" indices\n",
        "        # assuming coords represents (p,q) values where i<=p<=i+1, and j<=q<=j+1:\n",
        "        # shape: (m*n_Ho*n_Wo*n_C*N, 2)\n",
        "        # note the coordinates themselves (values in coords) are [i,j] within [0:n_Hi-1, 0:n_Wi] range\n",
        "        coords_lt = tf.cast(tf.math.floor(coords_2d), dtype='int32')  # nearest (i,j)\n",
        "        coords_rb = tf.cast(tf.math.ceil(coords_2d), dtype='int32')  # nearest (i+1, j+1)\n",
        "\n",
        "        coords_lb = tf.stack((coords_rb[..., 0], coords_lt[..., 1]), axis=-1)  # nearest (i+1, j)\n",
        "        coords_rt = tf.stack((coords_lt[..., 0], coords_rb[..., 1]), axis=-1)  # nearest (i, j+1)\n",
        "\n",
        "        # use the replicated input tensor \"input_offsets\" which holds the input values, to get these values at the specific locations:\n",
        "        # these type of Tensors doesn't allow for conversion into numpy-like arrays. to use tf.gather_nd, need to unroll indices\n",
        "        # unroll all grid tensors to be used with tf.gather_nd()\n",
        "\n",
        "        indices_lt = tf.stack([ur_grid_m, coords_lt[..., 0], coords_lt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_rb = tf.stack([ur_grid_m, coords_rb[..., 0], coords_rb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_lb = tf.stack([ur_grid_m, coords_lb[..., 0], coords_lb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_rt = tf.stack([ur_grid_m, coords_rt[..., 0], coords_rt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "\n",
        "        vals_lt = tf.gather_nd(input_offsets, indices_lt)\n",
        "        vals_rb = tf.gather_nd(input_offsets, indices_rb)\n",
        "        vals_lb = tf.gather_nd(input_offsets, indices_lb)\n",
        "        vals_rt = tf.gather_nd(input_offsets, indices_rt)\n",
        "\n",
        "        # calculate the offset from the left-top (i,j) position\n",
        "        ur_coords_offset_lt = coords_2d - tf.cast(coords_lt, dtype='float32')  # (m*n_Ho*n_Wo*n_C*N, 2)\n",
        "\n",
        "        # first linear interpolation (m*n_H*n_W*n_C*N)\n",
        "        vals_t = vals_lt + (vals_rt - vals_lt) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), top\n",
        "        vals_b = vals_lb + (vals_rb - vals_lb) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), bottom\n",
        "\n",
        "        # second linear interpolation\n",
        "        input_offsets = vals_t + (vals_b - vals_t) * ur_coords_offset_lt[..., 0]  # along the i axis (n_Hi)\n",
        "\n",
        "        # reshape back to output shape\n",
        "        input_offsets = tf.reshape(input_offsets, (m, n_Ho, n_Wo, n_C, N))\n",
        "\n",
        "        return input_offsets"
      ],
      "metadata": {
        "id": "hwUptDC7WJHS",
        "trusted": true
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def train_model(model, train_gen, val_gen, test_gen, mag, image_size, save_name, lr1, lr2, Epochs1, Epochs2):\n",
        "    from keras.callbacks import ModelCheckpoint\n",
        "    from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "    lr_decay = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
        "    save_model = ModelCheckpoint('/content/drive/MyDrive/200+{epoch:02d}.h5',\n",
        "                                 monitor='val_accuracy',\n",
        "                                 period=5,\n",
        "                                 save_best_only=True)\n",
        "\n",
        "    # List of model names\n",
        "    model_names = ['200epoch+01.h5', '200epoch+06.h5', '200epoch+16.h5', '200epoch+31.h5', '200epoch+36.h5', '200epoch+51.h5', '200epoch+61.h5', '200epoch+76.h5', '200epoch+91.h5']\n",
        "\n",
        "    # List to store loaded models\n",
        "    loaded_models = []\n",
        "\n",
        "    custom_objects = {\n",
        "        'DefConvLayer_red': DefConvLayer_red  # Assuming 'DefConvLayer_red' is a custom layer\n",
        "    }\n",
        "\n",
        "    # Load models in a loop\n",
        "    for model_name in model_names:\n",
        "        # Construct the full path to the model file\n",
        "        model_path = '/content/drive/MyDrive/Epochs/200/' + model_name\n",
        "\n",
        "        # Load the model and append it to the list\n",
        "        model = load_model(model_path, custom_objects=custom_objects)\n",
        "        loaded_models.append(model)\n",
        "\n",
        "        # Evaluate the loaded model\n",
        "        results = model.evaluate(test_gen)\n",
        "        print('Test loss and accuracy for model', model_name, ':', results)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(test_gen)\n",
        "        rounded_pred = np.argmax(predictions, axis=-1)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        cm = confusion_matrix(y_true=test_gen.classes, y_pred=rounded_pred)\n",
        "        cm_plot_labels = ['A', 'F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n",
        "        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix for model ' + model_name)\n",
        "\n",
        "        # Print classification report\n",
        "        print('Classification report for model', model_name, ':')\n",
        "        print(classification_report(y_true=test_gen.classes, y_pred=rounded_pred, target_names=cm_plot_labels))\n",
        "\n",
        "    # Return something meaningful, e.g., history\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "mDj2Er1H2Lmf",
        "trusted": true
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/leondgarse/keras_cv_attention_models"
      ],
      "metadata": {
        "id": "COIWAnOotVGZ",
        "outputId": "fe295557-4df4-4e21-b4d7-407a1301db37",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/leondgarse/keras_cv_attention_models\n",
            "  Cloning https://github.com/leondgarse/keras_cv_attention_models to /tmp/pip-req-build-kir7azd0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/leondgarse/keras_cv_attention_models /tmp/pip-req-build-kir7azd0\n",
            "  Resolved https://github.com/leondgarse/keras_cv_attention_models to commit 5bbbc792effde7d5d94c01b7c15625d9db109aa6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (4.66.2)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (6.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (2023.12.25)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (4.9.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (2.15.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->keras-cv-attention-models==1.4.2) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.5.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-cv-attention-models==1.4.2) (0.43.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2024.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_cv_attention_models import maxvit\n",
        "mm = maxvit.MaxViT_Tiny(input_shape=(224, 224, 3), pretrained=\"imagenet\")\n",
        "# mm.summary()"
      ],
      "metadata": {
        "id": "fLq_Narsto20",
        "outputId": "6b1cdf11-2f53-4a37-c8df-bf1416bed686",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Load pretrained from: /root/.keras/models/maxvit_tiny_224_imagenet.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def SSA(inputs,fltr):\n",
        "    shape=K.int_shape(inputs)\n",
        "    li=q=k=v=Conv2D(fltr,1,padding='same',activation='relu')(inputs)\n",
        "    print(\"Shape of Input of SSA\", inputs)\n",
        "    Qshape=K.int_shape(q)\n",
        "    Kshape= K.int_shape(k)\n",
        "    Vshape= K.int_shape(v)\n",
        "    a=Qshape[1]*Qshape[2]\n",
        "    q=Reshape((a,Qshape[3]))(q)\n",
        "    k=Reshape((a,Kshape[3]))(k)\n",
        "    k=Permute((2,1))(k)\n",
        "    qk=tf.matmul(q,k)\n",
        "    qk=Activation('softmax')(qk)\n",
        "    v=Reshape((a,Vshape[3]))(v)\n",
        "    qkv=tf.matmul(qk,v)\n",
        "    print(qkv.shape)\n",
        "    qkv=Reshape((Vshape[1],Vshape[2],Vshape[3]))(qkv)\n",
        "    qkv = Conv2D(shape[3], 1, strides=1, padding='same', activation='relu')(qkv)\n",
        "    print(\"Shape of Output of SSA\", qkv)\n",
        "    return qkv"
      ],
      "metadata": {
        "id": "gfdo3wQDgQWF",
        "trusted": true
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def CDSA(input,fltr,nh):\n",
        "    attn = []\n",
        "    print(\"Shape of CDSA Input\", input.shape)\n",
        "    feature_split = tf.split(input, num_or_size_splits= num_splits, axis=3)\n",
        "    print(feature_split[0].shape)\n",
        "    shape=K.int_shape(feature_split[0])\n",
        "    x = SSA(feature_split[0],fltr)\n",
        "    attn.append(x)\n",
        "    for i in range(1,nh):\n",
        "        x = Add()([feature_split[i],x])\n",
        "        x = SSA(x,fltr)\n",
        "        attn.append(x)\n",
        "    mh_lka_attn = Add()(attn)\n",
        "    mh_lka_attn = Conv2D(fltr,1, strides=1, padding='same', activation='relu')(mh_lka_attn)\n",
        "    print(\"Shape of CDSA Output\", mh_lka_attn.shape)\n",
        "    return mh_lka_attn\n"
      ],
      "metadata": {
        "id": "NVDzywSVfVX_",
        "trusted": true
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CAL(input,fltr,nh):\n",
        "    print(\"Shape of CAL Input\", input.shape)\n",
        "    x = DefConv_full(input, fltr, kernel_size=3)\n",
        "    rs1 = x = Add()([x,input])\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = CDSA(x,fltr,nh)\n",
        "    rs2 = x = Add()([rs1,x])\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = Conv2D(fltr, 1, padding='same', activation='relu')(x)\n",
        "    x = Add()([rs2,x])\n",
        "    print(\"Shape of CAL Output\", x.shape)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "PKnsju-la_cg",
        "trusted": true
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fun= 'categorical_crossentropy'\n",
        "gpu_num=2\n",
        "k=5\n",
        "lr1=0.005\n",
        "lr2=0.0001\n",
        "image_size=224\n",
        "classes=8\n",
        "ratio=8\n",
        "fltr=256\n",
        "nh=2  # number of splits\n",
        "mag='40'"
      ],
      "metadata": {
        "id": "uQqoWozCTBhK",
        "trusted": true
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "\n",
        "input_image = Input(shape=(224, 224, 3))\n",
        "mn_input = input_image\n",
        "\n",
        "# Load the model\n",
        "base_model = maxvit.MaxViT_Tiny(input_shape=(224, 224, 3), pretrained=\"imagenet\")\n",
        "new_base_model = Model(inputs=base_model.input, outputs=base_model.get_layer('stack_3_block_5/grid_ffn_output').output)\n",
        "mn_output = new_base_model(mn_input)\n",
        "print(mn_output.shape)\n",
        "\n",
        "mn_output = Conv2D(fltr, 1, padding='same', activation='relu')(mn_output)\n",
        "print(mn_output.shape)\n",
        "mn_output = BatchNormalization()(mn_output)  # Add Batch Normalization\n",
        "mn_output = Dropout(0.5)(mn_output)\n",
        "num_splits = 2\n",
        "CAL_out = CAL(mn_output,fltr,nh)\n",
        "print(CAL_out.shape)\n",
        "CAL_out = GlobalAveragePooling2D()(CAL_out)\n",
        "out=Dense(classes,activation='softmax')(CAL_out)\n",
        "if gpu_num<1:\n",
        "    model=Model(inputs=input_image, outputs=out)\n",
        "    #model.summary()\n",
        "    parallel_model = multi_gpu_model(model, gpus=gpu_num)\n",
        "    parallel_model.summary()\n",
        "else:\n",
        "    parallel_model=Model(inputs=input_image, outputs=out)\n",
        "    parallel_model.summary()"
      ],
      "metadata": {
        "id": "i--5bFDwR9fx",
        "outputId": "899c4329-8313-4b87-a518-2255e8baec00",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Load pretrained from: /root/.keras/models/maxvit_tiny_224_imagenet.h5\n",
            "(None, 14, 14, 256)\n",
            "(None, 14, 14, 256)\n",
            "Shape of CAL Input (None, 14, 14, 256)\n",
            "Shape of CDSA Input (None, 14, 14, 256)\n",
            "(None, 14, 14, 128)\n",
            "Shape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='tf.split_89/split:0', description=\"created by layer 'tf.split_89'\")\n",
            "(None, 196, 256)\n",
            "Shape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='conv2d_11/Relu:0', description=\"created by layer 'conv2d_11'\")\n",
            "Shape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='add_6/add:0', description=\"created by layer 'add_6'\")\n",
            "(None, 196, 256)\n",
            "Shape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='conv2d_13/Relu:0', description=\"created by layer 'conv2d_13'\")\n",
            "Shape of CDSA Output (None, 14, 14, 256)\n",
            "Shape of CAL Output (None, 14, 14, 256)\n",
            "(None, 14, 14, 256)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " model_2 (Functional)        (None, 14, 14, 256)          1263885   ['input_5[0][0]']             \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 14, 14, 256)          65792     ['model_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 14, 14, 256)          1024      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 14, 14, 256)          0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 14, 14, 18)           41490     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " def_conv_layer_red_1 (DefC  (None, 14, 14, 256)          589824    ['dropout_1[0][0]',           \n",
            " onvLayer_red)                                                       'conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 14, 14, 256)          0         ['def_conv_layer_red_1[0][0]',\n",
            "                                                                     'dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 14, 14, 256)          512       ['add_5[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.split_89 (TFOpLambda)    [(None, 14, 14, 128),        0         ['layer_normalization_2[0][0]'\n",
            "                              (None, 14, 14, 128)]                  ]                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 256)          33024     ['tf.split_89[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_273 (Reshape)       (None, 196, 256)             0         ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_272 (Reshape)       (None, 196, 256)             0         ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " permute_2 (Permute)         (None, 256, 196)             0         ['reshape_273[0][0]']         \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_180 (TFOp  (None, 196, 196)             0         ['reshape_272[0][0]',         \n",
            " Lambda)                                                             'permute_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_180[0][0]']\n",
            "                                                                                                  \n",
            " reshape_274 (Reshape)       (None, 196, 256)             0         ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_181 (TFOp  (None, 196, 256)             0         ['activation_2[0][0]',        \n",
            " Lambda)                                                             'reshape_274[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_275 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_181[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 128)          32896     ['reshape_275[0][0]']         \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 14, 14, 128)          0         ['tf.split_89[0][1]',         \n",
            "                                                                     'conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 256)          33024     ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " reshape_277 (Reshape)       (None, 196, 256)             0         ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_276 (Reshape)       (None, 196, 256)             0         ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " permute_3 (Permute)         (None, 256, 196)             0         ['reshape_277[0][0]']         \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_182 (TFOp  (None, 196, 196)             0         ['reshape_276[0][0]',         \n",
            " Lambda)                                                             'permute_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_182[0][0]']\n",
            "                                                                                                  \n",
            " reshape_278 (Reshape)       (None, 196, 256)             0         ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_183 (TFOp  (None, 196, 256)             0         ['activation_3[0][0]',        \n",
            " Lambda)                                                             'reshape_278[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_279 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_183[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 14, 14, 128)          32896     ['reshape_279[0][0]']         \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 14, 14, 128)          0         ['conv2d_11[0][0]',           \n",
            "                                                                     'conv2d_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 14, 14, 256)          33024     ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 14, 14, 256)          0         ['add_5[0][0]',               \n",
            "                                                                     'conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 14, 14, 256)          512       ['add_8[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 14, 14, 256)          65792     ['layer_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 14, 14, 256)          0         ['add_8[0][0]',               \n",
            "                                                                     'conv2d_15[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 256)                  0         ['add_9[0][0]']               \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 8)                    2056      ['global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13570722 (51.77 MB)\n",
            "Trainable params: 13540514 (51.65 MB)\n",
            "Non-trainable params: 30208 (118.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(parallel_model,train_gen,val_gen,test_gen,mag,image_size,'maxvit',lr1,lr2,4,100)"
      ],
      "metadata": {
        "id": "_6LvLQM-S6Vp",
        "outputId": "8d33a75a-00af-445f-85ab-1cc061363b19",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151/151 [==============================] - 240s 2s/step - loss: 1.3148 - acc: 0.5927\n",
            "Test loss and accuracy for model 200epoch+01.h5 : [1.314810872077942, 0.5927152037620544]\n",
            "151/151 [==============================] - 67s 402ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[  1  22   8   1   1   0   0   0]\n",
            " [  0 233   7  20   0   0   0   0]\n",
            " [  0   8  72   1   0   1   0   0]\n",
            " [  0  21   2  30   0   0   0   0]\n",
            " [  0  50  10   2   9   0   0   0]\n",
            " [  0  18   6   1   0   8   0   0]\n",
            " [  0   3  24   0   0   3   2   0]\n",
            " [  0  12  23   2   0   0   0   3]]\n",
            "Classification report for model 200epoch+01.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      0.03      0.06        33\n",
            "           F       0.63      0.90      0.74       260\n",
            "          PT       0.47      0.88      0.62        82\n",
            "          TA       0.53      0.57      0.55        53\n",
            "          DC       0.90      0.13      0.22        71\n",
            "          LC       0.67      0.24      0.36        33\n",
            "          MC       1.00      0.06      0.12        32\n",
            "          PC       1.00      0.07      0.14        40\n",
            "\n",
            "    accuracy                           0.59       604\n",
            "   macro avg       0.78      0.36      0.35       604\n",
            "weighted avg       0.70      0.59      0.52       604\n",
            "\n",
            "151/151 [==============================] - 69s 418ms/step - loss: 0.5950 - acc: 0.7964\n",
            "Test loss and accuracy for model 200epoch+06.h5 : [0.5950199961662292, 0.7963576316833496]\n",
            "151/151 [==============================] - 67s 397ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  1 234   3   3   0  19   0   0]\n",
            " [  5   0  67   0   2   8   0   0]\n",
            " [  1  32   1  12   2   5   0   0]\n",
            " [  0  18   0   0  47   6   0   0]\n",
            " [  0   0   0   0   1  32   0   0]\n",
            " [  1   1   6   0   0   2  22   0]\n",
            " [  0   0   1   0   3   2   0  34]]\n",
            "Classification report for model 200epoch+06.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.80      1.00      0.89        33\n",
            "           F       0.82      0.90      0.86       260\n",
            "          PT       0.86      0.82      0.84        82\n",
            "          TA       0.80      0.23      0.35        53\n",
            "          DC       0.85      0.66      0.75        71\n",
            "          LC       0.43      0.97      0.60        33\n",
            "          MC       1.00      0.69      0.81        32\n",
            "          PC       1.00      0.85      0.92        40\n",
            "\n",
            "    accuracy                           0.80       604\n",
            "   macro avg       0.82      0.76      0.75       604\n",
            "weighted avg       0.83      0.80      0.79       604\n",
            "\n",
            "151/151 [==============================] - 69s 416ms/step - loss: 0.2644 - acc: 0.9040\n",
            "Test loss and accuracy for model 200epoch+16.h5 : [0.2644025683403015, 0.9039735198020935]\n",
            "151/151 [==============================] - 68s 405ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 32   0   0   0   1   0   0   0]\n",
            " [  0 229   7  13   3   6   2   0]\n",
            " [  0   0  79   0   0   3   0   0]\n",
            " [  0   3   1  45   1   3   0   0]\n",
            " [  0   1   1   2  64   3   0   0]\n",
            " [  0   0   2   0   0  31   0   0]\n",
            " [  0   0   2   0   0   0  30   0]\n",
            " [  0   0   2   0   1   1   0  36]]\n",
            "Classification report for model 200epoch+16.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      0.97      0.98        33\n",
            "           F       0.98      0.88      0.93       260\n",
            "          PT       0.84      0.96      0.90        82\n",
            "          TA       0.75      0.85      0.80        53\n",
            "          DC       0.91      0.90      0.91        71\n",
            "          LC       0.66      0.94      0.78        33\n",
            "          MC       0.94      0.94      0.94        32\n",
            "          PC       1.00      0.90      0.95        40\n",
            "\n",
            "    accuracy                           0.90       604\n",
            "   macro avg       0.89      0.92      0.90       604\n",
            "weighted avg       0.92      0.90      0.91       604\n",
            "\n",
            "151/151 [==============================] - 70s 427ms/step - loss: 0.2304 - acc: 0.9305\n",
            "Test loss and accuracy for model 200epoch+31.h5 : [0.2303508222103119, 0.9304635524749756]\n",
            "151/151 [==============================] - 67s 401ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0 249   0   5   5   1   0   0]\n",
            " [  2   0  78   0   2   0   0   0]\n",
            " [  3   8   0  40   1   1   0   0]\n",
            " [  0   1   0   0  70   0   0   0]\n",
            " [  0   1   0   0   1  31   0   0]\n",
            " [  1   0   4   0   0   0  27   0]\n",
            " [  0   0   0   0   6   0   0  34]]\n",
            "Classification report for model 200epoch+31.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.85      1.00      0.92        33\n",
            "           F       0.96      0.96      0.96       260\n",
            "          PT       0.95      0.95      0.95        82\n",
            "          TA       0.89      0.75      0.82        53\n",
            "          DC       0.82      0.99      0.90        71\n",
            "          LC       0.94      0.94      0.94        33\n",
            "          MC       1.00      0.84      0.92        32\n",
            "          PC       1.00      0.85      0.92        40\n",
            "\n",
            "    accuracy                           0.93       604\n",
            "   macro avg       0.93      0.91      0.91       604\n",
            "weighted avg       0.93      0.93      0.93       604\n",
            "\n",
            "151/151 [==============================] - 68s 413ms/step - loss: 0.1202 - acc: 0.9570\n",
            "Test loss and accuracy for model 200epoch+36.h5 : [0.12016897648572922, 0.9569536447525024]\n",
            "151/151 [==============================] - 68s 403ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0 257   0   3   0   0   0   0]\n",
            " [  0   1  75   0   1   1   4   0]\n",
            " [  0   7   0  46   0   0   0   0]\n",
            " [  1   2   0   0  66   2   0   0]\n",
            " [  0   0   0   0   0  33   0   0]\n",
            " [  0   0   1   0   0   0  31   0]\n",
            " [  0   1   1   0   1   0   0  37]]\n",
            "Classification report for model 200epoch+36.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.97      1.00      0.99        33\n",
            "           F       0.96      0.99      0.97       260\n",
            "          PT       0.97      0.91      0.94        82\n",
            "          TA       0.94      0.87      0.90        53\n",
            "          DC       0.97      0.93      0.95        71\n",
            "          LC       0.92      1.00      0.96        33\n",
            "          MC       0.89      0.97      0.93        32\n",
            "          PC       1.00      0.93      0.96        40\n",
            "\n",
            "    accuracy                           0.96       604\n",
            "   macro avg       0.95      0.95      0.95       604\n",
            "weighted avg       0.96      0.96      0.96       604\n",
            "\n",
            "151/151 [==============================] - 69s 415ms/step - loss: 0.1085 - acc: 0.9636\n",
            "Test loss and accuracy for model 200epoch+51.h5 : [0.1084594577550888, 0.9635761380195618]\n",
            "151/151 [==============================] - 70s 404ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0 251   1   8   0   0   0   0]\n",
            " [  0   0  82   0   0   0   0   0]\n",
            " [  0   6   0  47   0   0   0   0]\n",
            " [  0   3   0   2  66   0   0   0]\n",
            " [  0   0   0   0   0  33   0   0]\n",
            " [  0   0   1   0   0   0  31   0]\n",
            " [  0   0   1   0   0   0   0  39]]\n",
            "Classification report for model 200epoch+51.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00        33\n",
            "           F       0.97      0.97      0.97       260\n",
            "          PT       0.96      1.00      0.98        82\n",
            "          TA       0.82      0.89      0.85        53\n",
            "          DC       1.00      0.93      0.96        71\n",
            "          LC       1.00      1.00      1.00        33\n",
            "          MC       1.00      0.97      0.98        32\n",
            "          PC       1.00      0.97      0.99        40\n",
            "\n",
            "    accuracy                           0.96       604\n",
            "   macro avg       0.97      0.97      0.97       604\n",
            "weighted avg       0.96      0.96      0.96       604\n",
            "\n",
            "151/151 [==============================] - 70s 417ms/step - loss: 0.0504 - acc: 0.9801\n",
            "Test loss and accuracy for model 200epoch+61.h5 : [0.05041233077645302, 0.9801324605941772]\n",
            "151/151 [==============================] - 68s 401ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0 258   0   1   0   0   1   0]\n",
            " [  0   0  82   0   0   0   0   0]\n",
            " [  0   6   0  47   0   0   0   0]\n",
            " [  0   2   0   0  68   0   0   1]\n",
            " [  0   0   0   0   1  32   0   0]\n",
            " [  0   0   0   0   0   0  32   0]\n",
            " [  0   0   0   0   0   0   0  40]]\n",
            "Classification report for model 200epoch+61.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00        33\n",
            "           F       0.97      0.99      0.98       260\n",
            "          PT       1.00      1.00      1.00        82\n",
            "          TA       0.98      0.89      0.93        53\n",
            "          DC       0.99      0.96      0.97        71\n",
            "          LC       1.00      0.97      0.98        33\n",
            "          MC       0.97      1.00      0.98        32\n",
            "          PC       0.98      1.00      0.99        40\n",
            "\n",
            "    accuracy                           0.98       604\n",
            "   macro avg       0.98      0.98      0.98       604\n",
            "weighted avg       0.98      0.98      0.98       604\n",
            "\n",
            "151/151 [==============================] - 70s 419ms/step - loss: 0.0871 - acc: 0.9801\n",
            "Test loss and accuracy for model 200epoch+76.h5 : [0.08706540614366531, 0.9801324605941772]\n",
            "151/151 [==============================] - 68s 411ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0 260   0   0   0   0   0   0]\n",
            " [  0   0  81   0   0   0   1   0]\n",
            " [  0   7   0  46   0   0   0   0]\n",
            " [  0   4   0   0  67   0   0   0]\n",
            " [  0   0   0   0   0  33   0   0]\n",
            " [  0   0   0   0   0   0  32   0]\n",
            " [  0   0   0   0   0   0   0  40]]\n",
            "Classification report for model 200epoch+76.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00        33\n",
            "           F       0.96      1.00      0.98       260\n",
            "          PT       1.00      0.99      0.99        82\n",
            "          TA       1.00      0.87      0.93        53\n",
            "          DC       1.00      0.94      0.97        71\n",
            "          LC       1.00      1.00      1.00        33\n",
            "          MC       0.97      1.00      0.98        32\n",
            "          PC       1.00      1.00      1.00        40\n",
            "\n",
            "    accuracy                           0.98       604\n",
            "   macro avg       0.99      0.97      0.98       604\n",
            "weighted avg       0.98      0.98      0.98       604\n",
            "\n",
            "151/151 [==============================] - 70s 419ms/step - loss: 0.0550 - acc: 0.9868\n",
            "Test loss and accuracy for model 200epoch+91.h5 : [0.05498785525560379, 0.9867549538612366]\n",
            "151/151 [==============================] - 68s 410ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0 260   0   0   0   0   0   0]\n",
            " [  0   0  82   0   0   0   0   0]\n",
            " [  0   5   0  48   0   0   0   0]\n",
            " [  1   2   0   0  68   0   0   0]\n",
            " [  0   0   0   0   0  33   0   0]\n",
            " [  0   0   0   0   0   0  32   0]\n",
            " [  0   0   0   0   0   0   0  40]]\n",
            "Classification report for model 200epoch+91.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.97      1.00      0.99        33\n",
            "           F       0.97      1.00      0.99       260\n",
            "          PT       1.00      1.00      1.00        82\n",
            "          TA       1.00      0.91      0.95        53\n",
            "          DC       1.00      0.96      0.98        71\n",
            "          LC       1.00      1.00      1.00        33\n",
            "          MC       1.00      1.00      1.00        32\n",
            "          PC       1.00      1.00      1.00        40\n",
            "\n",
            "    accuracy                           0.99       604\n",
            "   macro avg       0.99      0.98      0.99       604\n",
            "weighted avg       0.99      0.99      0.99       604\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-3edca79327a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'maxvit'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-0466fb2b0e23>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_gen, val_gen, test_gen, mag, image_size, save_name, lr1, lr2, Epochs1, Epochs2)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Return something meaningful, e.g., history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}