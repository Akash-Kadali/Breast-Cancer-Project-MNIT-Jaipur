{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8146556,
          "sourceType": "datasetVersion",
          "datasetId": 4817492
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 8158384,
          "datasetId": 4826407
        }
      ],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"tensorflow>=1.7.0\"\n",
        "!pip install tensorflow-addons\n",
        "!pip install tensorflow-hub\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vq5qLS4d2LmQ",
        "outputId": "101fa287-5fe4-45b1-d228-5e78d7dcf95c",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow>=1.7.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.7.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.2.2)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (3.20.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (2.15.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.2.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, utils\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "vmaszhvR2LmY",
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(f\"tensorflow version: {tf.__version__}\")\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ht481_PZ2LmZ",
        "outputId": "09672c1d-1309-450e-9623-16cca8cbe3ab",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "import statistics\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Dense, DepthwiseConv2D,AveragePooling2D, Concatenate, Dropout, Permute,Reshape,Lambda,Activation, Add,Multiply, MaxPooling2D, Conv2D, Flatten, BatchNormalization, GlobalAveragePooling2D,LayerNormalization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16,ConvNeXtTiny,ResNet50, MobileNet, Xception, EfficientNetB0 , DenseNet169, DenseNet201, DenseNet121, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import gc\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from functools import partial\n",
        "from collections import Counter\n",
        "from statistics import mean\n",
        "\n",
        "from keras.models import load_model\n",
        "#from keras.models import Sequential\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "o91Tp0x_sHTl",
        "trusted": true
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION, tf.config.list_physical_devices()"
      ],
      "metadata": {
        "id": "N-4YPF2w26ll",
        "outputId": "d510a19c-8417-400c-b863-fa4bbfb217b9",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.15.0',\n",
              " [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              "  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = '/content/drive/MyDrive/Breast Cancer Project/IW/400/A'\n",
        "F = '/content/drive/MyDrive/Breast Cancer Project/IW/400/F'\n",
        "PT ='/content/drive/MyDrive/Breast Cancer Project/IW/400/PT'\n",
        "TA ='/content/drive/MyDrive/Breast Cancer Project/IW/400/TA'\n",
        "DC ='/content/drive/MyDrive/Breast Cancer Project/IW/400/DC'\n",
        "LC ='/content/drive/MyDrive/Breast Cancer Project/IW/400/LC'\n",
        "MC ='/content/drive/MyDrive/Breast Cancer Project/IW/400/MC'\n",
        "PC ='/content/drive/MyDrive/Breast Cancer Project/IW/400/PC'"
      ],
      "metadata": {
        "id": "4EWX3Gd8r32a",
        "trusted": true
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirlist=[A, F, PT, TA, DC, LC, MC, PC]\n",
        "classes=['A','F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n",
        "filepaths=[]\n",
        "labels=[]\n",
        "for i,j in zip(dirlist, classes):\n",
        "    filelist=os.listdir(i)\n",
        "    for f in filelist:\n",
        "        filepath=os.path.join (i,f)\n",
        "        filepaths.append(filepath)\n",
        "        labels.append(j)\n",
        "print ('filepaths: ', len(filepaths), '   labels: ', len(labels))"
      ],
      "metadata": {
        "id": "QNZkBeucr9Mh",
        "outputId": "736eab6e-b89f-4ac0-b234-3e859361ff92",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepaths:  1820    labels:  1820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Files=pd.Series(filepaths, name='filepaths')\n",
        "Label=pd.Series(labels, name='labels')\n",
        "df=pd.concat([Files,Label], axis=1)\n",
        "df=pd.DataFrame(np.array(df).reshape(len(filepaths),2), columns = ['filepaths', 'labels'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QVgOHhygsAlZ",
        "outputId": "26c694b2-32dc-47a5-a4f2-2e7e2395ac05",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           filepaths labels\n",
              "0  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "1  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "2  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "3  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "4  /content/drive/MyDrive/Breast Cancer Project/I...      A"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06ed2227-6c45-4d61-86eb-e8552bbb589b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepaths</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06ed2227-6c45-4d61-86eb-e8552bbb589b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06ed2227-6c45-4d61-86eb-e8552bbb589b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06ed2227-6c45-4d61-86eb-e8552bbb589b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-79c7322f-e789-4329-9c05-9f3768982aff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79c7322f-e789-4329-9c05-9f3768982aff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-79c7322f-e789-4329-9c05-9f3768982aff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1820,\n  \"fields\": [\n    {\n      \"column\": \"filepaths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1820,\n        \"samples\": [\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/400/LC/SOB_M_LC-14-12204-400-028.png\",\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/400/DC/SOB_M_DC-14-18650-400-002.png\",\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/400/F/SOB_B_F-14-21998CD-400-016.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"F\",\n          \"LC\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['labels'].value_counts())"
      ],
      "metadata": {
        "id": "1uQkt3MTsD_o",
        "outputId": "6eab44cf-470b-4171-af48-a7d4802155da",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels\n",
            "DC    788\n",
            "F     237\n",
            "MC    169\n",
            "PC    138\n",
            "LC    137\n",
            "TA    130\n",
            "PT    115\n",
            "A     106\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, train_size=0.70)\n",
        "#train_new, valid = train_test_split(train, train_size=0.90, random_state=0)\n",
        "\n",
        "print(f\"train set shape: {train.shape}\")\n",
        "print(f\"test set shape: {test.shape}\")\n",
        "print(f\"validation set shape: {test.shape}\")"
      ],
      "metadata": {
        "id": "pfI-lh99sGr7",
        "outputId": "87720e5d-188b-49ad-d1eb-58ea72fc57cb",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set shape: (1274, 2)\n",
            "test set shape: (546, 2)\n",
            "validation set shape: (546, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train = '/content/drive/MyDrive/fold5/40/train'\n",
        "# test = '/content/drive/MyDrive/fold5/40/test'"
      ],
      "metadata": {
        "id": "G5LJCbZ2IooS",
        "trusted": true
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)"
      ],
      "metadata": {
        "id": "BF_mNPBOsQPL",
        "trusted": true
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tand get the number os devices.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(dataframe=train,\n",
        "                                              x_col = 'filepaths', y_col ='labels',\n",
        "                                              target_size = (224,224), batch_size = 4 * strategy.num_replicas_in_sync,\n",
        "                                              class_mode = 'categorical', shuffle = True)\n",
        "\n",
        "val_gen = test_datagen.flow_from_dataframe(test,\n",
        "                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n",
        "                                             class_mode = 'categorical',\n",
        "                                            batch_size = 4 * strategy.num_replicas_in_sync, shuffle = False)\n",
        "\n",
        "\n",
        "test_gen = test_datagen.flow_from_dataframe(test,\n",
        "                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n",
        "                                             class_mode = 'categorical',\n",
        "                                            batch_size = 4, shuffle = False)"
      ],
      "metadata": {
        "id": "4Gl5R4EJsRbN",
        "outputId": "15ad17c4-0d02-4134-c7eb-306624a6a874",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICES AVAILABLE: 1\n",
            "Found 1274 validated image filenames belonging to 8 classes.\n",
            "Found 546 validated image filenames belonging to 8 classes.\n",
            "Found 546 validated image filenames belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "\n",
        "def plotmodel(history,name):\n",
        "\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.plot(epochs,smooth_curve(acc))\n",
        "    plt.plot(epochs,smooth_curve(val_acc))\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
        "    #plt.savefig('acc_'+name+'_'+mag+'_'+fold+'.png')\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.plot(epochs,smooth_curve(loss))\n",
        "    plt.plot(epochs,smooth_curve(val_loss))\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "   # plt.savefig('loss_'+name+'_'+mag+'_'+fold+'.png')\n",
        "\n",
        "def label_smooth(y_true, y_pred):\n",
        "    y_true=((1-0.1)*y_true+0.05)\n",
        "    return K.categorical_crossentropy(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "CJBdug_F2Lmc",
        "trusted": true
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    #plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 3.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"green\" if cm[i, j] > thresh else \"red\", fontdict={'fontsize':'x-large'})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "LeIVRsgY2Lmc",
        "trusted": true
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DefConv_full(input, filters, kernel_size, strides=1):\n",
        "    \"\"\"\n",
        "    Using DefConv_reduced to implement full DC layer.\n",
        "    \"\"\"\n",
        "    offsets = layers.Conv2D(filters=2 * kernel_size ** 2,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=strides,\n",
        "                            padding='same',\n",
        "                            kernel_initializer='random_normal'\n",
        "                            )(input)\n",
        "    X = DefConvLayer_red(filters=filters,\n",
        "                         kernel_size=kernel_size,\n",
        "                         strides=strides\n",
        "                         )(input, offsets)\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "class DefConvLayer_red(Layer):\n",
        "\n",
        "    def __init__(self, filters,strides, kernel_size=3, **kwargs):\n",
        "        assert type(kernel_size) == int, \"expect kernel_size to be of type 'int'\"\n",
        "        assert type(strides) == int, \"expect strides to be of type int\"\n",
        "        self.N = kernel_size ** 2\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "\n",
        "        super(DefConvLayer_red, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], self.N, self.filters),\n",
        "                                 # Wdc is of shape [n_C=input_channels, lxl=N, filters=output_channels]\n",
        "                                 initializer='RandomNormal',\n",
        "                                 dtype='float32',\n",
        "                                 trainable=True)\n",
        "\n",
        "    def call(self, input, offsets):\n",
        "        # input of shape: (m=batch_size, n_H, n_W, n_C)\n",
        "        # offsets of shape: (m, n_H, n_W, 2*N)\n",
        "        # m, n_H, n_W, n_C = input.shape\n",
        "        # offsets = super(DefConvLayer, self).call(input) # Conv2D to learn offsets (m, n_H, n_W, 2*N)\n",
        "\n",
        "        input_offsets = self.BLIN(input, offsets)  # (m, n_H, n_W, n_C, N)\n",
        "        # BLIN returns N interpolated values of input at the offsets, for each spatial pixel\n",
        "        # replicate the offset input to each of the output channels\n",
        "        input_offsets = tf.expand_dims(input_offsets, axis=-1)\n",
        "        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, 1, self.filters])  # (m, n_H, n_W, n_C, N, filters)\n",
        "\n",
        "        new_shape = (1, 1, 1,) + self.W.shape\n",
        "        W = tf.reshape(self.W, shape=new_shape)  # (1, 1, 1, n_C, N, filters) to be broadcastable to input_offsets\n",
        "\n",
        "        output = tf.multiply(input_offsets, W)  # (m, n_H, n_W, n_C, N, filters)\n",
        "        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, n_C, filters) reduce along each channel kernel\n",
        "        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, filters) reduce along input channels\n",
        "        return output\n",
        "\n",
        "    @tf.function\n",
        "    def BLIN(self, input, offsets_in):  # Bi-Linear Interpolation of input feature map values at offset locations\n",
        "        \"\"\"\n",
        "        'input' shape: (m, n_Hi, n_Wi, n_C)\n",
        "        'offsets_in' shape: (m, n_Ho, n_Wo, 2*N)\n",
        "        'offsets_in' is the output of the Conv2D layer step aimed at learning the offsets,\n",
        "                     possibly smaller spatial size than input's, if strides>1\n",
        "        \"\"\"\n",
        "        offsets = offsets_in\n",
        "        m    = tf.shape(input)[0]\n",
        "        n_Hi = tf.shape(input)[1]\n",
        "        n_Wi = tf.shape(input)[2]\n",
        "        n_C  = tf.shape(input)[3]\n",
        "\n",
        "        n_Ho = tf.shape(offsets)[1] # also the output spatial shape\n",
        "        n_Wo = tf.shape(offsets)[2]\n",
        "        N    = tf.shape(offsets)[3] // 2\n",
        "\n",
        "        # expand the input into (m, n_Hi, n_Wi, n_C, N). this will also be the output shape of this function\n",
        "        input_offsets = tf.expand_dims(input, axis=-1) # (m, n_Hi, n_Wi, n_C, N, 1)\n",
        "        # replicate N times, to be compatible with the kernel operation later\n",
        "        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, N])  # (m, n_Hi, n_Wi, n_C, N)\n",
        "\n",
        "        # the offset metrices will be replicated n_C times: same (spatial) offsets for each of the input *channels*.\n",
        "        offsets = tf.reshape(offsets, (m, n_Ho, n_Wo, 1, N, 2))  # (m, n_Ho, n_Wo, 1, N, 2) add a \"channel\" axis\n",
        "        offsets = tf.tile(offsets, [1, 1, 1, n_C, 1, 1])  # (m, n_Ho, n_Wo, n_C, N, 2) replicate for each of the input channels\n",
        "\n",
        "        # construct a full index grid to be applied onto \"input_offsets\" of size (m, n_H, n_W, n_C, N)\n",
        "        (grid_m, grid_i, grid_j, grid_c, grid_N) = tf.meshgrid(tf.range(m), tf.range(n_Hi),\n",
        "                                                               tf.range(n_Wi), tf.range(n_C), tf.range(N),\n",
        "                                                               indexing='ij')  # (m, n_Hi, n_Wi, n_C, N) a list of 5 metrices with index-like values\n",
        "\n",
        "        # adjust indices to 'strides' down-sample, and\n",
        "        # unroll indices to fit into tf.gather_nd later. (unroll offsets also)\n",
        "        ur_grid_m = tf.reshape(grid_m[:, ::self.strides, ::self.strides, :, :], [-1])  # (m*n_Ho*n_Wo*n_C*N, 1); integers\n",
        "        ur_grid_i = tf.reshape(grid_i[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_j = tf.reshape(grid_j[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_c = tf.reshape(grid_c[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_N = tf.reshape(grid_N[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_offsets = tf.reshape(offsets, (-1, 2))  # (m*n_Ho*n_Wo*n_C*N, 2) both i, j\n",
        "\n",
        "        # spatial indices will be adjusted using 'offsets'\n",
        "        coords_i = tf.cast(ur_grid_i, dtype='float32') + ur_offsets[..., 0]\n",
        "        coords_j = tf.cast(ur_grid_j, dtype='float32') + ur_offsets[..., 1]\n",
        "\n",
        "        # Need to think further on how to handle edges,\n",
        "        # perhaps assume outside of index values can be zeros instead of hard-clipping.\n",
        "        coords_i = tf.clip_by_value(coords_i, 0, tf.cast(n_Hi, dtype='float32')-1)\n",
        "        coords_j = tf.clip_by_value(coords_j, 0, tf.cast(n_Wi, dtype='float32')-1)\n",
        "        coords_2d = tf.stack([coords_i, coords_j], axis=-1)  # (m*n_Ho*n_Wo*n_C*N, 2); float32\n",
        "\n",
        "        # generate top and bottom, left and right, nearest \"real\" indices\n",
        "        # assuming coords represents (p,q) values where i<=p<=i+1, and j<=q<=j+1:\n",
        "        # shape: (m*n_Ho*n_Wo*n_C*N, 2)\n",
        "        # note the coordinates themselves (values in coords) are [i,j] within [0:n_Hi-1, 0:n_Wi] range\n",
        "        coords_lt = tf.cast(tf.math.floor(coords_2d), dtype='int32')  # nearest (i,j)\n",
        "        coords_rb = tf.cast(tf.math.ceil(coords_2d), dtype='int32')  # nearest (i+1, j+1)\n",
        "\n",
        "        coords_lb = tf.stack((coords_rb[..., 0], coords_lt[..., 1]), axis=-1)  # nearest (i+1, j)\n",
        "        coords_rt = tf.stack((coords_lt[..., 0], coords_rb[..., 1]), axis=-1)  # nearest (i, j+1)\n",
        "\n",
        "        # use the replicated input tensor \"input_offsets\" which holds the input values, to get these values at the specific locations:\n",
        "        # these type of Tensors doesn't allow for conversion into numpy-like arrays. to use tf.gather_nd, need to unroll indices\n",
        "        # unroll all grid tensors to be used with tf.gather_nd()\n",
        "\n",
        "        indices_lt = tf.stack([ur_grid_m, coords_lt[..., 0], coords_lt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_rb = tf.stack([ur_grid_m, coords_rb[..., 0], coords_rb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_lb = tf.stack([ur_grid_m, coords_lb[..., 0], coords_lb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_rt = tf.stack([ur_grid_m, coords_rt[..., 0], coords_rt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "\n",
        "        vals_lt = tf.gather_nd(input_offsets, indices_lt)\n",
        "        vals_rb = tf.gather_nd(input_offsets, indices_rb)\n",
        "        vals_lb = tf.gather_nd(input_offsets, indices_lb)\n",
        "        vals_rt = tf.gather_nd(input_offsets, indices_rt)\n",
        "\n",
        "        # calculate the offset from the left-top (i,j) position\n",
        "        ur_coords_offset_lt = coords_2d - tf.cast(coords_lt, dtype='float32')  # (m*n_Ho*n_Wo*n_C*N, 2)\n",
        "\n",
        "        # first linear interpolation (m*n_H*n_W*n_C*N)\n",
        "        vals_t = vals_lt + (vals_rt - vals_lt) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), top\n",
        "        vals_b = vals_lb + (vals_rb - vals_lb) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), bottom\n",
        "\n",
        "        # second linear interpolation\n",
        "        input_offsets = vals_t + (vals_b - vals_t) * ur_coords_offset_lt[..., 0]  # along the i axis (n_Hi)\n",
        "\n",
        "        # reshape back to output shape\n",
        "        input_offsets = tf.reshape(input_offsets, (m, n_Ho, n_Wo, n_C, N))\n",
        "\n",
        "        return input_offsets"
      ],
      "metadata": {
        "id": "hwUptDC7WJHS",
        "trusted": true
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def train_model(model, train_gen, val_gen, test_gen, mag, image_size, save_name, lr1, lr2, Epochs1, Epochs2):\n",
        "    from keras.callbacks import ModelCheckpoint\n",
        "    from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "    lr_decay = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
        "    save_model = ModelCheckpoint('/content/drive/MyDrive/200+{epoch:02d}.h5',\n",
        "                                 monitor='val_accuracy',\n",
        "                                 period=5,\n",
        "                                 save_best_only=True)\n",
        "\n",
        "    # List of model names\n",
        "    model_names = ['400epoch+01.h5', '400epoch+06.h5', '400epoch+16.h5', '400epoch+21.h5', '400epoch+26.h5', '400epoch+36.h5', '400epoch+51.h5']\n",
        "\n",
        "    # List to store loaded models\n",
        "    loaded_models = []\n",
        "\n",
        "    custom_objects = {\n",
        "        'DefConvLayer_red': DefConvLayer_red  # Assuming 'DefConvLayer_red' is a custom layer\n",
        "    }\n",
        "\n",
        "    # Load models in a loop\n",
        "    for model_name in model_names:\n",
        "        # Construct the full path to the model file\n",
        "        model_path = '/content/drive/MyDrive/Epochs/400/' + model_name\n",
        "\n",
        "        # Load the model and append it to the list\n",
        "        model = load_model(model_path, custom_objects=custom_objects)\n",
        "        loaded_models.append(model)\n",
        "\n",
        "        # Evaluate the loaded model\n",
        "        results = model.evaluate(test_gen)\n",
        "        print('Test loss and accuracy for model', model_name, ':', results)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(test_gen)\n",
        "        rounded_pred = np.argmax(predictions, axis=-1)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        cm = confusion_matrix(y_true=test_gen.classes, y_pred=rounded_pred)\n",
        "        cm_plot_labels = ['A', 'F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n",
        "        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix for model ' + model_name)\n",
        "\n",
        "        # Print classification report\n",
        "        print('Classification report for model', model_name, ':')\n",
        "        print(classification_report(y_true=test_gen.classes, y_pred=rounded_pred, target_names=cm_plot_labels))\n",
        "\n",
        "    # Return something meaningful, e.g., history\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "mDj2Er1H2Lmf",
        "trusted": true
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/leondgarse/keras_cv_attention_models"
      ],
      "metadata": {
        "id": "COIWAnOotVGZ",
        "outputId": "da6c85e8-0058-4468-b411-2a33646df31f",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/leondgarse/keras_cv_attention_models\n",
            "  Cloning https://github.com/leondgarse/keras_cv_attention_models to /tmp/pip-req-build-bwko65hk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/leondgarse/keras_cv_attention_models /tmp/pip-req-build-bwko65hk\n",
            "  Resolved https://github.com/leondgarse/keras_cv_attention_models to commit 5bbbc792effde7d5d94c01b7c15625d9db109aa6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (4.66.2)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (6.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (2023.12.25)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (4.9.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (2.15.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->keras-cv-attention-models==1.4.2) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.5.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-cv-attention-models==1.4.2) (0.43.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2024.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_cv_attention_models import maxvit\n",
        "mm = maxvit.MaxViT_Tiny(input_shape=(224, 224, 3), pretrained=\"imagenet\")\n",
        "# mm.summary()"
      ],
      "metadata": {
        "id": "fLq_Narsto20",
        "outputId": "1f2e6151-9e3b-406b-9f09-d218623906a7",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Load pretrained from: /root/.keras/models/maxvit_tiny_224_imagenet.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def SSA(inputs,fltr):\n",
        "    shape=K.int_shape(inputs)\n",
        "    li=q=k=v=Conv2D(fltr,1,padding='same',activation='relu')(inputs)\n",
        "    print(\"Shape of Input of SSA\", inputs)\n",
        "    Qshape=K.int_shape(q)\n",
        "    Kshape= K.int_shape(k)\n",
        "    Vshape= K.int_shape(v)\n",
        "    a=Qshape[1]*Qshape[2]\n",
        "    q=Reshape((a,Qshape[3]))(q)\n",
        "    k=Reshape((a,Kshape[3]))(k)\n",
        "    k=Permute((2,1))(k)\n",
        "    qk=tf.matmul(q,k)\n",
        "    qk=Activation('softmax')(qk)\n",
        "    v=Reshape((a,Vshape[3]))(v)\n",
        "    qkv=tf.matmul(qk,v)\n",
        "    print(qkv.shape)\n",
        "    qkv=Reshape((Vshape[1],Vshape[2],Vshape[3]))(qkv)\n",
        "    qkv = Conv2D(shape[3], 1, strides=1, padding='same', activation='relu')(qkv)\n",
        "    print(\"Shape of Output of SSA\", qkv)\n",
        "    return qkv"
      ],
      "metadata": {
        "id": "gfdo3wQDgQWF",
        "trusted": true
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def CDSA(input,fltr,nh):\n",
        "    attn = []\n",
        "    print(\"Shape of CDSA Input\", input.shape)\n",
        "    feature_split = tf.split(input, num_or_size_splits= num_splits, axis=3)\n",
        "    print(feature_split[0].shape)\n",
        "    shape=K.int_shape(feature_split[0])\n",
        "    x = SSA(feature_split[0],fltr)\n",
        "    attn.append(x)\n",
        "    for i in range(1,nh):\n",
        "        x = Add()([feature_split[i],x])\n",
        "        x = SSA(x,fltr)\n",
        "        attn.append(x)\n",
        "    mh_lka_attn = Add()(attn)\n",
        "    mh_lka_attn = Conv2D(fltr,1, strides=1, padding='same', activation='relu')(mh_lka_attn)\n",
        "    print(\"Shape of CDSA Output\", mh_lka_attn.shape)\n",
        "    return mh_lka_attn\n"
      ],
      "metadata": {
        "id": "NVDzywSVfVX_",
        "trusted": true
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CAL(input,fltr,nh):\n",
        "    print(\"Shape of CAL Input\", input.shape)\n",
        "    x = DefConv_full(input, fltr, kernel_size=3)\n",
        "    rs1 = x = Add()([x,input])\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = CDSA(x,fltr,nh)\n",
        "    rs2 = x = Add()([rs1,x])\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = Conv2D(fltr, 1, padding='same', activation='relu')(x)\n",
        "    x = Add()([rs2,x])\n",
        "    print(\"Shape of CAL Output\", x.shape)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "PKnsju-la_cg",
        "trusted": true
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fun= 'categorical_crossentropy'\n",
        "gpu_num=2\n",
        "k=5\n",
        "lr1=0.005\n",
        "lr2=0.0001\n",
        "image_size=224\n",
        "classes=8\n",
        "ratio=8\n",
        "fltr=256\n",
        "nh=2  # number of splits\n",
        "mag='40'"
      ],
      "metadata": {
        "id": "uQqoWozCTBhK",
        "trusted": true
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "\n",
        "input_image = Input(shape=(224, 224, 3))\n",
        "mn_input = input_image\n",
        "\n",
        "# Load the model\n",
        "base_model = maxvit.MaxViT_Tiny(input_shape=(224, 224, 3), pretrained=\"imagenet\")\n",
        "new_base_model = Model(inputs=base_model.input, outputs=base_model.get_layer('stack_3_block_5/grid_ffn_output').output)\n",
        "mn_output = new_base_model(mn_input)\n",
        "print(mn_output.shape)\n",
        "\n",
        "mn_output = Conv2D(fltr, 1, padding='same', activation='relu')(mn_output)\n",
        "print(mn_output.shape)\n",
        "mn_output = BatchNormalization()(mn_output)  # Add Batch Normalization\n",
        "mn_output = Dropout(0.5)(mn_output)\n",
        "num_splits = 2\n",
        "CAL_out = CAL(mn_output,fltr,nh)\n",
        "print(CAL_out.shape)\n",
        "CAL_out = GlobalAveragePooling2D()(CAL_out)\n",
        "out=Dense(classes,activation='softmax')(CAL_out)\n",
        "if gpu_num<1:\n",
        "    model=Model(inputs=input_image, outputs=out)\n",
        "    #model.summary()\n",
        "    parallel_model = multi_gpu_model(model, gpus=gpu_num)\n",
        "    parallel_model.summary()\n",
        "else:\n",
        "    parallel_model=Model(inputs=input_image, outputs=out)\n",
        "    parallel_model.summary()"
      ],
      "metadata": {
        "id": "i--5bFDwR9fx",
        "outputId": "d1688a65-e6a3-4e70-9e4e-1600011bd83b",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Load pretrained from: /root/.keras/models/maxvit_tiny_224_imagenet.h5\n",
            "(None, 14, 14, 256)\n",
            "(None, 14, 14, 256)\n",
            "Shape of CAL Input (None, 14, 14, 256)\n",
            "Shape of CDSA Input (None, 14, 14, 256)\n",
            "(None, 14, 14, 128)\n",
            "Shape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='tf.split_134/split:0', description=\"created by layer 'tf.split_134'\")\n",
            "(None, 196, 256)\n",
            "Shape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='conv2d_19/Relu:0', description=\"created by layer 'conv2d_19'\")\n",
            "Shape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='add_11/add:0', description=\"created by layer 'add_11'\")\n",
            "(None, 196, 256)\n",
            "Shape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='conv2d_21/Relu:0', description=\"created by layer 'conv2d_21'\")\n",
            "Shape of CDSA Output (None, 14, 14, 256)\n",
            "Shape of CAL Output (None, 14, 14, 256)\n",
            "(None, 14, 14, 256)\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " model_4 (Functional)        (None, 14, 14, 256)          1263885   ['input_8[0][0]']             \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 14, 14, 256)          65792     ['model_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 14, 14, 256)          1024      ['conv2d_16[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 14, 14, 256)          0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 14, 14, 18)           41490     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " def_conv_layer_red_2 (DefC  (None, 14, 14, 256)          589824    ['dropout_2[0][0]',           \n",
            " onvLayer_red)                                                       'conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 14, 14, 256)          0         ['def_conv_layer_red_2[0][0]',\n",
            "                                                                     'dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 14, 14, 256)          512       ['add_10[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.split_134 (TFOpLambda)   [(None, 14, 14, 128),        0         ['layer_normalization_4[0][0]'\n",
            "                              (None, 14, 14, 128)]                  ]                             \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 14, 14, 256)          33024     ['tf.split_134[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_413 (Reshape)       (None, 196, 256)             0         ['conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_412 (Reshape)       (None, 196, 256)             0         ['conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " permute_4 (Permute)         (None, 256, 196)             0         ['reshape_413[0][0]']         \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_272 (TFOp  (None, 196, 196)             0         ['reshape_412[0][0]',         \n",
            " Lambda)                                                             'permute_4[0][0]']           \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_272[0][0]']\n",
            "                                                                                                  \n",
            " reshape_414 (Reshape)       (None, 196, 256)             0         ['conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_273 (TFOp  (None, 196, 256)             0         ['activation_4[0][0]',        \n",
            " Lambda)                                                             'reshape_414[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_415 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_273[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 14, 14, 128)          32896     ['reshape_415[0][0]']         \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 14, 14, 128)          0         ['tf.split_134[0][1]',        \n",
            "                                                                     'conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 14, 14, 256)          33024     ['add_11[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_417 (Reshape)       (None, 196, 256)             0         ['conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_416 (Reshape)       (None, 196, 256)             0         ['conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " permute_5 (Permute)         (None, 256, 196)             0         ['reshape_417[0][0]']         \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_274 (TFOp  (None, 196, 196)             0         ['reshape_416[0][0]',         \n",
            " Lambda)                                                             'permute_5[0][0]']           \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_274[0][0]']\n",
            "                                                                                                  \n",
            " reshape_418 (Reshape)       (None, 196, 256)             0         ['conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_275 (TFOp  (None, 196, 256)             0         ['activation_5[0][0]',        \n",
            " Lambda)                                                             'reshape_418[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_419 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_275[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 14, 14, 128)          32896     ['reshape_419[0][0]']         \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 14, 14, 128)          0         ['conv2d_19[0][0]',           \n",
            "                                                                     'conv2d_21[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 14, 14, 256)          33024     ['add_12[0][0]']              \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 14, 14, 256)          0         ['add_10[0][0]',              \n",
            "                                                                     'conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, 14, 14, 256)          512       ['add_13[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 14, 14, 256)          65792     ['layer_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 14, 14, 256)          0         ['add_13[0][0]',              \n",
            "                                                                     'conv2d_23[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 256)                  0         ['add_14[0][0]']              \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 8)                    2056      ['global_average_pooling2d_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13570722 (51.77 MB)\n",
            "Trainable params: 13540514 (51.65 MB)\n",
            "Non-trainable params: 30208 (118.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(parallel_model,train_gen,val_gen,test_gen,mag,image_size,'maxvit',lr1,lr2,4,100)"
      ],
      "metadata": {
        "id": "_6LvLQM-S6Vp",
        "outputId": "2fb45552-4c6b-42d5-e842-d516f3171347",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137/137 [==============================] - 216s 2s/step - loss: 1.2912 - acc: 0.5586\n",
            "Test loss and accuracy for model 400epoch+01.h5 : [1.2911920547485352, 0.5586080551147461]\n",
            "137/137 [==============================] - 64s 409ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[  5  15   6   4   1   0   2   0]\n",
            " [  1 190  12  13   2   2   4   0]\n",
            " [  1   8  49   1   0   0  10   0]\n",
            " [  1  13   0  28   0   0   4   0]\n",
            " [  1  20  10   4  16   0   2   0]\n",
            " [  0  18  15   2   0   3   3   0]\n",
            " [  1   8  13   1   1   0  13   0]\n",
            " [  1   2  27   1   7   3   1   1]]\n",
            "Classification report for model 400epoch+01.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.45      0.15      0.23        33\n",
            "           F       0.69      0.85      0.76       224\n",
            "          PT       0.37      0.71      0.49        69\n",
            "          TA       0.52      0.61      0.56        46\n",
            "          DC       0.59      0.30      0.40        53\n",
            "          LC       0.38      0.07      0.12        41\n",
            "          MC       0.33      0.35      0.34        37\n",
            "          PC       1.00      0.02      0.05        43\n",
            "\n",
            "    accuracy                           0.56       546\n",
            "   macro avg       0.54      0.38      0.37       546\n",
            "weighted avg       0.59      0.56      0.51       546\n",
            "\n",
            "137/137 [==============================] - 63s 412ms/step - loss: 0.5803 - acc: 0.8004\n",
            "Test loss and accuracy for model 400epoch+06.h5 : [0.5802515745162964, 0.8003662824630737]\n",
            "137/137 [==============================] - 63s 400ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 25   0   5   1   2   0   0   0]\n",
            " [  0 209   2   7   2   4   0   0]\n",
            " [  1   3  63   0   1   0   1   0]\n",
            " [  0  10   1  34   1   0   0   0]\n",
            " [  0   5   0   1  47   0   0   0]\n",
            " [  0  11   3   0   2  25   0   0]\n",
            " [  0   7  18   0   1   2   9   0]\n",
            " [  0   0  11   0   6   1   0  25]]\n",
            "Classification report for model 400epoch+06.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.96      0.76      0.85        33\n",
            "           F       0.85      0.93      0.89       224\n",
            "          PT       0.61      0.91      0.73        69\n",
            "          TA       0.79      0.74      0.76        46\n",
            "          DC       0.76      0.89      0.82        53\n",
            "          LC       0.78      0.61      0.68        41\n",
            "          MC       0.90      0.24      0.38        37\n",
            "          PC       1.00      0.58      0.74        43\n",
            "\n",
            "    accuracy                           0.80       546\n",
            "   macro avg       0.83      0.71      0.73       546\n",
            "weighted avg       0.82      0.80      0.79       546\n",
            "\n",
            "137/137 [==============================] - 63s 409ms/step - loss: 0.4321 - acc: 0.8608\n",
            "Test loss and accuracy for model 400epoch+16.h5 : [0.4320639967918396, 0.860805869102478]\n",
            "137/137 [==============================] - 62s 402ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 30   0   2   0   0   1   0   0]\n",
            " [  0 202   5   0   0  14   0   3]\n",
            " [  0   0  63   0   0   6   0   0]\n",
            " [  1  10   1  27   1   3   0   3]\n",
            " [  1   7   0   0  41   2   0   2]\n",
            " [  0   0   1   0   0  40   0   0]\n",
            " [  0   1   7   0   0   4  25   0]\n",
            " [  0   0   0   0   0   1   0  42]]\n",
            "Classification report for model 400epoch+16.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.94      0.91      0.92        33\n",
            "           F       0.92      0.90      0.91       224\n",
            "          PT       0.80      0.91      0.85        69\n",
            "          TA       1.00      0.59      0.74        46\n",
            "          DC       0.98      0.77      0.86        53\n",
            "          LC       0.56      0.98      0.71        41\n",
            "          MC       1.00      0.68      0.81        37\n",
            "          PC       0.84      0.98      0.90        43\n",
            "\n",
            "    accuracy                           0.86       546\n",
            "   macro avg       0.88      0.84      0.84       546\n",
            "weighted avg       0.89      0.86      0.86       546\n",
            "\n",
            "137/137 [==============================] - 64s 411ms/step - loss: 0.5066 - acc: 0.8700\n",
            "Test loss and accuracy for model 400epoch+21.h5 : [0.5065503120422363, 0.8699633479118347]\n",
            "137/137 [==============================] - 63s 403ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 32   0   1   0   0   0   0   0]\n",
            " [  0 215   1   5   0   3   0   0]\n",
            " [  0   0  61   0   5   3   0   0]\n",
            " [  0   4   1  40   1   0   0   0]\n",
            " [  0   3   0   0  49   1   0   0]\n",
            " [  0   3   1   0   1  36   0   0]\n",
            " [  0   0  12   0   0   2  23   0]\n",
            " [  0   0   7   0  13   4   0  19]]\n",
            "Classification report for model 400epoch+21.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      0.97      0.98        33\n",
            "           F       0.96      0.96      0.96       224\n",
            "          PT       0.73      0.88      0.80        69\n",
            "          TA       0.89      0.87      0.88        46\n",
            "          DC       0.71      0.92      0.80        53\n",
            "          LC       0.73      0.88      0.80        41\n",
            "          MC       1.00      0.62      0.77        37\n",
            "          PC       1.00      0.44      0.61        43\n",
            "\n",
            "    accuracy                           0.87       546\n",
            "   macro avg       0.88      0.82      0.83       546\n",
            "weighted avg       0.89      0.87      0.87       546\n",
            "\n",
            "137/137 [==============================] - 64s 412ms/step - loss: 0.2071 - acc: 0.9432\n",
            "Test loss and accuracy for model 400epoch+26.h5 : [0.20709891617298126, 0.9432234168052673]\n",
            "137/137 [==============================] - 62s 405ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 31   0   1   0   0   1   0   0]\n",
            " [  1 214   0   2   0   7   0   0]\n",
            " [  0   0  64   0   0   0   5   0]\n",
            " [  0   8   0  37   0   0   1   0]\n",
            " [  0   2   0   0  51   0   0   0]\n",
            " [  0   0   1   0   0  40   0   0]\n",
            " [  0   0   0   0   0   0  37   0]\n",
            " [  0   0   1   0   0   1   0  41]]\n",
            "Classification report for model 400epoch+26.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.97      0.94      0.95        33\n",
            "           F       0.96      0.96      0.96       224\n",
            "          PT       0.96      0.93      0.94        69\n",
            "          TA       0.95      0.80      0.87        46\n",
            "          DC       1.00      0.96      0.98        53\n",
            "          LC       0.82      0.98      0.89        41\n",
            "          MC       0.86      1.00      0.92        37\n",
            "          PC       1.00      0.95      0.98        43\n",
            "\n",
            "    accuracy                           0.94       546\n",
            "   macro avg       0.94      0.94      0.94       546\n",
            "weighted avg       0.95      0.94      0.94       546\n",
            "\n",
            "137/137 [==============================] - 64s 411ms/step - loss: 0.1149 - acc: 0.9560\n",
            "Test loss and accuracy for model 400epoch+36.h5 : [0.11489544808864594, 0.9560439586639404]\n",
            "137/137 [==============================] - 63s 405ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  2 212   0   5   0   4   0   1]\n",
            " [  0   0  68   0   0   1   0   0]\n",
            " [  2   5   0  39   0   0   0   0]\n",
            " [  1   1   0   0  51   0   0   0]\n",
            " [  0   1   1   0   0  39   0   0]\n",
            " [  0   0   0   0   0   0  37   0]\n",
            " [  0   0   0   0   0   0   0  43]]\n",
            "Classification report for model 400epoch+36.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.87      1.00      0.93        33\n",
            "           F       0.97      0.95      0.96       224\n",
            "          PT       0.99      0.99      0.99        69\n",
            "          TA       0.89      0.85      0.87        46\n",
            "          DC       1.00      0.96      0.98        53\n",
            "          LC       0.89      0.95      0.92        41\n",
            "          MC       1.00      1.00      1.00        37\n",
            "          PC       0.98      1.00      0.99        43\n",
            "\n",
            "    accuracy                           0.96       546\n",
            "   macro avg       0.95      0.96      0.95       546\n",
            "weighted avg       0.96      0.96      0.96       546\n",
            "\n",
            "137/137 [==============================] - 64s 412ms/step - loss: 0.0661 - acc: 0.9725\n",
            "Test loss and accuracy for model 400epoch+51.h5 : [0.06612779945135117, 0.9725274443626404]\n",
            "137/137 [==============================] - 63s 406ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 33   0   0   0   0   0   0   0]\n",
            " [  0 217   0   6   1   0   0   0]\n",
            " [  0   0  68   0   0   1   0   0]\n",
            " [  0   3   0  43   0   0   0   0]\n",
            " [  0   1   0   0  52   0   0   0]\n",
            " [  0   1   1   0   0  39   0   0]\n",
            " [  0   1   0   0   0   0  36   0]\n",
            " [  0   0   0   0   0   0   0  43]]\n",
            "Classification report for model 400epoch+51.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00        33\n",
            "           F       0.97      0.97      0.97       224\n",
            "          PT       0.99      0.99      0.99        69\n",
            "          TA       0.88      0.93      0.91        46\n",
            "          DC       0.98      0.98      0.98        53\n",
            "          LC       0.97      0.95      0.96        41\n",
            "          MC       1.00      0.97      0.99        37\n",
            "          PC       1.00      1.00      1.00        43\n",
            "\n",
            "    accuracy                           0.97       546\n",
            "   macro avg       0.97      0.97      0.97       546\n",
            "weighted avg       0.97      0.97      0.97       546\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-3edca79327a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'maxvit'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-81-5081de18bddc>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_gen, val_gen, test_gen, mag, image_size, save_name, lr1, lr2, Epochs1, Epochs2)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Return something meaningful, e.g., history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}