{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8146556,
          "sourceType": "datasetVersion",
          "datasetId": 4817492
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 8158384,
          "datasetId": 4826407
        }
      ],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"tensorflow>=1.7.0\"\n",
        "!pip install tensorflow-addons\n",
        "!pip install tensorflow-hub\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vq5qLS4d2LmQ",
        "outputId": "183113e7-5c8f-45a4-dd3e-ad2ab615bba6",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow>=1.7.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.7.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.7.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.7.0) (3.2.2)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (3.20.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (2.15.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.2.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, utils\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "vmaszhvR2LmY",
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(f\"tensorflow version: {tf.__version__}\")\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ht481_PZ2LmZ",
        "outputId": "0607415e-0c8b-41b5-dd54-556994fe3d79",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "import statistics\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Dense, DepthwiseConv2D,AveragePooling2D, Concatenate, Dropout, Permute,Reshape,Lambda,Activation, Add,Multiply, MaxPooling2D, Conv2D, Flatten, BatchNormalization, GlobalAveragePooling2D,LayerNormalization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16,ConvNeXtTiny,ResNet50, MobileNet, Xception, EfficientNetB0 , DenseNet169, DenseNet201, DenseNet121, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import gc\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from functools import partial\n",
        "from collections import Counter\n",
        "from statistics import mean\n",
        "\n",
        "from keras.models import load_model\n",
        "#from keras.models import Sequential\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "o91Tp0x_sHTl",
        "trusted": true
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION, tf.config.list_physical_devices()"
      ],
      "metadata": {
        "id": "N-4YPF2w26ll",
        "outputId": "4265e605-ea25-4659-8297-34ae03267c8a",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.15.0',\n",
              " [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              "  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = '/content/drive/MyDrive/Breast Cancer Project/IW/40/A'\n",
        "F = '/content/drive/MyDrive/Breast Cancer Project/IW/40/F'\n",
        "PT ='/content/drive/MyDrive/Breast Cancer Project/IW/40/PT'\n",
        "TA ='/content/drive/MyDrive/Breast Cancer Project/IW/40/TA'\n",
        "DC ='/content/drive/MyDrive/Breast Cancer Project/IW/40/DC'\n",
        "LC ='/content/drive/MyDrive/Breast Cancer Project/IW/40/LC'\n",
        "MC ='/content/drive/MyDrive/Breast Cancer Project/IW/40/MC'\n",
        "PC ='/content/drive/MyDrive/Breast Cancer Project/IW/40/PC'"
      ],
      "metadata": {
        "id": "4EWX3Gd8r32a",
        "trusted": true
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirlist=[A, F, PT, TA, DC, LC, MC, PC]\n",
        "classes=['A','F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n",
        "filepaths=[]\n",
        "labels=[]\n",
        "for i,j in zip(dirlist, classes):\n",
        "    filelist=os.listdir(i)\n",
        "    for f in filelist:\n",
        "        filepath=os.path.join (i,f)\n",
        "        filepaths.append(filepath)\n",
        "        labels.append(j)\n",
        "print ('filepaths: ', len(filepaths), '   labels: ', len(labels))"
      ],
      "metadata": {
        "id": "QNZkBeucr9Mh",
        "outputId": "3a1ee7c7-1cf5-4c5b-c76a-4397a155bb17",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepaths:  1995    labels:  1995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Files=pd.Series(filepaths, name='filepaths')\n",
        "Label=pd.Series(labels, name='labels')\n",
        "df=pd.concat([Files,Label], axis=1)\n",
        "df=pd.DataFrame(np.array(df).reshape(len(filepaths),2), columns = ['filepaths', 'labels'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QVgOHhygsAlZ",
        "outputId": "6fb57624-c4f3-4800-90f4-eb9d1963f026",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           filepaths labels\n",
              "0  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "1  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "2  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "3  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "4  /content/drive/MyDrive/Breast Cancer Project/I...      A"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f130e7b2-9e23-4cf0-96b3-92842aaaac61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepaths</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f130e7b2-9e23-4cf0-96b3-92842aaaac61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f130e7b2-9e23-4cf0-96b3-92842aaaac61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f130e7b2-9e23-4cf0-96b3-92842aaaac61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff142a3d-02ce-430d-a776-502a2eca5c01\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff142a3d-02ce-430d-a776-502a2eca5c01')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff142a3d-02ce-430d-a776-502a2eca5c01 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1995,\n  \"fields\": [\n    {\n      \"column\": \"filepaths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1995,\n        \"samples\": [\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/40/DC/SOB_M_DC-14-11951-40-003.png\",\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/40/MC/SOB_M_MC-14-19979C-40-017.png\",\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/40/PT/SOB_B_PT-14-21998AB-40-054.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"F\",\n          \"LC\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['labels'].value_counts())"
      ],
      "metadata": {
        "id": "1uQkt3MTsD_o",
        "outputId": "7ea7b854-2719-42ff-86ea-ced06db33b1b",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels\n",
            "DC    864\n",
            "F     253\n",
            "MC    205\n",
            "LC    156\n",
            "TA    149\n",
            "PC    145\n",
            "A     114\n",
            "PT    109\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, train_size=0.70)\n",
        "#train_new, valid = train_test_split(train, train_size=0.90, random_state=0)\n",
        "\n",
        "print(f\"train set shape: {train.shape}\")\n",
        "print(f\"test set shape: {test.shape}\")\n",
        "print(f\"validation set shape: {test.shape}\")"
      ],
      "metadata": {
        "id": "pfI-lh99sGr7",
        "outputId": "21a891e5-851f-405f-c4f9-a503d1787471",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set shape: (1396, 2)\n",
            "test set shape: (599, 2)\n",
            "validation set shape: (599, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train = '/content/drive/MyDrive/fold5/40/train'\n",
        "# test = '/content/drive/MyDrive/fold5/40/test'"
      ],
      "metadata": {
        "id": "G5LJCbZ2IooS",
        "trusted": true
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)"
      ],
      "metadata": {
        "id": "BF_mNPBOsQPL",
        "trusted": true
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tand get the number os devices.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(dataframe=train,\n",
        "                                              x_col = 'filepaths', y_col ='labels',\n",
        "                                              target_size = (224,224), batch_size = 4 * strategy.num_replicas_in_sync,\n",
        "                                              class_mode = 'categorical', shuffle = True)\n",
        "\n",
        "val_gen = test_datagen.flow_from_dataframe(test,\n",
        "                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n",
        "                                             class_mode = 'categorical',\n",
        "                                            batch_size = 4 * strategy.num_replicas_in_sync, shuffle = False)\n",
        "\n",
        "\n",
        "test_gen = test_datagen.flow_from_dataframe(test,\n",
        "                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n",
        "                                             class_mode = 'categorical',\n",
        "                                            batch_size = 4, shuffle = False)"
      ],
      "metadata": {
        "id": "4Gl5R4EJsRbN",
        "outputId": "010d26dc-134d-4495-dc68-e093a916d66c",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICES AVAILABLE: 1\n",
            "Found 1396 validated image filenames belonging to 8 classes.\n",
            "Found 599 validated image filenames belonging to 8 classes.\n",
            "Found 599 validated image filenames belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "\n",
        "def plotmodel(history,name):\n",
        "\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.plot(epochs,smooth_curve(acc))\n",
        "    plt.plot(epochs,smooth_curve(val_acc))\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
        "    #plt.savefig('acc_'+name+'_'+mag+'_'+fold+'.png')\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.plot(epochs,smooth_curve(loss))\n",
        "    plt.plot(epochs,smooth_curve(val_loss))\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "   # plt.savefig('loss_'+name+'_'+mag+'_'+fold+'.png')\n",
        "\n",
        "def label_smooth(y_true, y_pred):\n",
        "    y_true=((1-0.1)*y_true+0.05)\n",
        "    return K.categorical_crossentropy(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "CJBdug_F2Lmc",
        "trusted": true
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    #plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 3.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"green\" if cm[i, j] > thresh else \"red\", fontdict={'fontsize':'x-large'})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "LeIVRsgY2Lmc",
        "trusted": true
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DefConv_full(input, filters, kernel_size, strides=1):\n",
        "    \"\"\"\n",
        "    Using DefConv_reduced to implement full DC layer.\n",
        "    \"\"\"\n",
        "    offsets = layers.Conv2D(filters=2 * kernel_size ** 2,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=strides,\n",
        "                            padding='same',\n",
        "                            kernel_initializer='random_normal'\n",
        "                            )(input)\n",
        "    X = DefConvLayer_red(filters=filters,\n",
        "                         kernel_size=kernel_size,\n",
        "                         strides=strides\n",
        "                         )(input, offsets)\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "class DefConvLayer_red(Layer):\n",
        "\n",
        "    def __init__(self, filters,strides, kernel_size=3, **kwargs):\n",
        "        assert type(kernel_size) == int, \"expect kernel_size to be of type 'int'\"\n",
        "        assert type(strides) == int, \"expect strides to be of type int\"\n",
        "        self.N = kernel_size ** 2\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "\n",
        "        super(DefConvLayer_red, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], self.N, self.filters),\n",
        "                                 # Wdc is of shape [n_C=input_channels, lxl=N, filters=output_channels]\n",
        "                                 initializer='RandomNormal',\n",
        "                                 dtype='float32',\n",
        "                                 trainable=True)\n",
        "\n",
        "    def call(self, input, offsets):\n",
        "        # input of shape: (m=batch_size, n_H, n_W, n_C)\n",
        "        # offsets of shape: (m, n_H, n_W, 2*N)\n",
        "        # m, n_H, n_W, n_C = input.shape\n",
        "        # offsets = super(DefConvLayer, self).call(input) # Conv2D to learn offsets (m, n_H, n_W, 2*N)\n",
        "\n",
        "        input_offsets = self.BLIN(input, offsets)  # (m, n_H, n_W, n_C, N)\n",
        "        # BLIN returns N interpolated values of input at the offsets, for each spatial pixel\n",
        "        # replicate the offset input to each of the output channels\n",
        "        input_offsets = tf.expand_dims(input_offsets, axis=-1)\n",
        "        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, 1, self.filters])  # (m, n_H, n_W, n_C, N, filters)\n",
        "\n",
        "        new_shape = (1, 1, 1,) + self.W.shape\n",
        "        W = tf.reshape(self.W, shape=new_shape)  # (1, 1, 1, n_C, N, filters) to be broadcastable to input_offsets\n",
        "\n",
        "        output = tf.multiply(input_offsets, W)  # (m, n_H, n_W, n_C, N, filters)\n",
        "        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, n_C, filters) reduce along each channel kernel\n",
        "        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, filters) reduce along input channels\n",
        "        return output\n",
        "\n",
        "    @tf.function\n",
        "    def BLIN(self, input, offsets_in):  # Bi-Linear Interpolation of input feature map values at offset locations\n",
        "        \"\"\"\n",
        "        'input' shape: (m, n_Hi, n_Wi, n_C)\n",
        "        'offsets_in' shape: (m, n_Ho, n_Wo, 2*N)\n",
        "        'offsets_in' is the output of the Conv2D layer step aimed at learning the offsets,\n",
        "                     possibly smaller spatial size than input's, if strides>1\n",
        "        \"\"\"\n",
        "        offsets = offsets_in\n",
        "        m    = tf.shape(input)[0]\n",
        "        n_Hi = tf.shape(input)[1]\n",
        "        n_Wi = tf.shape(input)[2]\n",
        "        n_C  = tf.shape(input)[3]\n",
        "\n",
        "        n_Ho = tf.shape(offsets)[1] # also the output spatial shape\n",
        "        n_Wo = tf.shape(offsets)[2]\n",
        "        N    = tf.shape(offsets)[3] // 2\n",
        "\n",
        "        # expand the input into (m, n_Hi, n_Wi, n_C, N). this will also be the output shape of this function\n",
        "        input_offsets = tf.expand_dims(input, axis=-1) # (m, n_Hi, n_Wi, n_C, N, 1)\n",
        "        # replicate N times, to be compatible with the kernel operation later\n",
        "        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, N])  # (m, n_Hi, n_Wi, n_C, N)\n",
        "\n",
        "        # the offset metrices will be replicated n_C times: same (spatial) offsets for each of the input *channels*.\n",
        "        offsets = tf.reshape(offsets, (m, n_Ho, n_Wo, 1, N, 2))  # (m, n_Ho, n_Wo, 1, N, 2) add a \"channel\" axis\n",
        "        offsets = tf.tile(offsets, [1, 1, 1, n_C, 1, 1])  # (m, n_Ho, n_Wo, n_C, N, 2) replicate for each of the input channels\n",
        "\n",
        "        # construct a full index grid to be applied onto \"input_offsets\" of size (m, n_H, n_W, n_C, N)\n",
        "        (grid_m, grid_i, grid_j, grid_c, grid_N) = tf.meshgrid(tf.range(m), tf.range(n_Hi),\n",
        "                                                               tf.range(n_Wi), tf.range(n_C), tf.range(N),\n",
        "                                                               indexing='ij')  # (m, n_Hi, n_Wi, n_C, N) a list of 5 metrices with index-like values\n",
        "\n",
        "        # adjust indices to 'strides' down-sample, and\n",
        "        # unroll indices to fit into tf.gather_nd later. (unroll offsets also)\n",
        "        ur_grid_m = tf.reshape(grid_m[:, ::self.strides, ::self.strides, :, :], [-1])  # (m*n_Ho*n_Wo*n_C*N, 1); integers\n",
        "        ur_grid_i = tf.reshape(grid_i[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_j = tf.reshape(grid_j[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_c = tf.reshape(grid_c[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_N = tf.reshape(grid_N[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_offsets = tf.reshape(offsets, (-1, 2))  # (m*n_Ho*n_Wo*n_C*N, 2) both i, j\n",
        "\n",
        "        # spatial indices will be adjusted using 'offsets'\n",
        "        coords_i = tf.cast(ur_grid_i, dtype='float32') + ur_offsets[..., 0]\n",
        "        coords_j = tf.cast(ur_grid_j, dtype='float32') + ur_offsets[..., 1]\n",
        "\n",
        "        # Need to think further on how to handle edges,\n",
        "        # perhaps assume outside of index values can be zeros instead of hard-clipping.\n",
        "        coords_i = tf.clip_by_value(coords_i, 0, tf.cast(n_Hi, dtype='float32')-1)\n",
        "        coords_j = tf.clip_by_value(coords_j, 0, tf.cast(n_Wi, dtype='float32')-1)\n",
        "        coords_2d = tf.stack([coords_i, coords_j], axis=-1)  # (m*n_Ho*n_Wo*n_C*N, 2); float32\n",
        "\n",
        "        # generate top and bottom, left and right, nearest \"real\" indices\n",
        "        # assuming coords represents (p,q) values where i<=p<=i+1, and j<=q<=j+1:\n",
        "        # shape: (m*n_Ho*n_Wo*n_C*N, 2)\n",
        "        # note the coordinates themselves (values in coords) are [i,j] within [0:n_Hi-1, 0:n_Wi] range\n",
        "        coords_lt = tf.cast(tf.math.floor(coords_2d), dtype='int32')  # nearest (i,j)\n",
        "        coords_rb = tf.cast(tf.math.ceil(coords_2d), dtype='int32')  # nearest (i+1, j+1)\n",
        "\n",
        "        coords_lb = tf.stack((coords_rb[..., 0], coords_lt[..., 1]), axis=-1)  # nearest (i+1, j)\n",
        "        coords_rt = tf.stack((coords_lt[..., 0], coords_rb[..., 1]), axis=-1)  # nearest (i, j+1)\n",
        "\n",
        "        # use the replicated input tensor \"input_offsets\" which holds the input values, to get these values at the specific locations:\n",
        "        # these type of Tensors doesn't allow for conversion into numpy-like arrays. to use tf.gather_nd, need to unroll indices\n",
        "        # unroll all grid tensors to be used with tf.gather_nd()\n",
        "\n",
        "        indices_lt = tf.stack([ur_grid_m, coords_lt[..., 0], coords_lt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_rb = tf.stack([ur_grid_m, coords_rb[..., 0], coords_rb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_lb = tf.stack([ur_grid_m, coords_lb[..., 0], coords_lb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_rt = tf.stack([ur_grid_m, coords_rt[..., 0], coords_rt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "\n",
        "        vals_lt = tf.gather_nd(input_offsets, indices_lt)\n",
        "        vals_rb = tf.gather_nd(input_offsets, indices_rb)\n",
        "        vals_lb = tf.gather_nd(input_offsets, indices_lb)\n",
        "        vals_rt = tf.gather_nd(input_offsets, indices_rt)\n",
        "\n",
        "        # calculate the offset from the left-top (i,j) position\n",
        "        ur_coords_offset_lt = coords_2d - tf.cast(coords_lt, dtype='float32')  # (m*n_Ho*n_Wo*n_C*N, 2)\n",
        "\n",
        "        # first linear interpolation (m*n_H*n_W*n_C*N)\n",
        "        vals_t = vals_lt + (vals_rt - vals_lt) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), top\n",
        "        vals_b = vals_lb + (vals_rb - vals_lb) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), bottom\n",
        "\n",
        "        # second linear interpolation\n",
        "        input_offsets = vals_t + (vals_b - vals_t) * ur_coords_offset_lt[..., 0]  # along the i axis (n_Hi)\n",
        "\n",
        "        # reshape back to output shape\n",
        "        input_offsets = tf.reshape(input_offsets, (m, n_Ho, n_Wo, n_C, N))\n",
        "\n",
        "        return input_offsets"
      ],
      "metadata": {
        "id": "hwUptDC7WJHS",
        "trusted": true
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def train_model(model, train_gen, val_gen, test_gen, mag, image_size, save_name, lr1, lr2, Epochs1, Epochs2):\n",
        "    from keras.callbacks import ModelCheckpoint\n",
        "    from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "    lr_decay = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
        "    save_model = ModelCheckpoint('/content/drive/MyDrive/100+{epoch:02d}.h5',\n",
        "                                 monitor='val_accuracy',\n",
        "                                 period=5,\n",
        "                                 save_best_only=True)\n",
        "\n",
        "    # List of model names\n",
        "    model_names = ['40epoch+01.h5', '40epoch+06.h5', '40epoch+21.h5', '40epoch+26.h5', '40epoch+36.h5', '40epoch+81.h5']\n",
        "\n",
        "    # List to store loaded models\n",
        "    loaded_models = []\n",
        "\n",
        "    custom_objects = {\n",
        "        'DefConvLayer_red': DefConvLayer_red  # Assuming 'DefConvLayer_red' is a custom layer\n",
        "    }\n",
        "\n",
        "    # Load models in a loop\n",
        "    for model_name in model_names:\n",
        "        # Construct the full path to the model file\n",
        "        model_path = '/content/drive/MyDrive/Epochs/40/' + model_name\n",
        "\n",
        "        # Load the model and append it to the list\n",
        "        model = load_model(model_path, custom_objects=custom_objects)\n",
        "        loaded_models.append(model)\n",
        "\n",
        "        # Evaluate the loaded model\n",
        "        results = model.evaluate(test_gen)\n",
        "        print('Test loss and accuracy for model', model_name, ':', results)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(test_gen)\n",
        "        rounded_pred = np.argmax(predictions, axis=-1)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        cm = confusion_matrix(y_true=test_gen.classes, y_pred=rounded_pred)\n",
        "        cm_plot_labels = ['A', 'F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n",
        "        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix for model ' + model_name)\n",
        "\n",
        "        # Print classification report\n",
        "        print('Classification report for model', model_name, ':')\n",
        "        print(classification_report(y_true=test_gen.classes, y_pred=rounded_pred, target_names=cm_plot_labels))\n",
        "\n",
        "    # Return something meaningful, e.g., history\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "mDj2Er1H2Lmf",
        "trusted": true
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/leondgarse/keras_cv_attention_models"
      ],
      "metadata": {
        "id": "COIWAnOotVGZ",
        "outputId": "39411415-9367-4733-a957-8af9f9645bfe",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/leondgarse/keras_cv_attention_models\n",
            "  Cloning https://github.com/leondgarse/keras_cv_attention_models to /tmp/pip-req-build-ues9j9jv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/leondgarse/keras_cv_attention_models /tmp/pip-req-build-ues9j9jv\n",
            "  Resolved https://github.com/leondgarse/keras_cv_attention_models to commit 5bbbc792effde7d5d94c01b7c15625d9db109aa6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (4.66.2)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (6.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (2023.12.25)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (4.9.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-cv-attention-models==1.4.2) (2.15.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->keras-cv-attention-models==1.4.2) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-cv-attention-models==1.4.2) (2.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras-cv-attention-models==1.4.2) (0.5.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-cv-attention-models==1.4.2) (0.43.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models==1.4.2) (2024.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv-attention-models==1.4.2) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-cv-attention-models==1.4.2) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_cv_attention_models import maxvit\n",
        "mm = maxvit.MaxViT_Tiny(input_shape=(224, 224, 3), pretrained=\"imagenet\")\n",
        "# mm.summary()"
      ],
      "metadata": {
        "id": "fLq_Narsto20",
        "outputId": "41c4237d-3d1a-40f9-8951-ff6eaac5ce7d",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Load pretrained from: /root/.keras/models/maxvit_tiny_224_imagenet.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def SSA(inputs,fltr):\n",
        "    shape=K.int_shape(inputs)\n",
        "    li=q=k=v=Conv2D(fltr,1,padding='same',activation='relu')(inputs)\n",
        "    print(\"Shape of Input of SSA\", inputs)\n",
        "    Qshape=K.int_shape(q)\n",
        "    Kshape= K.int_shape(k)\n",
        "    Vshape= K.int_shape(v)\n",
        "    a=Qshape[1]*Qshape[2]\n",
        "    q=Reshape((a,Qshape[3]))(q)\n",
        "    k=Reshape((a,Kshape[3]))(k)\n",
        "    k=Permute((2,1))(k)\n",
        "    qk=tf.matmul(q,k)\n",
        "    qk=Activation('softmax')(qk)\n",
        "    v=Reshape((a,Vshape[3]))(v)\n",
        "    qkv=tf.matmul(qk,v)\n",
        "    print(qkv.shape)\n",
        "    qkv=Reshape((Vshape[1],Vshape[2],Vshape[3]))(qkv)\n",
        "    qkv = Conv2D(shape[3], 1, strides=1, padding='same', activation='relu')(qkv)\n",
        "    print(\"Shape of Output of SSA\", qkv)\n",
        "    return qkv"
      ],
      "metadata": {
        "id": "gfdo3wQDgQWF",
        "trusted": true
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def CDSA(input,fltr,nh):\n",
        "    attn = []\n",
        "    print(\"Shape of CDSA Input\", input.shape)\n",
        "    feature_split = tf.split(input, num_or_size_splits= num_splits, axis=3)\n",
        "    print(feature_split[0].shape)\n",
        "    shape=K.int_shape(feature_split[0])\n",
        "    x = SSA(feature_split[0],fltr)\n",
        "    attn.append(x)\n",
        "    for i in range(1,nh):\n",
        "        x = Add()([feature_split[i],x])\n",
        "        x = SSA(x,fltr)\n",
        "        attn.append(x)\n",
        "    mh_lka_attn = Add()(attn)\n",
        "    mh_lka_attn = Conv2D(fltr,1, strides=1, padding='same', activation='relu')(mh_lka_attn)\n",
        "    print(\"Shape of CDSA Output\", mh_lka_attn.shape)\n",
        "    return mh_lka_attn\n"
      ],
      "metadata": {
        "id": "NVDzywSVfVX_",
        "trusted": true
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CAL(input,fltr,nh):\n",
        "    print(\"Shape of CAL Input\", input.shape)\n",
        "    x = DefConv_full(input, fltr, kernel_size=3)\n",
        "    rs1 = x = Add()([x,input])\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = CDSA(x,fltr,nh)\n",
        "    rs2 = x = Add()([rs1,x])\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = Conv2D(fltr, 1, padding='same', activation='relu')(x)\n",
        "    x = Add()([rs2,x])\n",
        "    print(\"Shape of CAL Output\", x.shape)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "PKnsju-la_cg",
        "trusted": true
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fun= 'categorical_crossentropy'\n",
        "gpu_num=2\n",
        "k=5\n",
        "lr1=0.005\n",
        "lr2=0.0001\n",
        "image_size=224\n",
        "classes=8\n",
        "ratio=8\n",
        "fltr=256\n",
        "nh=2  # number of splits\n",
        "mag='40'"
      ],
      "metadata": {
        "id": "uQqoWozCTBhK",
        "trusted": true
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "\n",
        "input_image = Input(shape=(224, 224, 3))\n",
        "mn_input = input_image\n",
        "\n",
        "# Load the model\n",
        "base_model = maxvit.MaxViT_Tiny(input_shape=(224, 224, 3), pretrained=\"imagenet\")\n",
        "new_base_model = Model(inputs=base_model.input, outputs=base_model.get_layer('stack_3_block_5/grid_ffn_output').output)\n",
        "mn_output = new_base_model(mn_input)\n",
        "print(mn_output.shape)\n",
        "\n",
        "mn_output = Conv2D(fltr, 1, padding='same', activation='relu')(mn_output)\n",
        "print(mn_output.shape)\n",
        "mn_output = BatchNormalization()(mn_output)  # Add Batch Normalization\n",
        "mn_output = Dropout(0.5)(mn_output)\n",
        "num_splits = 2\n",
        "CAL_out = CAL(mn_output,fltr,nh)\n",
        "print(CAL_out.shape)\n",
        "CAL_out = GlobalAveragePooling2D()(CAL_out)\n",
        "out=Dense(classes,activation='softmax')(CAL_out)\n",
        "if gpu_num<1:\n",
        "    model=Model(inputs=input_image, outputs=out)\n",
        "    #model.summary()\n",
        "    parallel_model = multi_gpu_model(model, gpus=gpu_num)\n",
        "    parallel_model.summary()\n",
        "else:\n",
        "    parallel_model=Model(inputs=input_image, outputs=out)\n",
        "    parallel_model.summary()"
      ],
      "metadata": {
        "id": "i--5bFDwR9fx",
        "outputId": "93f11d6f-db24-4fa7-b297-9d67cb3ec046",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Load pretrained from: /root/.keras/models/maxvit_tiny_224_imagenet.h5\n",
            "(None, 14, 14, 256)\n",
            "(None, 14, 14, 256)\n",
            "Shape of CAL Input (None, 14, 14, 256)\n",
            "Shape of CDSA Input (None, 14, 14, 256)\n",
            "(None, 14, 14, 128)\n",
            "Shape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='tf.split_108/split:0', description=\"created by layer 'tf.split_108'\")\n",
            "(None, 196, 256)\n",
            "Shape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='conv2d_11/Relu:0', description=\"created by layer 'conv2d_11'\")\n",
            "Shape of Input of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='add_6/add:0', description=\"created by layer 'add_6'\")\n",
            "(None, 196, 256)\n",
            "Shape of Output of SSA KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 128), dtype=tf.float32, name=None), name='conv2d_13/Relu:0', description=\"created by layer 'conv2d_13'\")\n",
            "Shape of CDSA Output (None, 14, 14, 256)\n",
            "Shape of CAL Output (None, 14, 14, 256)\n",
            "(None, 14, 14, 256)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " model_2 (Functional)        (None, 14, 14, 256)          1263885   ['input_5[0][0]']             \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 14, 14, 256)          65792     ['model_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 14, 14, 256)          1024      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 14, 14, 256)          0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 14, 14, 18)           41490     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " def_conv_layer_red_1 (DefC  (None, 14, 14, 256)          589824    ['dropout_1[0][0]',           \n",
            " onvLayer_red)                                                       'conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 14, 14, 256)          0         ['def_conv_layer_red_1[0][0]',\n",
            "                                                                     'dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 14, 14, 256)          512       ['add_5[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.split_108 (TFOpLambda)   [(None, 14, 14, 128),        0         ['layer_normalization_2[0][0]'\n",
            "                              (None, 14, 14, 128)]                  ]                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 256)          33024     ['tf.split_108[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_273 (Reshape)       (None, 196, 256)             0         ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_272 (Reshape)       (None, 196, 256)             0         ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " permute_2 (Permute)         (None, 256, 196)             0         ['reshape_273[0][0]']         \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_220 (TFOp  (None, 196, 196)             0         ['reshape_272[0][0]',         \n",
            " Lambda)                                                             'permute_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_220[0][0]']\n",
            "                                                                                                  \n",
            " reshape_274 (Reshape)       (None, 196, 256)             0         ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_221 (TFOp  (None, 196, 256)             0         ['activation_2[0][0]',        \n",
            " Lambda)                                                             'reshape_274[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_275 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_221[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 128)          32896     ['reshape_275[0][0]']         \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 14, 14, 128)          0         ['tf.split_108[0][1]',        \n",
            "                                                                     'conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 256)          33024     ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " reshape_277 (Reshape)       (None, 196, 256)             0         ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_276 (Reshape)       (None, 196, 256)             0         ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " permute_3 (Permute)         (None, 256, 196)             0         ['reshape_277[0][0]']         \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_222 (TFOp  (None, 196, 196)             0         ['reshape_276[0][0]',         \n",
            " Lambda)                                                             'permute_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 196, 196)             0         ['tf.linalg.matmul_222[0][0]']\n",
            "                                                                                                  \n",
            " reshape_278 (Reshape)       (None, 196, 256)             0         ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " tf.linalg.matmul_223 (TFOp  (None, 196, 256)             0         ['activation_3[0][0]',        \n",
            " Lambda)                                                             'reshape_278[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_279 (Reshape)       (None, 14, 14, 256)          0         ['tf.linalg.matmul_223[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 14, 14, 128)          32896     ['reshape_279[0][0]']         \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 14, 14, 128)          0         ['conv2d_11[0][0]',           \n",
            "                                                                     'conv2d_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 14, 14, 256)          33024     ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 14, 14, 256)          0         ['add_5[0][0]',               \n",
            "                                                                     'conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 14, 14, 256)          512       ['add_8[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 14, 14, 256)          65792     ['layer_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 14, 14, 256)          0         ['add_8[0][0]',               \n",
            "                                                                     'conv2d_15[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 256)                  0         ['add_9[0][0]']               \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 8)                    2056      ['global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13570722 (51.77 MB)\n",
            "Trainable params: 13540514 (51.65 MB)\n",
            "Non-trainable params: 30208 (118.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(parallel_model,train_gen,val_gen,test_gen,mag,image_size,'maxvit',lr1,lr2,4,100)"
      ],
      "metadata": {
        "id": "_6LvLQM-S6Vp",
        "outputId": "15f93c28-5031-40ab-dad2-822657b3379b",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 [==============================] - 149s 960ms/step - loss: 1.8884 - acc: 0.4073\n",
            "Test loss and accuracy for model 40epoch+01.h5 : [1.8883780241012573, 0.40734556317329407]\n",
            "150/150 [==============================] - 76s 430ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[  7   0   0   0   7  14   0   2]\n",
            " [  0 154   0   0   5 123   0   1]\n",
            " [  4   1  13   0   0  55   1   3]\n",
            " [  0  27   0   0   2  18   0   0]\n",
            " [  0  10   0   0   8  45   0   0]\n",
            " [  0   0   0   0   0  34   0   0]\n",
            " [  2   1   3   0   3   7   6   0]\n",
            " [  0   3   0   0   0  18   0  22]]\n",
            "Classification report for model 40epoch+01.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.54      0.23      0.33        30\n",
            "           F       0.79      0.54      0.64       283\n",
            "          PT       0.81      0.17      0.28        77\n",
            "          TA       0.00      0.00      0.00        47\n",
            "          DC       0.32      0.13      0.18        63\n",
            "          LC       0.11      1.00      0.20        34\n",
            "          MC       0.86      0.27      0.41        22\n",
            "          PC       0.79      0.51      0.62        43\n",
            "\n",
            "    accuracy                           0.41       599\n",
            "   macro avg       0.53      0.36      0.33       599\n",
            "weighted avg       0.63      0.41      0.45       599\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150/150 [==============================] - 73s 445ms/step - loss: 0.5191 - acc: 0.8347\n",
            "Test loss and accuracy for model 40epoch+06.h5 : [0.5190694332122803, 0.8347245454788208]\n",
            "150/150 [==============================] - 69s 416ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 17   3   4   0   1   5   0   0]\n",
            " [  0 250   9   0   2  22   0   0]\n",
            " [  0   0  76   0   0   1   0   0]\n",
            " [  0  22   3  19   2   1   0   0]\n",
            " [  0   2   0   0  53   8   0   0]\n",
            " [  0   0   0   0   0  34   0   0]\n",
            " [  0   0   3   0   1   0  18   0]\n",
            " [  0   1   2   0   2   5   0  33]]\n",
            "Classification report for model 40epoch+06.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      0.57      0.72        30\n",
            "           F       0.90      0.88      0.89       283\n",
            "          PT       0.78      0.99      0.87        77\n",
            "          TA       1.00      0.40      0.58        47\n",
            "          DC       0.87      0.84      0.85        63\n",
            "          LC       0.45      1.00      0.62        34\n",
            "          MC       1.00      0.82      0.90        22\n",
            "          PC       1.00      0.77      0.87        43\n",
            "\n",
            "    accuracy                           0.83       599\n",
            "   macro avg       0.87      0.78      0.79       599\n",
            "weighted avg       0.88      0.83      0.84       599\n",
            "\n",
            "150/150 [==============================] - 72s 435ms/step - loss: 0.5729 - acc: 0.8581\n",
            "Test loss and accuracy for model 40epoch+21.h5 : [0.5729444026947021, 0.8580968379974365]\n",
            "150/150 [==============================] - 71s 428ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 30   0   0   0   0   0   0   0]\n",
            " [  1 271   0   0   0  11   0   0]\n",
            " [  4   0  73   0   0   0   0   0]\n",
            " [  5  15   0  20   0   7   0   0]\n",
            " [  8  16   0   0  35   4   0   0]\n",
            " [  0   0   0   0   0  34   0   0]\n",
            " [  4   0   1   0   0   0  17   0]\n",
            " [  8   0   1   0   0   0   0  34]]\n",
            "Classification report for model 40epoch+21.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.50      1.00      0.67        30\n",
            "           F       0.90      0.96      0.93       283\n",
            "          PT       0.97      0.95      0.96        77\n",
            "          TA       1.00      0.43      0.60        47\n",
            "          DC       1.00      0.56      0.71        63\n",
            "          LC       0.61      1.00      0.76        34\n",
            "          MC       1.00      0.77      0.87        22\n",
            "          PC       1.00      0.79      0.88        43\n",
            "\n",
            "    accuracy                           0.86       599\n",
            "   macro avg       0.87      0.81      0.80       599\n",
            "weighted avg       0.90      0.86      0.85       599\n",
            "\n",
            "150/150 [==============================] - 72s 435ms/step - loss: 0.2527 - acc: 0.9316\n",
            "Test loss and accuracy for model 40epoch+26.h5 : [0.25271448493003845, 0.9315525889396667]\n",
            "150/150 [==============================] - 69s 422ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 30   0   0   0   0   0   0   0]\n",
            " [  0 275   5   1   0   1   0   1]\n",
            " [  0   0  76   0   0   0   0   1]\n",
            " [  0  21   4  22   0   0   0   0]\n",
            " [  0   2   2   0  58   0   0   1]\n",
            " [  0   1   0   0   0  33   0   0]\n",
            " [  0   0   1   0   0   0  21   0]\n",
            " [  0   0   0   0   0   0   0  43]]\n",
            "Classification report for model 40epoch+26.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00        30\n",
            "           F       0.92      0.97      0.95       283\n",
            "          PT       0.86      0.99      0.92        77\n",
            "          TA       0.96      0.47      0.63        47\n",
            "          DC       1.00      0.92      0.96        63\n",
            "          LC       0.97      0.97      0.97        34\n",
            "          MC       1.00      0.95      0.98        22\n",
            "          PC       0.93      1.00      0.97        43\n",
            "\n",
            "    accuracy                           0.93       599\n",
            "   macro avg       0.96      0.91      0.92       599\n",
            "weighted avg       0.93      0.93      0.93       599\n",
            "\n",
            "150/150 [==============================] - 71s 428ms/step - loss: 0.1272 - acc: 0.9733\n",
            "Test loss and accuracy for model 40epoch+36.h5 : [0.12715810537338257, 0.9732888340950012]\n",
            "150/150 [==============================] - 70s 429ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 30   0   0   0   0   0   0   0]\n",
            " [  0 281   0   0   0   1   1   0]\n",
            " [  0   0  77   0   0   0   0   0]\n",
            " [  0  13   0  34   0   0   0   0]\n",
            " [  0   0   0   0  63   0   0   0]\n",
            " [  0   0   0   0   0  34   0   0]\n",
            " [  0   0   1   0   0   0  21   0]\n",
            " [  0   0   0   0   0   0   0  43]]\n",
            "Classification report for model 40epoch+36.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00        30\n",
            "           F       0.96      0.99      0.97       283\n",
            "          PT       0.99      1.00      0.99        77\n",
            "          TA       1.00      0.72      0.84        47\n",
            "          DC       1.00      1.00      1.00        63\n",
            "          LC       0.97      1.00      0.99        34\n",
            "          MC       0.95      0.95      0.95        22\n",
            "          PC       1.00      1.00      1.00        43\n",
            "\n",
            "    accuracy                           0.97       599\n",
            "   macro avg       0.98      0.96      0.97       599\n",
            "weighted avg       0.97      0.97      0.97       599\n",
            "\n",
            "150/150 [==============================] - 71s 431ms/step - loss: 0.0947 - acc: 0.9716\n",
            "Test loss and accuracy for model 40epoch+81.h5 : [0.09471437335014343, 0.9716193675994873]\n",
            "150/150 [==============================] - 70s 421ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 30   0   0   0   0   0   0   0]\n",
            " [  0 280   0   2   0   1   0   0]\n",
            " [  0   0  77   0   0   0   0   0]\n",
            " [  0  13   0  34   0   0   0   0]\n",
            " [  0   1   0   0  62   0   0   0]\n",
            " [  0   0   0   0   0  34   0   0]\n",
            " [  0   0   0   0   0   0  22   0]\n",
            " [  0   0   0   0   0   0   0  43]]\n",
            "Classification report for model 40epoch+81.h5 :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      1.00      1.00        30\n",
            "           F       0.95      0.99      0.97       283\n",
            "          PT       1.00      1.00      1.00        77\n",
            "          TA       0.94      0.72      0.82        47\n",
            "          DC       1.00      0.98      0.99        63\n",
            "          LC       0.97      1.00      0.99        34\n",
            "          MC       1.00      1.00      1.00        22\n",
            "          PC       1.00      1.00      1.00        43\n",
            "\n",
            "    accuracy                           0.97       599\n",
            "   macro avg       0.98      0.96      0.97       599\n",
            "weighted avg       0.97      0.97      0.97       599\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-3edca79327a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'maxvit'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-40832f0954de>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_gen, val_gen, test_gen, mag, image_size, save_name, lr1, lr2, Epochs1, Epochs2)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Return something meaningful, e.g., history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAAHWCAYAAAAM3zzjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACfPklEQVR4nOzdd3wT9R/H8dddVhdt2WWWvQUXKsoUFNy4FZWhOBFxIIr+VEDcCogDRBAQUZTpXgiKW0FBQPbeuy0Umvn9/XHJpemgLbRJaj7PxyOPJneX5J3rN/e58b2LppRSCCGEEP9xeqQDCCGEEOEgBU8IIURMkIInhBAiJkjBE0IIEROk4AkhhIgJUvCEEELEBCl4QgghYoIUPCGEEDFBCp4QQoiYIAUvyqxbt44LL7yQlJQUNE1j3rx5pfr6mzdvRtM0pkyZUqqvW5517tyZzp07l9rrHTlyhP79+5OWloamadx///2l9trRqG/fvtSrV++Enlva8/6/RNM07r333kjHOGnff/89mqYxa9asSEeRgleQDRs2cOedd9KgQQPi4uJITk7mvPPO49VXX+XYsWNl+t59+vRh+fLlPPPMM0ybNo0zzzyzTN8vnPr27YumaSQnJxc4H9etW4emaWiaxssvv1zi19+5cyfDhg1j6dKlpZD2xD377LNMmTKFu+++m2nTpnHLLbdENM9/TUZGBtWqVSt0Iep0OnnkkUeoWbMm8fHxnH322Xz77bcRSBr9lixZwqWXXkpaWhpJSUm0bt2asWPH4vV6Q6b78MMPufnmm2ncuDGappXZSsqwYcPMZUDuW1xcXKm8vrVUXuU/5PPPP+faa6/F4XDQu3dvWrVqhcvl4qeffuLhhx9m5cqVTJgwoUze+9ixY/z66688/vjjZbZml56ezrFjx7DZbGXy+kWxWq0cPXqUTz/9lOuuuy5k3PTp04mLiyMnJ+eEXnvnzp0MHz6cevXqceqppxb7ed98880JvV9hFixYwDnnnMNTTz1Vqq8rDE8++SRHjx4tdHzfvn2ZNWsW999/P40bN2bKlClcfPHFLFy4kPbt24cxaXRbsmQJ5557Lo0bN+aRRx4hISGBL7/8kkGDBrFhwwZeffVVc9px48axZMkS2rZty4EDB8o827hx40hKSjIfWyyWUnldKXi5bNq0iRtuuIH09HQWLFhAjRo1zHEDBgxg/fr1fP7552X2/vv27QMgNTW1zN6jNNeWToTD4eC8887jgw8+yFfw3n//fS655BJmz54dlixHjx4lISEBu91eqq+7d+9eWrRoUWqv5/F48Pl8pZ6zPFqxYgXjxo3jySef5Mknn8w3/o8//mDGjBm89NJLDB48GMBccR0yZAi//PJLuCNHROfOnalXr95xD1289dZbACxatIhKlSoBcOedd9KpUyemTJkSUvCmTZtGrVq10HWdVq1alWl2gGuuuYYqVaqU+uvKLs1cXnzxRY4cOcKkSZNCil1Ao0aNGDRokPnY4/Hw9NNP07BhQxwOB/Xq1eOxxx7D6XSGPK9evXpceuml/PTTT5x11lnExcXRoEED3n33XXOaYcOGkZ6eDsDDDz+MpmnmcZHCjpEENv9z+/bbb2nfvj2pqakkJSXRtGlTHnvsMXN8YcfwFixYQIcOHUhMTCQ1NZUrrriCVatWFfh+69evp2/fvqSmppKSkkK/fv2Ou8adV69evfjyyy/JyMgwh/3555+sW7eOXr165Zv+4MGDDB48mFNOOYWkpCSSk5O56KKLWLZsmTnN999/T9u2bQHo16+fuSsk8Dk7d+5Mq1atWLJkCR07diQhIcGcL3mPI/Xp04e4uLh8n7979+5UrFiRnTt3Fvi5AscqNm3axOeff25m2Lx5M2AUwttuu43q1asTFxdHmzZtmDp1ashrBP4/L7/8MmPGjDHb1r///lvo/Awc65k5cyYtWrQgPj6edu3asXz5csBYsDVq1Ii4uDg6d+5s5slt5syZnHHGGcTHx1OlShVuvvlmduzYkW+6efPm0apVK+Li4mjVqhVz584tMJPP52PMmDG0bNmSuLg4qlevzp133smhQ4cK/RzFMWjQIK688ko6dOhQ4PhZs2ZhsVi44447zGFxcXHcdttt/Prrr2zbti1k+vfee8/83JUqVeKGG27IN03utnPuuecSHx9P/fr1GT9+fL73L87/GIz58+qrr3LKKacQFxdH1apV6dGjB4sXL843bWCeOxwOWrZsyVdffVWseVWUrKws4uLi8q1g16hRg/j4+JBhderUQddPrlz4fD6eeeYZateuTVxcHF27dmX9+vUFTquUIisri1L/MR8lTLVq1VINGjQo9vR9+vRRgLrmmmvUG2+8oXr37q0A1bNnz5Dp0tPTVdOmTVX16tXVY489pl5//XV1+umnK03T1IoVK5RSSi1btkyNHj1aAerGG29U06ZNU3PnzjXfJz09Pd/7P/XUUyr3v3DFihXKbrerM888U7366qtq/PjxavDgwapjx47mNJs2bVKAmjx5sjns22+/VVarVTVp0kS9+OKLavjw4apKlSqqYsWKatOmTfne77TTTlNXXXWVevPNN1X//v0VoIYMGVKs+ZWYmKiysrJUXFycmjRpkjnu/vvvV82aNTPzvfTSS+a4P//8UzVs2FA9+uij6q233lIjRoxQtWrVUikpKWrHjh1KKaV2796tRowYoQB1xx13qGnTpqlp06apDRs2KKWU6tSpk0pLS1NVq1ZVAwcOVG+99ZaaN2+eOa5Tp07m+x06dEjVrl1btW3bVnk8HqWUUuPHj1eAmjZtWqGfb/fu3WratGmqSpUq6tRTTzUzHDlyRB09elQ1b95c2Ww29cADD6ixY8eqDh06KECNGTMm3/+nRYsWqkGDBur5559Xo0ePVlu2bCn0fQHVunVrVadOHfX888+r559/XqWkpKi6deuq119/XbVo0UK98sor6n//+5+y2+2qS5cuIc+fPHmyAlTbtm3V6NGj1aOPPqri4+NVvXr11KFDh8zpvv76a6XrumrVqpUaNWqUevzxx1VKSopq2bJlvvbZv39/ZbVa1e23367Gjx+vHnnkEZWYmKjatm2rXC6XOV3eeX88H330kYqLi1ObNm1SCxcuVICaOXNmyDTdunVTzZs3z/fc+fPnK0B98skn5rCRI0cqTdPU9ddfr958802z3ef93J06dVI1a9ZU1apVU/fee68aO3asat++vQJC2nBx/8dKKdW3b18FqIsuukiNGTNGvfzyy+qKK65Qr732mjkNoNq0aaNq1Kihnn76aTVmzBjVoEEDlZCQoPbv33/cedWpUyfVp0+f404zbtw4Baj+/furf//9V23evFmNGzdO2Wy2fHlza9myZbH/Z0op83912mmnqTPOOEONHj1aDRs2TCUkJKizzjorZNrAMiYpKUkBKjExUd10001q9+7dxX6/45GC55eZmakAdcUVVxRr+qVLl5qNJbfBgwcrQC1YsMAclp6ergC1aNEic9jevXuVw+FQDz30kDmsoIW9UsUveIGCuW/fvkJzF1TwTj31VFWtWjV14MABc9iyZcuUruuqd+/e+d7v1ltvDXnNK6+8UlWuXLnQ98z9ORITE5VSSl1zzTWqa9euSimlvF6vSktLU8OHDy9wHuTk5Civ15vvczgcDjVixAhz2J9//pnvswV06tRJAWr8+PEFjsv7Bf76668VoEaOHKk2btyokpKS8q3IFCY9PV1dcsklIcPGjBmjAPXee++Zw1wul2rXrp1KSkpSWVlZ5ucCVHJystq7d2+x3g9QDocjZOXkrbfeUoBKS0szX1sppYYOHaoAc1qXy6WqVaumWrVqpY4dO2ZO99lnnylAPfnkk+awU089VdWoUUNlZGSYw7755hsFhLTPH3/8UQFq+vTpITm/+uqrfMOLW/COHj2q6tatq4YOHaqUUoUWvJYtW6rzzz8/3/NXrlwZ8v/fvHmzslgs6plnngmZbvny5cpqtYYMD7SdV155xRzmdDrN702ggBf3f7xgwQIFqPvuuy9fTp/PZ94HlN1uV+vXrzeHLVu2TAEhhbEgxSl4Ho9H3XvvvcpmsylAAcpisahx48Yd93knWvCaN2+unE6nOfzVV19VgFq+fLk5bMyYMeree+9V06dPV7NmzVKDBg1SVqtVNW7cWGVmZhb7PQsjuzT9srKyAKhQoUKxpv/iiy8AePDBB0OGP/TQQwD5jvW1aNEiZDdM1apVadq0KRs3bjzhzHkFdk18/PHH+Hy+Yj1n165dLF26lL59+5r78QFat27NBRdcYH7O3O66666Qxx06dODAgQPmPCyOXr168f3337N7924WLFjA7t27C9ydCcZxv8DuFK/Xy4EDB8zdtX/99Vex39PhcNCvX79iTXvhhRdy5513MmLECK666iri4uLMYx4n4osvviAtLY0bb7zRHGaz2bjvvvs4cuQIP/zwQ8j0V199NVWrVi3263ft2jVkt/fZZ59tvk7uNh0YHmh3ixcvZu/evdxzzz0hx3YvueQSmjVrZrbjQDvp06cPKSkp5nQXXHBBvuOVM2fOJCUlhQsuuID9+/ebtzPOOIOkpCQWLlxY7M8V8Pzzz+N2u0N2zxfk2LFjOByOfMMDny3QO3jOnDn4fD6uu+66kIxpaWk0btw4X0ar1cqdd95pPrbb7dx5553s3buXJUuWAMX/H8+ePRtN0wrs1JT3EEW3bt1o2LCh+bh169YkJyeHLDfcbnfIZ9i/fz9utxun05lveO7lgsVioWHDhnTv3p2pU6fy4YcfctlllzFw4MBSPx0KjEMNuY9DB5aHuT/LoEGDeO211+jVqxdXX301Y8aMYerUqaxbt44333zzpDNIwfNLTk4G4PDhw8WafsuWLei6TqNGjUKGp6WlkZqaypYtW0KG161bN99rVKxY8aSPaeR2/fXXc95559G/f3+qV6/ODTfcwEcffXTc4hfI2bRp03zjmjdvzv79+8nOzg4ZnvezVKxYEaBEn+Xiiy+mQoUKfPjhh0yfPp22bdvmm5cBPp+P0aNH07hxYxwOB1WqVKFq1ar8888/ZGZmFvs9a9WqVaKOHy+//DKVKlVi6dKljB07lmrVqhX7uXlt2bKFxo0b5zsO0rx5c3N8bvXr1y/R6+f9nwSKUp06dQocHvhfHe//36xZM3N84G/jxo3zTZf3uevWrSMzM5Nq1apRtWrVkNuRI0fYu3dviT7b5s2beemll3jmmWdCeu4VJD4+Pt8xdMDs+Rs4NrVu3TqUUjRu3DhfxlWrVuXLWLNmTRITE0OGNWnSxMwHxf8fb9iwgZo1a4asYBamOMuNn3/+Od9n+OWXX5gxY0a+4Vu3bjWf9/zzz/PCCy/wwQcf0Lt3b6677jrmzp1L+/btGTBgAB6Pp8h8JXGiy41evXqRlpbG/PnzTzqD9NL0S05OpmbNmqxYsaJEz8u7RlaYwrrVqmIclC3sPfKeKxMfH8+iRYtYuHAhn3/+OV999RUffvgh559/Pt98802pde09mc8S4HA4uOqqq5g6dSobN25k2LBhhU777LPP8sQTT3Drrbfy9NNPU6lSJXRd5/777y/2liyQ70B8Uf7++29zwbd8+fKQNfeyVtKshf1PSuN/VVI+n49q1aoxffr0AseXZMsVjNMQatWqFdLhZvfu3YDRs3nz5s3UrVsXXdepUaNGgZ1tdu3aBRiFK5BR0zS+/PLLAudRUYU1XIrz/2vTpk2+8wwfeugh0tLSePjhh0OGp6WlmffffPNNzj///Hyf9fLLL+fBBx9k8+bNha6EnoiTaYt16tTh4MGDJ51BCl4ul156KRMmTODXX3+lXbt2x502PT0dn8/HunXrzDU4gD179pCRkWH2uCwNFStWDOnRGJB3qwBA13W6du1K165dGTVqFM8++yyPP/44CxcupFu3bgV+DoA1a9bkG7d69WqqVKmSb822tPTq1Yt33nkHXde54YYbCp1u1qxZdOnShUmTJoUMz8jICOm6XNyVj+LIzs6mX79+tGjRgnPPPZcXX3yRK6+80uwJWlLp6en8888/+Hy+kC2A1atXm+MjIff///zzzw8Zt2bNGnN84O+6devyvUbettOwYUPmz5/PeeedV+LCXZCtW7eyfv16GjRokG/cPffcAxhbCampqZx66qksXLiQrKwsc68NwO+//w5gnp/ZsGFDlFLUr1/f3FI7np07d5KdnR3yXVi7di2AuSu5uP/jhg0b8vXXX3Pw4MFibeUVpWLFivm+2xUrVqRGjRoFfucD9uzZk2+lGYxdpECpb+GdKKUUmzdv5rTTTjvp15JdmrkMGTKExMRE+vfvz549e/KNz30y5sUXXwzAmDFjQqYZNWoUYBwDKS0NGzYkMzOTf/75xxy2a9eufF3CC1oDCnzBC9rNA0YX5FNPPZWpU6eGFNUVK1bwzTffmJ+zLHTp0oWnn36a119/PWTNMy+LxZJvLXDmzJn51uQDC6OCVg5K6pFHHmHr1q1MnTqVUaNGUa9ePfr06VPofCzKxRdfzO7du/nwww/NYR6Ph9dee42kpCQ6dep00plPxJlnnkm1atUYP358yGf78ssvWbVqldmOc7eT3LuRv/3223ynTFx33XV4vV6efvrpfO/n8XhK/P8ZOXIkc+fODbkFXnvIkCHMnTvX/N9fc801eL3ekItDOJ1OJk+ezNlnn23u4r3qqquwWCwMHz48X9tSSuU7udrj8YQcw3W5XLz11ltUrVqVM844Ayj+//jqq69GKcXw4cPzfday3PLOq0mTJnz77bchn9Xr9fLRRx9RoUKFkGOHxXX06FFWr17N/v37TyhT4Fzk3MaNG8e+ffvo0aPHCb1mbrKFl0vDhg15//33uf7662nevHnIlVZ++eUXZs6cSd++fQFjN0KfPn2YMGECGRkZdOrUiT/++IOpU6fSs2dPunTpUmq5brjhBh555BGuvPJK7rvvPo4ePcq4ceNo0qRJSKeNESNGsGjRIi655BLS09PZu3cvb775JrVr1z7uFSZeeuklLrroItq1a8dtt93GsWPHeO2110hJSTnursaTpes6//vf/4qc7tJLL2XEiBH069ePc889l+XLlzN9+vR8a/wNGzYkNTWV8ePHU6FCBRITEzn77LNLfDxswYIFvPnmmzz11FOcfvrpAEyePJnOnTvzxBNP8OKLL5bo9QDuuOMO3nrrLfr27cuSJUuoV68es2bN4ueff2bMmDHF7ixV2mw2Gy+88AL9+vWjU6dO3HjjjezZs4dXX32VevXq8cADD5jTPvfcc1xyySW0b9+eW2+9lYMHD/Laa6/RsmVLjhw5Yk7XqVMn7rzzTp577jmWLl3KhRdeiM1mY926dcycOZNXX32Va665ptgZC2q7gQ5abdu2pWfPnubws88+m2uvvZahQ4eyd+9eGjVqxNSpU9m8eXPIHoKGDRsycuRIhg4dyubNm+nZsycVKlRg06ZNzJ07lzvuuMM8cR2MXaEvvPACmzdvpkmTJnz44YcsXbqUCRMmmFctKu7/uEuXLtxyyy2MHTuWdevW0aNHD3w+Hz/++CNdunQJ2/UzH330UW6++WbOPvts7rjjDuLj4/nggw9YsmQJI0eODLka06JFi1i0aBFgFKXs7GxGjhwJQMeOHenYsSNgnPjfpUsXnnrqqRNadqSnp3P99deb5yf+9NNPzJgxg1NPPTWk09AJO+l+nv9Ba9euVbfffruqV6+estvtqkKFCuq8885Tr732msrJyTGnc7vdavjw4ap+/frKZrOpOnXqqKFDh4ZMo1TB3dSVyt8lu7DTEpQyun+3atVK2e121bRpU/Xee+/lOy3hu+++U1dccYWqWbOmstvtqmbNmurGG29Ua9euzfceebvuz58/X5133nkqPj5eJScnq8suu0z9+++/IdME3i/vaQ+B87hyd4svSO7TEgpT2GkJDz30kKpRo4aKj49X5513nvr1118L7NL+8ccfqxYtWiir1RryOTt16qRatmxZ4Hvmfp2srCyVnp6uTj/9dOV2u0Ome+CBB5Su6+rXX3897mco7P+9Z88e1a9fP1WlShVlt9vVKaecku//cLw2UBhADRgwoFivU1h3/g8//FCddtppyuFwqEqVKqmbbrpJbd++Pd97zZ49WzVv3lw5HA7VokULNWfOnEJPm5kwYYI644wzVHx8vKpQoYI65ZRT1JAhQ9TOnTvNaUpyHl5xPodSSh07dkwNHjxYpaWlKYfDodq2bau++uqrAl9n9uzZqn379ioxMVElJiaqZs2aqQEDBqg1a9aEZGzZsqVavHixateunYqLi1Pp6enq9ddfz/d6xfkfK2WcEvDSSy+pZs2aKbvdrqpWraouuugitWTJEnOagv6vShntq6hTDopzWoJSxqkinTp1Cslb0Kk7ge9+QbennnrKnC7wfyloWN7/VUHLov79+6sWLVqoChUqKJvNpho1aqQeeeSRkFNrToamVBi3oYUQopzp3Lkz+/fvL3GHNhF95BieEEKImCAFTwghREyQgieEECImyDE8IYQQMUG28IQQQsQEKXhCCCFiQsydeO7z+di5cycVKlQo1UtRCSGECD+lFIcPH6ZmzZpF/khtzBW8nTt35ruCvBBCiPJt27Zt1K5d+7jTxFzBC1ze57d/NpAUocs5nYyqyfl/60sIIWLV4awsGtWvU6zL88VcwQvsxkyqUIEKua6mXl4kS8ETQoh8inOISjqtCCGEiAlS8IQQQsQEKXhCCCFighQ8IYQQMUEKnhBCiJggBU8IIURMkIInhBAiJkjBK6baNVKoUznOvNX1/61VuyJ1/Y9LcqvWs0ekPxLWoY9ga9YIh00Lvdl1+OCDSMcr2uhROOy6mTvOf7MMGhjpZMf31JMFz/MPP4x0skJZpk4x529hN4fDEtGM+uxZWAcNxN65A45KycTZNGy9bwbAUb1y4blrpwFgvaO/OUxbvz6SHyVUOWwvHDiAZdJEbG1a5c/usMCnn0YkVsydeH6iNJcTDVAAmgb+X1WyHDuGAo52vwRPm1MBsK5bQ9y3X6MfORx8jtUGHjeBUyOPdese5k+Qn+WVl0CpfJ9LUwpH7144D2fCHXdFOGXBtP8Nxf7C88Hs/r8aYH3zdbydOsNVV0csX2G0AXdhn/BWMLeug89nzPObb8CZcwz69I1syAL42pyKSkxEy84GgvM68BfAd/oZEUpnsD47Ev2fZaikJFTt2mirVwOgjX4FDh4E/PPcZgO328zvufQy9M8+xTp5EiopCe3IkUh9hHzKa3uxzJqJ7d67Q9qJuXzx+XBcdTnOGTPh6mvCmivmfg8vKyuLlJQUVmzaW6IrrThmzcB72pl4GjTE8fMiql/RnexrbiD+y8/Qs4/gszvYvisTAOtfi6lxQXvA+Gfve28Wxy66FG3lP9TueBYa4GranN2//F3i/NVK8UorDpuGBviSk3EdyAwOt+toSqEApzs6m0fu7OrMtmibN+HreRXWUS8DoHQdp9Mb2ZAFMHPHxeE6fCw4vDzN85o18bw7HXu3LnhvvAl9xvtGdqsV5zF3xPLp3y9E1aqNatQIfdEP+fPlaROO5AS0Y8dQNjtUqoivU2e03bvRF/2Ac9U6VKNGEfssZsZy2l70hQuwXdg1//Jl924cdWoYRVDTcLp8J/1eWVlZVK+cQmZmJslFLNNll2YxOa+5AU/DRsZaSi6Hb+kLgOZ2mcOq3tEHDaPYeWrU4tiFFwGQ+PNP5tqwbc2qsg99HNr/hpprXq5tu0LGud6eFHyw+M+w5iqO3Nm9Q4aiL1yAe+JkSEwE/3B8vqjLrg24KzjPd+0LGef87EtzS5UfF4U5WdG00a8Es6/ZEByRkWEuePF44N+VkQkI+Dp3QTVuHPodXfVvMF+NGiHTO3/4yRjudoHHg3vsG2FMW7Ty3F7Ud98WvHxJS8NzW3//RCrs31EpeCcp6YP3AFBxceYw69bN5v3sm/uAxTi2kTTtHWPawMgd28MRsUC2SRONO7oOCQkh4/QdOwCjYNvuuzfMyYqWO7t15HC8AwehOnQMmSYas9venx58kJQUOvJCYxe3BtjuviN8oYrJNu5N447dDrnaurZ+XfA+YHt0SJiTHZ+2LpgPrxd9+ntYnn8Wy9hX0TONrQ4N8KXXg8qVI5KxMOW6vRxn+ULjJkBkvqNyDK+Eajatg37UOI6RMGuGuRaz751cjdNr7DZRwJFb+gFg//M37P+uwN2wMdYN69CA5HffIWvok2HNH6BlZBgZExKwjHrZOG6RmYm+ZDH6zz+Z+95zL9CihZldAXXr4hn5bJ4J/McKoiy7efzLbj/+dNu2hSNOiWh7dgOgUlNDh2/ehLJYjJU6lwttxYoIpCucluPfDajraLt3Y+97S8j4wMqnti90CyoalOv2kmv5EsLjwTLt3eB0Yf6OyhZeCVn270M/ehTA3A+9b+oMnBdenG9aV6MmeGsZv72XNNXYTXik963meOuWTWUfuDD+okxcHNZRL2N9ejjWsWPQf/4Jb/cexoF9gJycyGUsjD+7pny4J06B+PjQ8YEfgYy27IHD5YUtwAK5Xa6Cx0eS239sLjF0S0Nzu/F17xH8TNnR0+EDMHZtAyo5Gdc335GzfTc5mdk4/1qGyr2LMyuzkBeIoPLcXnItX3KzPvYo+soVqMBu5zB/R6XgldC2Azns+fhrADwVK4FSVO1zA6kP35dvWteZZwOgZWWS8PFslN1O9o235Jsu0pzbd5PjVuRs341r5hy0TRuDC7gopuLiUe3aRTpGzPPefmekIxStYiV8Xc6H6tUhIQF9/rdou3aZhxvwr8SKsmN5bSzW0a/ga9YMrJHZuSgF7yQ4u17IgZdeBaDCOxMAsK3+1+yYohzGmlniRx+gHz3K0UuvwFe5ivl8T3r9sOYNEfii517Dql4dX88rcX3xTXBYnjW0iPN4gmu+lkKar3+tPuqyB9ZqC1sjD+QuYhdWRAS2+ANbcJuMvRMqIQHfRRcXugUYcYGtoFxbntratVifeBxPn37m90DzeCKR7vjKc3vJs3yxvPE6tgcH4WvRAte3CwvdAixr5bLg/frrr1gsFi655JJIR+HorcbarQY45n9t7roEcPz5GxDsrHKkT38I7NsGsnLt3gy3wLEYraA12/T04HT1IliUC3LkiLlCoWdnh5xAbH16OACavyAqW3QtCJS/F6lWxC4oVadOOOKUiKpunJwdODZj+fwzY3iDhubxOwDVqlVE8hVGxRm7uwO5AbRV/6I5nVinTjb/F5pSxNk09EU/AOBo3th4/PG8cEc2lev2kmv5Ynl1DLb7B+Jr2coodmlpwV3NjRqHNVe5LHiTJk1i4MCBLFq0iJ07d0Y6jsmr20j46H3zQLh97Rrsi//AvuIf3A0b42zficp332ousKlVO0JJwR3oGuzz5d+d89OPweleeCmMqYrB4cB7yimA/6ThW3rj6Xcbnn634Tv1NHO4ArwD8+9mjiR3r5uCD/Ke3PyNsZtcAe5xE8IXqpjcd99j3HG5ICMDfb6xF0A1bAR//wX+rv/u51+MXMgCqMb+BarLZW5tqPR6Rpu57PLgRQsSk/D0uw2VZhR27zXXGo/T64U/tF+5bi+5li+2wQ/ga3MqrvkLoVo1c/miAPfY18Oaq9ydeH7kyBFq1KjB4sWLeeqpp2jdujWPPfZYsZ9/IieeJ416gZwOnfG0NY7JOX76wTjxvOc1xH/7FXr2ERRw4M1JVLnnNo6d3Y64338FwN2wEfYN6zk04nkOX9aTOqc1QwOcLU9hz6KSn4NSWieea2vXYm/ZNP+JoT4fjjhrVJ/UCgWfNG8dMczcypMTz0tfIKMvNRXdv8XkvfEm9HlzjBO47Xac2c7IhvTTf/g+34nnvpo1cW3ZYU7jqBCP5i+C7qefwfvoY9i7dpYTz0uJmV3XjfMIK1UyhsdZ0bzeUvuO/qdPPP/oo49o1qwZTZs25eabb+add96hrGt28sRx1OjRybiOZpV4ql1p9MhMmDfLLHY5p7cl6V1/T8z7BuM88ywAbBvWo4CU54abxU7pOnsW/FqmmYuif/kFWCwoQM/KMq/P53BYzC+S66XREc14PK5HHg3NnmDHEih2gPODjyKarzCuO+40cufkmNcVdNi04MJr4uRIRyyU+5beRvZcuwf1D6YbxQ7wXnJZpKIZWT6eh+3Wvthu7YvlxecB0H7/FVU9zci9c6fZVhw2zSx23jPPxPvg4AgmL1x5bS/6u1PNU7Z0nw9H9crB7F6vsXcmApctLHcFb9KkSdx8s3FB2B49epCZmckPP/xQ6PROp5OsrKyQW0llX38TWCzGeWlKofn83eL94zXAtnM7cb/9gqdmLY5d0IO9Xy/C1eb04DTHjLUzT7XqbNu0N2K9lAJ8XbvhveMuc2EAmJ1BlKbhnPYB6v77IxWvSGrkczifezHYvTlXr1LPPfdG5XU0AdQb43E+8lhwngeOZWgazvdmROV1EQP09HrB3fF+ub8Dlr8WhzlRKH3ZUizTpho3/y4/feNG9N27Qq65GmgrStdxDRmK+5c/orPjB+W3veibjU5NuduH5vOFtpcIXJWnXO3SXLNmDa1atWLHjh1Uq1YNgHvvvZfMzEymTZtW4HOGDRvG8OHD8w0v6bU0o0VpXktTCCHKu5Ls0ixXBW/IkCG89NJLWCzBnyFRSuFwONi1axcpKSn5nuN0OnE6g8cVsrKyqFOnjhQ8IYT4DyhJwSs3lxbzeDy8++67vPLKK1x44YUh43r27MkHH3zAXXfl3yfscDhwOKRICCFErCs3Be+zzz7j0KFD3Hbbbfm25K6++momTZpUYMETQgghoBx1Wpk0aRLdunUrcLfl1VdfzeLFi/nnn38ikEwIIUR5UG628D49zk/Cn3XWWWV+aoIQQojyrdxs4QkhhBAnQwqeEEKImCAFTwghREyQgieEECImSMETQggRE6TgCSGEiAlS8IQQQsQEKXhCCCFighQ8IYQQMUEKnhBCiJggBU8IIURMkIInhBAiJkjBE0IIEROk4AkhhIgJUvCEEELEBCl4QgghYkK5+QHY0lY12UFysiPSMUqsYtt7Ix3hhBz68/VIRzhh5fnHhTVNi3QEIaKGbOEJIYSICVLwhBBCxAQpeEIIIWKCFDwhhBAxQQqeEEKImCAFTwghREyQgieEECImSMETQggRE6TgCSGEiAkxe6WV0qLPnoX+6mgsv/4CgAYoAIsF5+yP4ZJLyjyDu/p6vGcuAKs7ODAQxBmH5ave2LCZo3K6T4H47OO/qMtB3Bf9g+/R9He8zRcXOrl1aSesm1ud2Ac4AY5G9dC2bClwnEpNxbnvUNiyFNuBA1if/B+WubPR9u8HcrUXq5WcL76Bzp0jGPA4DhzA0aIJ2sGDBY5Wyck4D2SGJcqcVbP4cesP/LNnKcv3LOOw6zD9069h3C9V0Od/jbZrF+TkoAGeyhXZn+ogfvd+Eo96sChjnufYdbLOO5sqqzahHTgAbjca4Gvdhr+H9OWVuCUs2/M3u4/sItuVTVpSDVpVO4UBbQfRpX7XsHxO8C9fxo7B8svPQGSWLyfK8vBDWGZ+hLZjO5Are1wczs+/ho4dw55JtvBOknXgPVh//YW8F3DSvF4cPS+FObPLPIP39O/B5iZfCIC4HLxXTMBNrmK4Ly14XwE+/y33FbSOVAh5GZW6N/Q5ea625a25/kSin7idO0Pj6HowUkYGzP82vHmKwTJ7Jra330Lfvz9/e/F4iLvwfPj2m4hkK4pl1ky0gwfNeawApWnBeZ6VFbbsL/w0kvGLX+efPUupWaEWAOf8sgXr2+PRN20CjwcqVTYmzsggbcNuUrKNYhdgdfuotvBX9N27wWqFCskAaMv/4YybH6DhtE9oVKkJ17e8iYFnP8A5tc/lhy0Lufj9bgz//omwfE4A68ABWH/5OaLLlxNlfX0s+o7t+bPn5ODo2iki31EpeCdJ27cPAF9yMu75C437N96EsljQAMeN15V9iMMpkJ2E9u11OD6+B9vPPY3hB6oaSyYNvN1mmJPrgesr+sD+8d3EfTKAuE8GYP/mlmAhc+SEvIW5rPCB5c8LyDtSVd2Bt9JOwkGfNxfNbRRwX1oaTrfC6fTizHaidN2Y75ddHJYsJaEaNzHno69GTVzfLgDA2/MqlKahAXFXXBqxfMejmjQJNCV8NWsa89zlw7ltlznccXl4tjZevGA0y+9ey97BWYy9aBwAu2om4x4xEueK1TiPunB/NAuAbR1Px5MQB4D7/Q/x3jUAAM1qY9DFOulDbGzesQHv/Q8A4HngIZTNxogvc/jwvDcY1X0sT3d5jik9p7P0ztVUS6zGi788y67Du8LyWbV9xopmRJcvJ8rjAYy27nl5NAAqvR4qPt7IHoG2LgXvJGj/G2pupru2hX4BnPMXGgs3nw8W/1mmOeJ+upa4b/vgyK6Klmt9Sj9WEbwW40HCYXO4Ssgy7vgs6LmagKfVz8GtRIs35D1UJeOLpx2qjrfVb6Byrbf5dNDA0+K30vtQx2F5bqSRCXCt2xQcYbfjene6cd/jgX9XhiVPsS39O7ineU2uLeL4eDx33W3cj8bcgMqV3bVmQ3BEWhqeu+8x7ocpe6d6XWhUqXHIhbFXnpKGd+jjqKZNIdfwumnNUEONLTL9px/N4brdzsrru7I1wc1vO34JvniTpvg6dUZzudB/zTUcqJVci7NrnYtP+diUsbGMPl1QtCxfToQ2+pVg9rUbQsY5f/jJyO5yhb2tyzG8k2CbNNG4o+uQkBA6sn0HwKgftvvuxf3L7+ENF6Dy7+fUjlREVd4LFi85Z3yF7nCCMx5fjc3mNPqBtNAn2Y0tPuU4Co6j/tf1b694rWBxoVL2l9GHyJP/31XBnLNnoW3bCgmJqNat8V3Y3ZgGsA0ZjPuzL8OSqThs442tEex2iIsLHVk3HfDnHvoI7o8/C2+4ItjGvWnezzvPqVMX8Gd/dAjuTz6PUMpC2PzHr61WcAV37dt0Y7hVsxY+fS57s/fy587fcVgcNKnctMzimjHKw/KlEGZ7Kaitn3Y6aBqaUmFvL1LwToKWkQGAytsYA3QdfD609evCFyoXH26wGrsVyKxsDte2NIP0Nca3pc4GfLmfpIAjKViXXBh8HfvR4JZf0mHy0f1bg7k7zZQhze0y/gL2vreEjFM1awWnW7YsLHmKS9uzGzA61YTw+bC8N818qK9YEcZUxRPIXuA8twU7RGnRll35sEx7FwBf9x7on35q3FeKhZu/I8GWQPu6HYG/jekPHEBf8B0qIYG/Glfgs0XD8Pg87Di8nS/WfUpmTiajur9GlYQqZR492pcvx1NoWw+w28HpDHt7kV2aJ8PrX9DnXYMJsPh3J+bkFDy+rNXeZHaNivvh+mAsVzzsrw5Zqfk6n6ABiZlgdQWHBXp0KtD21cDx6R3gDi7ksIbu/gwXpevkLF9FTmY2zr+X47ntdti5IzjB0SJ6ooab/7gjiUkhg/VlS9FXrkAF2kv2kTAHK4Zcx0xztu8257nvlNZobnewGUVZdm2pMW+9F11sbv0DOD05OL1OHu8wjIrxFc3hlnfeRnM68Tw5jD+PruWZH4fzws/P8N4/U3F73Uy4bDJ3nHF3eMJH+/LleApp66bASlKY24ts4f2X+Yud5deLQofnJELCEYjPRt/eGH1LMzznfRocr4Or/RziFtyc7yXtS7qjeW2EdAlVoQ/LnK6D14vm8+Ho1hnvZVdAXBz6rz+DwwFOZxjDnDx99Sp8TZuhbd8G2VFWpPOKT4Dq1QHQFy5AX/4PqlKlQk9XiDR99Sp8zZrhnmJsQfswiohP+bimxfU8cM5gY0KfsZ9D37AB73XX431wMLdrGrefcRc5nhw2Z2zi7b/Gc9snvfl128+8dvH4iHwecXJkC+9kFLWGVdQaWhlxn+0//qPA8ldHbHsbhI4/50tIyEbf2QD7kgvx1VtlFKxjSbC/hjFRheA5Vd5KwQPmWk5i/jf0hrkZ+dcOfYmJqCpVsUybimXaVFSjxrjmfBycLrGArJGUZ61WnzcXAJWcgvPbBWavtkLXiiMpT3bLG69je3AQvhYtcM3LdbwxSrLrc/3zNiUF17cLoVIlvD4vCzYZXeEtuoXJV7xndHzxetHnzQHAd8aZuKe+F9LxJc4aR7MqzXnlwlfpf9qdTPz7LeasmlX2HyJKly/FUtQWXFFbgGVECt5JCOyf1o4eLXgC/1qjatQ4TIkg5+IJYPMvOPdXw7btlHzTBM6p07c3AcBXw+jpaNnQBstBf8HTwJeQYdxPyjSH5fR8g5yeb4At1y5Pq88cr2xlv3WlqhsdajS3G9fS5TiP5ODcn4F79jxUm1OD0516WplnKQkzd0YGlrFjsL3xGgDert0gLc3otQb4WoXvBP7iCsn+6hhs9w/E17IVrm8Xolq0CE4XBdktr47B+sZYAHz+eev2uuk970bWHzR6DMZZ47DqVnC7sd18I/pKo7eg97bb83VWye3ChsbekkVbvi/bD0F0Ll+KK3d7KZC/rYe7vZTLgte3b180Tct3W78+vCc/u2/zX4nE54O8jdLfBVoB7rGvhyVPzqVvgd1tHpfTc1ILnlAzJlAJWXjq/mucguDTsW04FW/VbcHpvMYXXz+YFjxmdzgFy+bmxqkIAYEDOC578DSIMuQOdIN3ufKt/VqHDDYjuZ9/scyzlIQ7cOqBy4V98IP4GjYyHsfFwd9/gVJG7udeiFjGwuSe57bBD+Brcyqu+QuhWjX06e8B0THPLS+9YORr2NAY4IjD5XXRa861zFk1kyaVmgQndrmw3XAtllkz8Z3S2himH3+RuPOwcYzYqpf90aBoW76UxPG+oyFtPcztpVwWPIAePXqwa9eukFv9+vXDmkGNfM48fGWvUyNknKNbF+Owlq7DmW3LPEvOpeONHpkKWFnE+zmNXSDepkvwNDEuF6bvqYO74V9Q0TiRHq+O7jR2N1h2NMay0b+lmJiFZc0ZZjEEzGOF1j8vRPOF4bBwj4vNE7XtTRsGY3zxBZb3jYUvug4tWpZ9lhLwPfCQ2V6UzYb7xZfNcXGdOxjtxW6PutyAMc/xn3hus+H65juoUgVt82Zsg+41prFYIprd8szT2B57FN/pZ+B5aRQAXuXl+plX8tnaj+nb5raQy4LZrrkSyycf4+l3G74reprD/9zxR4Gvv/HQBl785VkALmpU9ifZR9PypaTUAw8V+B0FcHRqH7G2Xm47rTgcDtLS0oqesIx5rrwS69y56FlZ2Lp1AUD/YLp50qW3R9lf8SOn+2Sjp2RgS6ulcSKqr/Zacmqv9Qe1EPf5XcZ9m9OY1u407/uqb4Ea/mtTKrD+E3qdO2/Tv4zn6ArXhe/lD+HVjd6d+0r94+VjmfmhuYao79yJwxY83mKe2D3308KeHjGWd6ea+TS3G/vVPY3hudvLKfl3QUcDa66ToHW3G0f1ysZxLqXM4Z4BA8OS5ZM18/h07TwA9hwxur/XmvMNtven4wP27ttEtYcfBMD16Rw+mOOighvQ3kEFjs1lZ2P58gvj87w7Ga1KVeNzjhxB6vAdbNSsrDu9HgsHXIbH52HToQ18s/ErPD4Pd585kK4N8lxtqIx4rrwK69w5hS9fLorea2l6OnXC+v336Dt3og02rmSjbdlsZlf+c0/DqdwWvOJyOp04c/Xay8rKKtXX11q1RvMfIA8sdnP/taxcjqdU37EA/pPC81+0Ltf9XKcO6Dsb4qu+GRzOYIUwL4sQh21JVyx764W8lGXdqXgbLy34fQCsPnyp4Tnx3Nu5C/on89BWrEB581wRxmrF+dV86NQpLFlKQttsHCstqJ0E/lpWrCA8ZzOWjHk8yf9YA1DBc1o0wLL0b8Jxgso/e5by3j9TQ4Yl7TDWtHQgbdtBwOg1mpSd61izCl4ENvfn0Lw+2LPHeLx9G8YqhwvFJm5c8iZe5aVaYnUua9KTfqf254KGwdMbyprW6hS0uXPyZQ78taz4p+yXLyfI4lPHbetsKvur1eSlKZWr1ZYTffv25b333iMuV++kiy66iJkzZ+abdtiwYQwfPjzf8D0HMklOTi7TnGWhYtt7Ix3hhBz6M/qOMxRXOfyKmHJffkuI/6KsrCyqV04hM7PoZXq53cLr0qUL48aNMx8nFtIFfejQoTz44IPm46ysLOrUqVPm+YQQQkSXclvwEhMTadSoUZHTORwOHA5HGBIJIYSIZuW2l6YQQghRElLwhBBCxAQpeEIIIWJCuTyGN2XKlEhHEEIIUc7IFp4QQoiYIAVPCCFETJCCJ4QQIiZIwRNCCBETpOAJIYSICVLwhBBCxAQpeEIIIWKCFDwhhBAxQQqeEEKImCAFTwghREyQgieEECImSMETQggRE6TgCSGEiAlS8IQQQsQEKXhCCCFiQrn8PbxYdujP1yMd4YT8uv5ApCOcsHaNKkc6ghCiFMgWnhBCiJggBU8IIURMkIInhBAiJkjBE0IIEROk4AkhhIgJUvCEEELEBCl4QgghYoIUPCGEEDFBCp4QQoiYIAVPCCFETJBLi5WGqVNw3HUHeNzmIM3/13NzbzyTp0YmVxH02bPQx4zG8tsvgJFZAVgsOGd/DJdcErFs57ZvjuPAvuNOo4DvV+0HoF3nU4jbs+u403sSEvlxyZbSinjinnoSx7NPhw7TNJzTPoDrr49MpuKK4uxNX6/H1sz8/9+rV8KAv2x03ugBpcx2fswKF9wMv9TL/1rXtLieaVfOKOvIRYrm72hRbFf1RPvxB7SMDCBXdqsV50dz4LLLwp5JCt5J0ka/gn3IYOOfqetgd0DOseAEO3dGLFtRrPfeg77fKCoq13DN68XR81KcH86Cq66OSLaDZ3cg7Ys5wS8J/i+MppkLrdyO1m+Ew1/wcj8n8BjAVaVqWUYuFm3AXdgnvBXMqOvg86EphePmG3DmHIM+fSMbshDlIXuKI4V7z7o/ZNjDY18m5WA2ENouEjzw0xR454Wb2HRmo5DntKjaqmyDFlM0f0eLon/6sfndC8nu8eC46nKcU9+DXjeFNZOmlFJFT/bfkZWVRUpKCnsOZJKcnHzSr+ew62hK4atZE9embTjSqsDhw+D1oimF0nWcTm8pJC99DpuGBviSk/HM+Rh7ty54b7wJ/aMZaF5vqWY/kYtHp/7+I87qNTmW3oDUP3/mtD492X3ZNVT/dBYacKRBY/78/FcA9OwjnHV5e+J3bmf3pVez6qW3AIhbv4ZzLjsPDdh5yVWseXlCiXOU5sWjzXkeF4frcHDFKNCOFOB0R+dXMtqzN329HgBr7t0cMtzMXbMmnnenY+/WhaxrrsAy72MSPaDsdpzZzrDnLY5wfkdLm5m9Rk0806YHs8/8EM3jKbXsWVlZVK+cQmZm0ct0OYZ3ErTRr5hfdNeaDdiuuwYOHcL90ijUqacaE/l88O/KSMYskPa/oeaaumtb6K5A5/yFxhqZzweL/4xAOkPG2R04Vq8haMHtuQp//2Hm/vP9r8zhVRZ8SfzO7eTUqGUWO4CGrz1vrmXGHYzsLzZoA+4KzvNdobtrnZ99GVwL/nFRmJMVrbxm10a/Esy9ZkPIuHNv9W95uFzyHS1lIfN9beh8d02ZZtyJwLJRCt5JsI1707hjt6N/Nx/947moU0/Dd+9AqGCsaWiA7dEhkQtZCNukicYdXYeEhNCR7TsA/uz33RveYEVI2L4VAJ/NDikp5vA6U8cDsPuya7Dv2k6TYQ/Ruv+1VJ3/uTlNZpszwhs2D9v704MPkpJCR17YHfDP87vvCF+oYiov2V0eJx8sf48Xf36W1/94Fc9rLxsj7HaIiwuZ9p+axgJZA7becTUT/3qL5Xv+CXvmwpTX7yiELhvzznd9w3ogMstGOYZ3ErQ9uwFQKSnYel0PNhuur+fnn27FinBHK1LgQLLK+0UKCByfWb8ufKGKSQEbBg0NGZawZSMAFVYs49zzT813jM9ntbH57sHhCVgILdt/HMluP/5027aFI06JlJfsu7N3c+snt5iP7zK+orgqJBY4vdMC8V6wr1rDwC/vAqBjemfevmwqdVPqlnne4ynP31Fz2ZiaimXUy+j+ZaA+/xssH0w3VzTCvWyULbyT4fb3yszKgqNHcb/6OlSqlH+67CPhzVUcXv++8zxrXyaLxfibkxOePMUUKGQ7bhsYMlx3Gjkr/fJ9vmKnAN3j5tT+15R5vuMKHC4vrGjo/q+jyxWePCVRDrL3bt2PL2/6js2DdnNgSDaLb19OnM9oDdt9h/hnzzJzWotuZWj7J7DFGcWkjqUi397yA53Su7Boy/dcPL0r2a7siHwOUzn9jgLBZWNiEtZRL2OZZvRU1/btw9u9ByT6V0DCvGyUglcKNKcTdWZbfLdH366o/6LsBk3yD/Qvj312OwuX7eTnr/5EBQejgNQ/f0GPxpUPUSoe7/gUneudT/Wk6iTYEmhZrRUW3diJpRSMXDTMnDbOEseTnUZg0YxFoKZptK/bkc96fUPbmmez4dB6Ji+dGIFP8d/j3L4b1/yFAHg7dETbtBGyI7MyIQXvZNhs5t2CdmWaEpMKHxcpRa0dFrV2GWa1J70BBDqrfJlvvPL/L440bw12O43GjEQDnDVqs/2m/sbuE6DSouP8n8paoPNNYVtBPp/xt4jdhhFRXrP720WSC37eVkCHmlxbIgBW3Uq/U/sD8NPWCHfAKWff0RCBZWPeFczadXB98U3wcZiXjVFX8Pr27YumaWiaht1up1GjRowYMYKbb77ZHF7QrV69emHPqiob3dU1IK5yCnE2zbzpi34wp9O3bcV+5mlhz3c8KjUVAO3o0YIn8C/AVKPGYUp0fJV/+s64o2khnVUCXJWNc+w8FYxxVRZ+DcC2Pney9bbgQX3bkcNlnLRwyr8bRytit5+qUycccUqkvGZX1dMAqOik4F2U/s+jWgXPu6uSYLSlo+7I7tIsb9/R3ALzPXAcMkR6enC6JgXsrSlDUVfwAHr06MGuXbtYt24dDz30EMOGDaNx48bs2rXLvAFMnjzZfPznn+Hvmuu+9XbA2OrwNWiIr3ET8xbY4lCAr05dfB06hj3f8bhvM9Zi8fkg7xfqpx8BI7t77OvhDVYA+8Z1aP4vd1bTlgVOc7BdJwASNq0jbdZ0LM4cfFYb2/vcTfLff5jTZZ0SuRUPd+6TbI/kWfP9xijQCnCPK/m5gmWtvGZ3330PAHYvNI7P0wnl77/Af1qR+/kXzcF/7PwNgPqpDcIVs0Dl6TuaV2C+43Ll30L9+6/gdE+NCGOqKC14DoeDtLQ00tPTufvuu+nWrRtfffUVaWlp5g0gNTXVfFy1avivoqH+9wRKM06uJOcYrn/XmDc8HmMiXce1cQue0a+GPd/xqJHPmT2l7HVqhIxzdOtifCZdhzPbRiBdqDP6Xml2RDnWuFmB02Q1a4nSdeJ2bKXBmJEAHGzfBdu+PbQccjcAPouF7GaRu4KGemN8cJ7XCG2vjksvCna2ibKVI4j+7Kv3rypwC25zv6vxYeT+6fnd5vCDOQdxdGpv5LbboYWxIrVw03e89vtoAG445eayD34c5ek7ms8ll5nLRnvThrlGKBznnh28alK7dmGNVS5OS4iPj+fAgcieNFwY1wsvYR8yGH3nThwOC8QnwNFsNH+vNm/n8yOcsHDuK6/ENncuelYWtm5dANA/mG6eMOrtcXFE81WZ/wVVvvsCx77ggipl6WKaDTV2UborVmLDEGMNscG4V8xdPPYD+1BApUXfcV7HlubnWfni+DB/gvxcd9yJfcJb6Dk5OGxasGs5RkbnxMmRjlioaM4+698PefX3V2hfpyN1U9JJclRg46ENfLX+c15vA7cug5T9h1H+dl5l7pdm7r/OrMOUbx9gxd5/+H7zAgCe6vQ07WqfG7HPExDt39HC6F9+Afh7SO/cmSv7+8HsXbuFPVdUFzylFN999x1ff/01AwcOLPoJBXA6nTidwcsGZWVllVY8ANQDD+FMScUx4C5jq85/kFZpmlH0atYs1fcrTXqr1mhz5wLB7v65/1pWLscTiWB+SauXU2Ne6AV847dtJn7bZgCO1axjFryd1/Uh7eMPcezYio7/hGKfcVDfnVSBpW9/xJFTI78mrN4Yj7NiZRwvPGsMCByHiZILMB9PNGfvlN6FtQfWsGzP3/y6/Wey3dmkxqVybp32nHZ2EtqyeUDB7bzKvxuZsORNqiVW5+rm13HXmffSvm6HCHyK/KL9O1oYX9duqDPORPdfBabA7OvWhj171F1Ls2/fvrz33nvExcXhdrvx+Xz06tWLN998k8TE4MmjmqYxd+5cevbsedzXGzZsGMOHD883vLSupSmK50SupRktSvNamkKI0lXur6XZpUsXli5dyrp16zh27BhTp04NKXYlMXToUDIzM83btii8ioUQQoiyF5W7NBMTE2nUqFHRExaDw+HA4XCUymsJIYQov6JyC08IIYQobVLwhBBCxISo26U5ZcqUYk0XZX1thBBCRDnZwhNCCBETpOAJIYSICVLwhBBCxAQpeEIIIWKCFDwhhBAxQQqeEEKImCAFTwghREyQgieEECImSMETQggRE6TgCSGEiAlS8IQQQsQEKXhCCCFighQ8IYQQMUEKnhBCiJggBU8IIURMkIInhBAiJkTdD8CK4zvm8kY6wglp16hypCOcsF0ZOZGOcMJqpMZFOoIQUUO28IQQQsQEKXhCCCFighQ8IYQQMUEKnhBCiJggBU8IIURMkIInhBAiJkjBE0IIEROk4AkhhIgJUvCEEELEBCl4QgghYoIUvJPkaFSPOJtW4M1ROSXS8Ujs1onUZAepiVZSE61U9P9NTXaQdH4HcLnMaa2fzKWif5rj3ZIuviCCn8ifdegj2E5pjsOmmbfAfLfcd29ks21YT936ValXNd681ff/rdOiHo4fv6fKfXdSp1V96tVKofYpDUjr0ZE6zetSr1pCyHPqV40nbuH8iH4eANatw9qvD47KKSHz3GHTcMRZYcGCSCdEnz0L66CB2Dt3wFEpmTibhq33zVgHDij0O2p+V20ajtQk7Kc0x3r/fbBlS6Q/TtBTT+af53YdPvww0smKFmXZpeCdrIMHUf67ClC6bj4mKwvmzI5MLj/brz+jeQu4/qbXi+33X0mtUQn8461L/w6ZRPlvebkv7FH6QUvIMupl9NWr0XINC2S1jnsD3p8eiVgAVHzxaSxHjgSzacGU1n17qHHVRVT44F2cp59J5p0D0dwu4pf8iXX/PlAKX1w8GsHPU/WufmH+BPnZhj+F9b13ISsr3+fSvF4c3bvCN19HLB+A9dmRWN98HW3ZUlStWuZwPdd3UOX5aw5PT8d7x11QtRrWN17DcUYbtH//LfvQRdAG3IXj2aeD81w3FtmaUjhuvgGmTolUtCJFY3YpeCfr8GE0wJecjNOtcDq9ON0KZbGgAY4br4toPG+zZrhOP5OM/Ydx3nEXACoxkcOff4MCtJwcEm64GgDXNUZW95ltyVi/jYxsDzmPPWE8x243/gLuCyJf8FDKmO81auI7vyuqQQO8Dw4GMOZ7v94Ri+ZscxqHr7iabT/9zea9R9k99ysAjnXrbsxzwBefwN53Z3LoyZG4mrU0n5vdoQu604m7Vm1UfDwA1oP7SR79QgQ+SZDv9DOC2WvWNNq6y4dzyTJzuOOyiyOa0fPKaJz/rsV5MAvP6+PM4dqB/QD4WrfBPX+hcf+89qHPHT0Wz4sv41rwA57/PYmWmYll1MvhC18I+4S3jHkeFxe6fNE0Y573j/zKUGGiMbsUvJOg/W+ouSbu2rYrZJxz/kJjLdLng8V/RiCd4fCSFWT/+Bv4F54B3s7n42vQEADbb78aAxOTAPA1bY6qUSNkel/VqoCxYLOsW1O2oYugjX4FTSkU4L1vEPrCBbgnTobExOBEPh/8uzIi+bLuuZ/9E9/D07RZyNadstrMtV3NGfwFBsfK5cZ43ULij8YCeffsL1E2uzlNyluvl33w4/BpBNv6mg3BEa1b42t7ln+iyM1zAF/nLqjGjUPmOZs2onm9Ru5f/zAHa9lHzPsK8LUIrnR4L7vCmGb/vrKOfFzagLuC83xXaBbnZ18Gt1J/XBTmZEWL1uxS8E6CbdJE874+dw6W55/FMvZV9O8XQrtzAWMhYYvwMaXCKKv/16H00Gag79qJfdIE4l56DstfS4xhO3cGJ7BG9lelbOPe9N+xYR3+FN6Bg1AdOoZMowG2R4eEP9xxWPbuMe8ru8O8r2dmAOBNqoAGHLnyGjwNG4U+98B+cDrDEbNA5jy32yEuz08OVakCROc819atM+6kphrZ/VRKanAawPpycAta/+IzAHzndwtDwsLZcu+WT0oKHXlhd8A/z+++I3yhiilasxdryfXJJ58U+wUvv/zyEw5T3mgZGcZfwN73lpBxvvr1jULi86GtXxf+cEU5cgTLurUAuLqH7qK0LZiPbUFoR4nAFhUJCXjO6xCmkAXT9uw27igFSRUgIQHrQw9gmWscqwnsYtNWrIhYxoBqva7CunM7AI6/l5jDs265NTiRxQIeD5asDACc55wHgObzmZNogG3LJtxNmpV55oIE5rlKTQ0dkZODvuC74HRRMM9zC2zJ5d1jQbXqKJsNze0GQP94HtbkFLS/lqD//BOeAQPx3jMg3HFDaNnZQPBwQqHTbdsWjjglEq3Zi1XwevbsWawX0zQNb0EdJP6r/J/Vl5yM69+1UKEC2saNWN58HcvECcYCGSAn+n5ANOWUpkYRs9k5NmEyACo+gWOPPo6vchUSH34g33M04OjgR1EVK4Y5bR7+hRQeD3g9WJ9/NnS83W70Ps212ypSEuZ/jaaMwhX4642P59CzweNDyhGH5glm1TMzwelEO5od8lqBLcGICMzzxNC1dXvn9mhOp7mSEQ3zPIT/O6qSU0MGa1u3orndxrF2rxd93z50/zE77/ld8d7QK+J7MszlR2FFw79CnbunddSI0uzF2qXp8/mKdYupYpeb3Q7Vq0NCAqpVKzxvjsd7/4MhPQijiXb0KPrePSjg8IIfzeGqWjVynhiO656BHMr2cOjQUXKu7xX65Jxj4Q1bEP+XSaWk4Nx7kBy3Imf7brzX+jsIRdECYPPebHbNC+29qOfkkDhrRnCAz/jeBNpLwtefU/vcU0O28KKR7dqr0ZcsMdbicx8/LQfMvS6BldZ69ck5kInr0y/Qtm7Bfn5H9E8+jmBCURZO6hheThRuuYSVxWL8LWA+eP09IoH8xzwiTFNGT6nDn3+D9/QzCp/QYsH+g3F+lc//WePGvRGOiIXzeMyFVMjaY/XqqGbNQ6fNszUSKakvjgRABTpTKEWVQUb7iFv4LdoxYyXCXa8BAI4lf2Dbujk4vZ8v13GnsLPZjL/+LTjbDddimTcH5XDg/PVP4/8CUTPPTf52q/l3FwcEem6SkGD8rVQJkpPx9bgI94xZaG43tgcHhTFoAQL//8JW4AIrREXsNoyIKM1e4oLn9Xp5+umnqVWrFklJSWzcuBGAJ554gkmTJp1wEE3TjnsbNmyYOW2zZs1wOBzs3r37hN+vNASOZ2hHj+Yf5+/VCKAaNQ5XpOOyzTRO9lTA4a8W4O18fuETu90k9r0J3T+PPR07A6AdOVzGKYtw5AiafwtP37cv5ORh69PDgeCWklKqkBcJn2q9ryP+F2Mr2tmshTHQYkF3ObGuX0v8T4vMvLbNxncp8Pm0PPmT3p8alswFUdXTAOO4te3qK7HMnmUUuz+WQOvW5oJNtWoVsYwFUf4CrO3aVfAE/ty+008PPqdNG1TFimhbtsCBA2WesTDKv9WsFbHHQtWpE444JRKt2Utc8J555hmmTJnCiy++iD1XdW7VqhUTJ048zjOPb9euXeZtzJgxJCcnhwwbPNg4x+qnn37i2LFjXHPNNUydGrkFAID7tv7GHZ8P8hQ93d+DUwHusZHtUg5QoU1zLIcOAaDi4vC2P07HE5eLxJuvxz5nVnDYwYPGXz3CHXsdDrxt2wLGvPX07oOn3214+t2G79TTzOEA3v63RyajX/XrLyfxy0/NA/fe9PrGiMAWqs2Gq1VrPFWrAcHcvqQkXA0bo3LNa5/NhqtNcKEcbu677zHuuFxYPpmHiovHuWQZtGgJf/8F/k5N7udfjFjGgqjG/pXNjAyjuAUKc2ACj8doR48MDT7J6YTD/hW7CG49uXvdFHxwJM+xUf9J/gpwj5sQvlDFFK3ZS7z0evfdd5kwYQI33XQTlsAuPaBNmzasXr36hIOkpaWZt5SUFDRNCxmW5O/aOmnSJHr16sUtt9zCO++8c8LvVypu6m0erLfXCfYC0zZvxvbIYP8DDc5sG5F4AcktG2Ndvy74Jc/1f8vN8cKzkJlJ0g1XY//sE7y5tkxty4yrsHjz7jYMt/h4PFPeM09e1ed/i2fCRDwTJuK79DLAf76YpuF7/ImIRIxb+C1pF3chYcG3xgnmr44HQCUk4E1OMU7GtTvwpNcn+8pr2f79HyhdRwPcdeqyZcMedvz2T8ipC/tfe5vsK6+NyOcBUA88ZLZ1BTiXLoemTQFwdGpvbKXa7UYBjCb1Gxi9MQF7u7PQf/jeGJ7g3wIBSEmFevXNp1hHDEPzePCd2RYqVAhv3lzUG+ODy5caVUPGOS69KNhHIM8pOdEgWrOXuBvSjh07aNSoUb7hPp8Pd6AnVxk5fPgwM2fO5Pfff6dZs2ZkZmby448/0qFDZLrJW2Z+CDYbyu1Gz8rCYdOMAue/CogCnO++H5FsAcl1qmM5eCDkUkpadjapSf5jMpqG55xzOfLt98Q/9zTxI540s+v+IqkRLCJ4PcQ/NoRjz0ZuTV7/8guwWFAeD/rOncZ8t1rN40gKcL0ZubXeKg/ei237VmPeOXOodq+xpZk456PgvHU5qdb7WtyNm5H0wbtoPh8KsG7fRp2W9dCPHUP3dxByp9XA69+lGCnWO283s2uAo1mj4Gk3/uHeTl0imlH/eB6Wj+cZD/ynUWi//4qvQSP0NavQ/1mG9s8yY3zuHrBuF9YBd0N8PPovP6P/+QcqPh73qFfD+wEK4LrjTuwT3kLPyTHaeZ557pw4OdIRCxWN2Utc8Fq0aMGPP/5Ienp6yPBZs2Zx2mmnlVqwgsyYMYPGjRvTsqWxFnnDDTcwadKk4xY8p9OJM9cJu1lZWaWWx9u5C9raNWjfzYf9/oPggR6Euo5z9sdw6aWl9n4nQs8wdmPm7v6gQbDbsFJYfzeutOK+oDu2r74wG2VemlJYV68GW2QPkvu6dsN7+51GL7odxjluZqcJwHP3vaj+/SOUDny5tx7ynEsX+KsAx5LFJMz/OnhNSjD+H3mu8GHbvYu4X34kp32nMk5eON3fqzH3Z8j72Sx//IYn7xPDSF+2FMu00MMcur+PQYCW5y9g7KadOtn4PDVq4OndF+/Dj6CaReacx9zUG+NxVqxs7H0Bc54rTcM57QO4/voIpju+aMyuqRIe2f/444/p06cPQ4cOZcSIEQwfPpw1a9bw7rvv8tlnn3HBBSd/Jf0pU6Zw//33k+E/sTugXbt2XHPNNTz00EMALF68mE6dOrF7924qFLLrYdiwYQwfPjzf8D0HMklOTj7prOF2zFU+T/2Itxe8G7U82JVRfnsj10iNrh7CQpS2rKwsqldOITOz6GV6iY/hXXHFFXz66afMnz+fxMREnnzySVatWsWnn35aKsWuMP/++y+//fYbQ4YMwWq1YrVaOeecczh69CgzZswo9HlDhw4lMzPTvG2LwqsSCCGEKHsndCmBDh068O2335Z2luOaNGkSHTt25I03Qs8Dmzx5MpMmTeL22wvukedwOHA4HAWOE0IIETtO+No5ixcvZtWqVYBxXO+MM45zAvNJcrvdTJs2jREjRtAqz3k+/fv3Z9SoUaxcudI8tieEEELkVeKCt337dm688UZ+/vlnUv0nXmdkZHDuuecyY8YMateuXdoZ+eSTTzhw4ABXXnllvnHNmzenefPmTJo0iVGjRpX6ewshhPhvKHGnlR49epCRkcHUqVNp6j8PZ82aNfTr14/k5GS++uqrMglaWrKyskhJSZFOK2EmnVYiQzqtiP+6knRaKfEW3g8//MAvv/xiFjuApk2b8tprr0XsfDghhBCiKCXupVmnTp0CTzD3er3UrFmzVEIJIYQQpa3EBe+ll15i4MCBLF682By2ePFiBg0axMsvv3ycZwohhBCRU6xjeBUrVkTL9VMl2dnZeDwerP4fSAzcT0xM5GDgIsNRSo7hRYYcw4sMOYYn/utK/RjemDFjSiOXEEIIETHFKnh9+vQp6xxCCCFEmTrhE8/B+MVzV54f+CuPuwmFEEL895W400p2djb33nsv1apVIzExkYoVK4bchBBCiGhU4oI3ZMgQFixYwLhx43A4HEycOJHhw4dTs2ZN3n333bLIKIQQQpy0Eu/S/PTTT3n33Xfp3Lkz/fr1o0OHDjRq1Ij09HSmT5/OTTfdVPSLCCGEEGFW4i28gwcP0qBBA8A4Xhc4DaF9+/YsWrSodNMJIYQQpaTEBa9BgwZs2rQJgGbNmvHRRx8BxpZf4GLSQgghRLQpccHr168fy5YtA+DRRx/ljTfeIC4ujgceeICHH3641AMKIYQQpaHEv5aQ15YtW1iyZAmNGjWidevWpZWrzMiVViJDrrQSGXKlFfFfV6a/lpBXeno66enpJ/syQgghRJkqVsEbO3ZssV/wvvvuO+EwQgghRFkp1i7N+vXrF+/FNI2NGzeedKiyVN53aQpREiu2ZUY6wglrVScl0hFEOVDquzQDvTKFEEKI8qrEvTSFEEKI8kgKnhBCiJggBU8IIURMkIInhBAiJkjBE0IIERNOqOD9+OOP3HzzzbRr144dO3YAMG3aNH766adSDSeEEEKUlhIXvNmzZ9O9e3fi4+P5+++/cTqdAGRmZvLss8+WekAhhBCiNJS44I0cOZLx48fz9ttvY7PZzOHnnXcef/31V6mGE0IIIUpLiQvemjVr6NixY77hKSkpZGRklEamcke/oz8Om5bvpr3ycqSjYXn4Ieynt8ZROQWHTSPOpmFvVB/WrcN2fmccFRLMvHH+v/aG9bC3aoYj3maMs+s4qlfGduN1aGvXRvojwYEDWCZNxNamVf757rDAp59GOuHxPfVk/tx2HT78MNLJADijYUXObJBa4O2MBqm06nQqrc9twenN02h9Wv1Cpz2zQSqN+l0T0c+iT3+PuEDbTrCHzPO4Im7Wxx6NaHZTlLeXwuizZ2Ht2D7f8sURZ4XPP49IphJfPDotLY3169dTr169kOE//fST+cOwscR63jlY//gdAAWg6+DzoQH2Rx/GvXUrvleLfy3SUs83/k20nBwjm90OLhcAtuFPYfnxB3M65c8NoG/dYgxLSUE1aIi2ZTPawYPoX3yOdnNvVJMm4f4YISyzZmK7924UoOGf75oGSqH5fDiuuhznjJlwdWQXtgXRBtyFfcJbwdyB9qIUjptvwJlzDPr0jWxIpULmrbJY0HwKTfnb9Y6tHLjmJjwVK1P1vYnBpwHKakXz+czvQMoP84lbuYyclm3C/zm2bcM26F6U3Y7mcqG53cY8j4uDnOAvYCjAd8WVqDy/9uI7r31Y4xakXLSXQlgH3oO+bx/gz+6neb04el6K88NZcNXVYc1U4i2822+/nUGDBvH777+jaRo7d+5k+vTpDB48mLvvvrssMkav3bux+Iudr0IFnG6F0+nF6VYo3YIG2N58LaIRPU8/g+uLb3A6vXiefcEc7jv9DHxpNQBwj3oV9zffGSM0LThNej1cfyzBuWUHvnPaoR09ClGwFa+aNDEXyL7kZGO+u3w4t+0yhztuvC6yIQsRWHj54uJC24umGbn794t0RMCYhznp9fn7n+38te4Ay35bZS60Dl52DVuef40djwwjo8uF5nNctevy19r9LFl/kLWTZ5v/iwb33Rr+D6AUtv79UJUrg9tjDNJ1nNt34zv3PFSDBiiHA/wZtX+W4nlyWMjN17Vb+HPnUV7aS0E0f7HzJSfjnr/QuH/jTcYKFJH5jpa44D366KP06tWLrl27cuTIETp27Ej//v258847GThwYFlkjFr60EfMNS/X9t0h45zfLQyu1Sz+M8zJgrz3P4jvgguMNcNcfFf0RN+9C1+9engH3GsO15QyFwT68n8gOxvi4vCMGAmAddLb4QtfCPXdt8H5vm1XcERaGp7bbvdPpCI63wuiDbgrmHvXvpBxzs++DLaXHxeFOVmQfjgLMDL+++mP+JKSAHDs2EZgVci+f685vbtWHQB8uo710EFz+OFOXfGkpBrT791T5rnzsrw2Fn3hAtzX3YimjD0XqnkLLB/OMIZPnIyv+0XGcEDbvfs4rxYZ5aG9FEb739CCv6OAc75/2ejzhf07WuKCp2kajz/+OAcPHmTFihX89ttv7Nu3j6effros8kU16xefBR8cPRoyTlPKWHMEbPfdS7TRv/evcXW7MF8xVDVqAsZnsD5wH5a3J6Bq1kQlJKD9+gv4e+ZGim2SfzearkNCQujIxo2B6JzvtvenBx/4C4npwu6AP/fdd4QvVB5pb79mFrbaI4fSqlMbWrdtTPqQAfj8w3PqNTSnz6lv3Nd9PnLqpJP2xitUeX8y8f/8jdVfPJ1164XvAwDaqlVYH38U78BBWBcuCA7fvNkcrjp0hBTj1xg0QMXFYXn+WSyT30Fbty6seQtTHtpLYY77HW3fAYjMd/SEfwDWbrfTokWL0sxS7mhZWeZ9R+sWeC/vCZUro23cgP7pJ+YuHW19dHyBctPWrgEo8Hictm2red86+R2Y/A5K0yA1Fe3oUbSNG1HNm4cta758/t2qKu8XyePBMu3d4HRRNt+17GwAlN1+/Om2bQtHnAJV+P1nIwNQ7aNp5nD7geCxmIqfzETzevCkViJ+1XJzmsTVK0lcvTLk9RSw9t15ZZw6F48HW99bUHXr4hn5LI7GuX7aLPsIWCyQmYn18aFoP3xvjtIPHUJ/4nHzsfeqq3GPfxsqVgxf9jzKQ3spTKHf0YDAscgwf0dLXPC6dOmClus4T14LFiwodNx/jtcLgKpQAc3jCdnd52vUCG3TJmOaXAfIo0am/3fSkvP/5pjm9RrHIH1e3E88hWrfAeuAu9DXrzcmiPRxPP98Jy4uZLD1sUfRV64wjm8oFX3zPfDTk4UtwAIdh/wdiyLB4t8tGdhdlvubHliBsx7OouqMqeZwT3IKzhq1SVwTWuwAvEkVUPHxZZY3L+vIEWhL/8b1/U8QHx/aBjQNEhKwTp2c73m+Bg1w/fw7+pLFWP/3GJY5s9F278a1cFG+PSBhUw7aS6EK+Y6aLBYje5i/oyX+T5566qm0adPGvLVo0QKXy8Vff/3FKaecUhYZo552+DDe3n1xrtlATmY2zt+XoOo3QAv808sZBXj7+4+FORz4zu+Ke8as4DEDtztCyQpneW0s1tGv4GvWDKwnvOMi5gWOdwGs/vALFm/MYOnva1k/bprZoUkDtj/0BH+t3MmqWV/jsztIXLOSzPZdWPr9UrLOOhcw2pH1yGHShwwIT/bff8fy/LN4H3gI1a5d/gmUwntrf/N76umfa1fgwYNQpQq+7j1wffc9vvr10X/5Gf2zKD/FRZRIiZcMo0ePLnD4sGHDOHLkyEkHKld03ViTsVjwvDzKHKxOPx33rLnoKYnGGnKuE/Sjhv/4BVnGlp5lxFPmKO9llxlrYAD+jgeqTRvztAbt4IGQbsZhZ7GAx2OuHVreeB3bg4PwtWiB6+vvcKTXMqYrbO0yUvynThS6Ru4/LaTQNfow8CZVMKIkJJLd1ihcnqrV8KakGlvNfonL/8YXn0DKogXY9+/FUyGZ5J+/p96IR0n+4xcOXnIl9q2bSVr+N5W+/Jgy/wlpjwfbrcYpM57hufoTxMWZezNU6zYh31Nq1DDvahkZxq76Bg0gORnfDb3Qn3sG/cdF+C6/oqzTF6wctJdC5fmO5lPUFmAZKbVt9Ztvvpl33nmntF6uXFA2f0Pz+fKPzLXvWlWrFqZExaeaNAVAW7sW29VXYlmUq6dXQqK5b908xufxGDcwunpHkEpNBUA7ehTLq2Ow3T8QX8tWuL5dCGlp5v9DNWocwZT5qcREALQidkGpOnXCEadAxxoZ7cLnCF0QpSz4OuSxxd8hJTA8u0VrNKVIXfAVBy6/lo1jJrLvxr6A0fnJkqsHZ5k4cgR97Vr0VauIS4ozTx7X9gR7iOr/LAs9sfzp4eY4DbDef5/5WFWpatzxH0eLhPLQXgqT+ztaoAh9R0ut4P3666/EnUC17tu3L5qmoWkaNpuN6tWrc8EFF/DOO+/gy1NI/v77b6699lqqV69OXFwcjRs35vbbb2dthK7+oVr4O24ola+XJj/9aN713hF95yf6OncBwDJ9GpZP5gWLN6D/9hv6Lz+jEhLwnX2OMey7+cYJxYBqHNkTz9239Tfu+HzYBj+Ar82puOYvhGrVzPmuAPfY1yMXsgDuXjcFH+TdG/KNUTgU4B43IXyh8th/Q29jV2RWhrmCA6C5Qnvm5tRr4B9uLIwTVywDIKtdBzaNegssFlK+/9acXpX1Xg6HA0+/2/LfzjsvmMERh69xE7ydu+Dpdxu+ps2M4YHxuTrh6X/8ZgyL4MU0ykN7KUzu72hhy8ZIfEc1pVSJ9k5dddVVIY+VUuzatYvFixfzxBNP8NRTTxXyzIL17duXPXv2MHnyZLxeL3v27OGrr77iueeeo0OHDnzyySdYrVY+++wzrr76arp37859991Hw4YN2bt3LzNnzmTbtm18WMzL7GRlZZGSksKeA5kkJyeXKGte+syPsPe6HjBOPHcdzNVr02FB8/lQgHP3fojwVhFgbA0NfsA4oXz9JhzVKqMdOoiy2XBPnIy9z80hnRU8t9+J583xkJODo1kjtB07jN2Gy/J3Tgg3h8048VbpOs5d+6BSJWN4nNXf6UbH6Yy+Y6iB3L64OFyHjwWH23XjHEjA6S69HcYrtmWWaPoq70+m1isjsR06wKFuF7NhwvsApI15jtpjjQsXKOCfH5fjrlWHpld0psLypcZwXWfp72vxVq5C6ufzaDiwLxrgjYvj739Lfp5bqzr5O1SdCHPe6jrOjVuhlrHL21EhPngVorg4nJu3Q+XK6NPfw9avN9hsuFauQeW5qlQ4hbu9lCYze3IynjkfY+/WBe+NN6F/NKNUv6NZWVlUr5xCZmbRy/QSH8NLSQlthLqu07RpU0aMGMGFF15YyLOOz+FwkJaWBkCtWrU4/fTTOeecc+jatStTpkyhV69e9OvXj4svvpi5c+eaz6tfvz5nn312xK7h6bv6Gnzp6ehbtqAfPozDpoVcWgzA07tvRIud5fGhWGbNBEDLzDD+7tiOo1Iy2uHDRs87txtbris2BE4YtUx+B/2vJWj/rkQ7dgzlcOCeOTffe4Sb/u5UM6Pm8+GoXjlkvivAc8ddkQ1ZCNcdd2Kf8BZ6Tk6+9qIA58T8PQjDKW3Cq1gPGcdoK87/gjMa+rvl51ov9lms1Br9DO4q1UnyFztjhI825zRF8/rQ/KtOCth578Nhy18Q72VXYP1kntFW6tU2e28GjklqgPfsdliHP4W++E/0P/9AWa143nwrosUOor+9HI/nyiuxzp2LnpWFrZuxR0n/YLqZ3XvRxWHPVKKC5/V66devH6eccgoVy/j8lPPPP582bdowZ84cKleuzP79+xkyZEiB06b69xcXxOl0mj9hBMbaQKnRdVyr1mG59mqsn/t7cwV2+wHup0bg+98Tpfd+J8Dy26/oGzeEDNM8Hjh82LgfGObveWk+BpTHjbZkMdhseM85F/f7MyAKjhfom40uELmz5j6OqgGWf1cSfdt3oN4Yj7NiZRwv+H9KK9BeNA3ntA/g+usjmA4OXnQF1adNRD+abZSs3IXOauXQ+d1x7N1DxW8+Rz92lFxXMzXOOc3TM1kDLJHuNt+mDXwyD2W1GrtpjxlbSub1QpOS0H//FX77BVWrFp7effHed7/RUSvCor29HI/WqjWafwMl5Lvq/2tZsRxPQU8sy0wl3aUZFxfHqlWrqF+/ftETF0Pfvn3JyMhg3rx5+cbdcMMN/PPPP/Tt25dHHnmEgwcPlrjQDhs2jOHDh+cbXhq7NIWIdiXdpRlNSmuXpvhvK8kuzRJ3WmnVqhUbN2484XAloZRC0zRKWJNDDB06lMzMTPO2LQqvSiCEEKLsndAPwA4ePJjPPvuMXbt2kZWVFXIrTYEtySb+rvGrV68u8Ws4HA6Sk5NDbkIIIWJPsQveiBEjyM7O5uKLL2bZsmVcfvnl1K5dm4oVK1KxYkVSU1NL9bjeggULWL58OVdffTUXXnghVapU4cUXXyxw2lj94VkhhBDFV+xOK8OHD+euu+5i4cKFpR7C6XSye/fufKclXHrppfTu3RuLxcLEiRO59tprufzyy7nvvvto1KgR+/fv56OPPmLr1q3MmDGj1HMJIYT47yh2wQscR+vUqVOph/jqq6+oUaMGVquVihUr0qZNG8aOHUufPn3Q/RduveKKK/jll1947rnn6NWrF1lZWdSpU4fzzz+fkSNHlnomIYQQ/y3F7qWp6zp79uyhatWqZZ2pTJXmiedCRDvppSn+68rsxPMmTZoc96eBAA4eLONr5gkhhBAnoEQFb/jw4fmutCKEEEKUByUqeDfccAPVovDK/0IIIURRin1aQlG7MoUQQohoVuyCdzJXOxFCCCEirdi7NPP+Np0QQghRnpTaD8AKIYQQ0UwKnhBCiJggBU8IIURMkIInhBAiJkjBE0IIEROk4AkhhIgJUvCEEELEBCl4QgghYoIUPCGEEDFBCp4QQoiYUKJfSxBClC/l+UdUd2XkRDrCCamRGhfpCKIQsoUnhBAiJkjBE0IIEROk4AkhhIgJUvCEEELEBCl4QgghYoIUPCGEEDFBCp4QQoiYIAVPCCFETJCCJ4QQIiZIwSsNTz2Jw6aF3uw6fPhhpJMdlz57FtaO7c3McYHscVb4/PNIxytaOZ3v5TY3RHX2etUSqVc1Pt8tPS2JhA/eDZnWsmMblYcMokb3DtRpUY96tVKoVzWe+v5b6pOPRuhTFCCK53mRoiy7FLyTpA24C8ezT6MFBujGLNWUwnHzDTB1SqSiFck68B6sv/4czO6neb04el4Kc2ZHJFdxlNf5Xl5zQznIrnzB+1pw0aZ7vVS7705SnnnSHGbbvImkWTNQySkcvfgyvIlJaIDyj0/8eA54POHJfRxRP8+PIxqza0opVfRk/x1ZWVmkpKSw50AmycnJJ/16DpuGBvji4nAdPhYcbtfRlEIBTnd0zmIze3IynjkfY+/WBe+NN6F/NAPN60XpOk6nN9IxC1Re53t5zQ3hz17Sa2nqK5bja3VKvuH1qiei+XwoYPM+f26XC6xW0HUSZn1AtbtvBU0DpcwF9N63p5Hd85oS5y7Na2lKeylaVlYW1SunkJlZ9DJdtvBOgjbgLnOt0LVrX8g452dfmmuL/LgozMmKpv1vaDD7tl0h45zzFxrZfT5Y/GcE0h1feZ3v5TU3lI/sBRU7gOwu3fIPtNvNLY5qd98KwJ5J00MmsW7cULoBS6g8zPPCRGt22cI7CfaKFdCPHCl0TSWwhuNt2hT3itUn9V6lzV6jKvr+/eZWnP7D9+YWnvvd94LZ256F+5ffIx03RHmd7+U1N0Qme2n9WkJ6WgV0rwelaWzeezRkXJ0W6Vj37cXZsDE7f/uHelXjzS283e/N4lj3S0r8fqW1hSftpXhKsoUnPw90ErTsbACU3X786bZtC0ecEtEyMgBQCQkFT6Dr4POhrV8XvlDFVF7ne3nNDeUre3rNFDSvB5Qyd1EqYN8Lo0OmSx71PJZ9e1HA0SuvpfKQQeY4Z+NmJ1TsSlN5mud5RWt2KXgnI7BxXNg/1V80cLnCl6m4vP5jc3GFrI1aLEb2nCj8TbLyOt/La24oV9k1tyukI5YC9j/9Atn97gwOPHqUSs8NN6YHKr78rDktwNFu3cMR9fjK0TzPJ0qzyzE8IcR/yuZ9x9i07xj7nn4Bd/XqAFR54hGqXXWxOU3d5nXRAGfzVmzad4xNu4+w9e815vikOR+iHzoY7uiijEnBOxmafz2ysLUUn7+bdBGb9RFhsRh/C9uCK2oLMJLK63wvr7mhXGY/ctd9bF+xmYx7jF2VCT8uBCD1fw+jH81GaRq7Fvk7ZVkseGvXNZ9r27Obis+PCHvmEOVwnpuiNHtUFby+ffvSs2fPQsf//fffXHvttVSvXp24uDgaN27M7bffztq1a8MXMheVmAiAVsRmuapTJxxxSkSlpgKgHT1a8AT+BqkaNQ5TouIrr/O9vOaG8p09Y/jzgLHrMuHdd0ic/zUaxvlg9XOdbF4/V4cVgOR33qLWOa0jERko3/M8WrNHVcE7ns8++4xzzjkHp9PJ9OnTWbVqFe+99x4pKSk88cQTEcnk7nVT8MGRI6Ejv/kaMI4JuMdNCF+oYnLf1t+44/NB3qL304+AP/vY18MbrBjK63wvr7mhfGfPzVchEWeb01CaVvAt17QKcLY5LVJRy/U8j9bsUXVaQt++fcnIyGDevHkhw48ePUp6ejrt27dn7ty5+Z6XkZFBqn+LpShy4nmQnHgefuU1N0T3ieeV7u3PkYsvx3Xx5aEjjhyhXsPq+U48ty/7G1er1sFd+365T0vIuH8Ihx4fXuLccuK5QU48P0Fff/01+/fvZ8iQIQWOL26xKwuuO+5EAXpOjnGdOIfF+EcH/qETJ0csW1E8V15pZM/KwtatCwD6B9ONYgd4L7r4uM+PpPI638trboju7BXmzqJmn+uD19Cs7r+uZv2qZrE7fPlV5vSprzxL3Zb1qHbLtVR69AEqjnicqnf2Mce70mqQMejhCHySUNE8z4sSjdnLxWkJ69YZ54I1a9asxM91Op04nU7zcVZWVqnlAlBvjMdZsTKOF4xuzeaxL03DOe0DuP76Un2/0qS1ao3m32IOrNXm/mtZsZzIX02wYOV1vpfX3BDd2bO7dSfpi0+CAwKdIgCl6+wZO5Fj199oDjt8862oxCQcfy0m/udFaMeO4kutGHy9K69HJSWFJfvxRPM8L0o0Zi8XuzRfeOEFHn30UQ4ePEjFihULfnIhhg0bxvDh+XdLlNYuTSFE2SitK62EW2nu0hRF+8/t0mzSpAkAq1eX/BI0Q4cOJTMz07xti8KrEgghhCh75aLgXXjhhVSpUoUXX3yxwPEZ/stkFcThcJCcnBxyE0IIEXui7hheZmYmS5cuDRlWuXJlJk6cyLXXXsvll1/OfffdR6NGjdi/fz8fffQRW7duZcaMGZEJLIQQolyIuoL3/fffc9ppoee+3HbbbUycOJFffvmF5557jl69epGVlUWdOnU4//zzGTlyZITSCiGEKC+iqtNKOJT2eXhCiLIhnVZEcfznOq0IIYQQJ0sKnhBCiJggBU8IIURMkIInhBAiJkjBE0IIEROk4AkhhIgJUvCEEELEBCl4QgghYoIUPCGEEDFBCp4QQoiYIAVPCCFETJCCJ4QQIiZIwRNCCBETpOAJIYSICVLwhBBCxAQpeEIIIWJC1P3iuRBCQPn9IdWMbFekI5yw1ER7pCOUKdnCE0IIEROk4AkhhIgJUvCEEELEBCl4QgghYoIUPCGEEDFBCp4QQoiYIAVPCCFETJCCJ4QQIiZIwRNCCBETpOCdjAMHsEyaiK3t6ThsWsgtzn+zTJoY6ZSF0mfPwtrhvJDMDpuGI84Kn38e6XiFsva8DEecNX9um469Xm1YvDjSEY/vqSfztReHXYcPP4x0suOyXdUTe9WK+ed7vA0+/TTS8QplmTrF/D4WdnM4LJHLt+RPqjRNp3rFOKqnOqie6iDN/7fihZ3A5cL+wwJSb7qWqk3qmuOPd6t4efeIfZ4QUdbWpeCdBMusmdjuuh196d9o5sA8X5x/V4Q7VrFZ770H62+/BLP7aV4vjp6XwpzZEclVFMsXn6N5vQCh2XUNfccOHO3awjffRCRbUbQBd+F49ulgbt34CmpK4bj5Bpg6JVLRiqR/+jF6Rkb+9uLx4Ljqcnh/ekRyFcX34yKU/74ClK6HPAbw9bgo/MH8UgYPwrpnN5pS+cY5/viN6jVSqXTFRdiW/oXzokvwVqtujleQ77MAuNucVqaZiyMa27oUvJOgmjRBYSx0fTVr4nT58HXqjKqbbjY+6+uvRTDh8Wn79wHgS07GPX+hcf/Gm1AWCxrguPG6CKYrnPeOu/A1a4YGeM/rYAxMTMTp9KJq1DCy33xDJCMWyj7hLaO9xMXhdCucTi9Ot0JpmpG7f79IRyySr2bN0PZitRrZ+/WObLBC2KdONuZ5cnLoPPe3cwBv/zsils996mm4W7Xm4Idz2XPwGIeffcnIVLWasXzxevHUrMW+v1eR9eo4nD0uAcB5+pns2ZOF2/8dcHXobC539A0bIvBJQkVjW5eCdxKUf8tOAa41G7C8NhZ94QLcU97Fd8aZxkQ+H/y7MpIxC6T9b2gw+7ZdIeOc8xcaXxyfDxb/GYF0x+d94CH01avx1auHanVKyDj3yOeMO4cOQXZ2BNIVThtwV3Ce79oXMs752ZfBNfQfF4U5WdG00a+EtPXcXFOmGXeisK0fr527JhiHGxTgq14933PD5fDoNzjw05+4ul9sbgUBEBeHCmwVHTsGduPCzr4GDQFwXn0dOBzm5Fr2EbOAW3dsC0v2wkRrW5eCdxJs49407tjtaJs2YX38UbwDB6E6dITUVMDY+rM9OiRiGQtjCxxb1HVISAgd2d5YY9QA2333hjdYMejf+7cuul0IWugONst0Y+GrAfrvv4U72nHZcu/yS0oKHXmhccxFA2x3R25rozC52zpxob9ioG9YD0RnWz9eO7csWQL4c99/X5iTFU3LyUH3+YwHuo7j6y9IHPMylo3GCodj/tfGSoafZcM6876ndZuwZs0rWtu6/DzQSdD27AZApaRi63sLqm5dPCOfBY8H/Z9lwelWRN9xPC0jAwCVt9gF6Dr4fGjr1xU8PoK0tWsAY5ey/vpYY+CxYzgqp6BlZRm7qrxetLVr4fyuEUwaSvNvcSr78X+CRdsW2bXzgphtPTUVy6iX0f1tWp//DZYPppu79qOtrRfazo8dw/L+e8Hc0djOjx0NPvC4qXj9lSHjHQu/o8pZbdCyjwBgycw0tpysVg4/NTJ8QQsQrW1dtvBOhtvt/+tCW/o37olTID4e62OPou3LtRnvb5BRxd/pI+/auinQ+SYnJzx5SiIz0/ibnIK+dSsAms9nFLsqVfD2vdU/XUZk8hUm0CmhsIVAYHeWKwp/Ty3Q1hOTsI56Gcu0qQBo+/bh7d4DEhON8dHW1gtp5/rMj4xiGNhDEIXtXDtizEsF+GrV4cCXC9iz/QD7f16Cs4uxImdZvxbLrp3B5wBH+92OqlI1AolzidK2LgWvFGgZGXgfeAjVrh2W18ZiHf0KqnLlSMeKCd67BgCg4uNxDx4CmZlYJr0d4VT/bc7tu3H5O614O3RE27Qx6o6XFsU6cYJxR4/c6QhFMXfWW61kfDAbd7vzUElJeBo2wpdUwez84W7c1HyOLyGBhMlv4/j8k0hEjnpS8E6GzWb8tVjwDH8ayxuvY3twEL4WLfD27hucLjGpwKdHVFFbcEVtAUZSSorxNyszOEzX8T73Ak7/gtiYLjWssYoU2JoobK02cDymiN1AERFo63m34GrXwfVFrlNAoq2tF9DOtZUr0X/9BVW7Nij/PI+idp7w2mggeJqB+7Qz8KbXM8cnjX6J+E/n4T7jLAAsWzYBRrE7+Pl3aB4PyY8ODmfk/KK0rUvBOwmqajXA6DYclxSH7f6BAOj//ot19CvmdPq2rVgfvD8SEQulAp1qjh4teAJ/g1SNGocpUfGpJsYarbZ2bf6R555n7i5R8fHhjFUk5d/tpxWxG0fVqROOOCWiqqcBwWNiIdLTg9M1aRKmRMVTUDu3+LfuvP1ui7p2Xvnc07H6d1H6kioAoAIreH6Or78AwNOwEQC6vz25z2qH57TT8aVWxLJtC9rBA+GKnU+0tvWIFry+ffuiaRp33XVXvnEDBgxA0zT69u1rDtu9ezcDBw6kQYMGOBwO6tSpw2WXXcZ3330XxtRB7tvvBHKd+FmpEp5eN+Hpdxu+xk3McZ6eV+E7p11EMhbGfVt/447PB3mL3k8/AkZ299jXwxusGHyduwBGhwnynqx7+LC5EPOd2Tbc0Y7L3eum4IMjebaUvvka8M/zcRPCF6qY3HffY9xxufLvFfj7r+B0T40IY6qi5WvnOTlYpk9DWSx4WhqntERLO69yZits/64MdtlPTkZpGtbVq0N6Y+JyAhD31Wchz/empYHTiXbksDHAFrk9BdHa1iO+hVenTh1mzJjBsWPHzGE5OTm8//771K1b1xy2efNmzjjjDBYsWMBLL73E8uXL+eqrr+jSpQsDBgyIRHTUI48GTzy32XCuWodn6nt4Jkw0jmsAWKx4Zs7Gd931EclYGDXyOTO7vU6NkHGObl2M4we6DlFWNAC0DevxduiIvnkz2orlwREeD46WTY3zf2w2aNkyYhkLot4YH5znNUI7FTguvSh4zKZDxzAnK4ZLLjOPGdmbNsw1QuE492xjnmsatIuuFbu87VyfNRPt0CF8PS7CcdP1UdPOq7RpinX9OpSmc/ge4xQJZbXi7HEJlu1bSRgXvICF+6xzANAzM415nkvS80+jeTy4Tj8TVaFC+D5AHtHa1iN+WsLpp5/Ohg0bmDNnDjfdZKwVzJkzh7p161K/fn1zunvuuQdN0/jjjz9IDPQIA1q2bMmtt94a9twA+rtTzZMrdbcbR/XKxrEOtzt4BYcuXSKSrTjcV16Jbe5c9KwsbN38W00fTDc/k7fHxRHNVxjLbf3Qd+9CAZafja1RsrNxxNvM7O6J70QwYeFcd9yJfcJb6Dk5OGxa8PQPjNzOiZMjHbFA+pfGbjQF6Dt35mov7wfbSxSdApKb65FHsb/wvNHO/VeD0T//LDjPP/goovkqXtIV65bNxpadBhX8xc2ydQuW7dtQQPLjQ3B88yWe1qdi/+ar4JOVMgtL/IzgdzfPRfciIhrbesS38ABuvfVWJk8Ofvh33nmHfv2Cl505ePAgX331FQMGDAgpdgGp/v30BXE6nWRlZYXcSou+2ThYHGhaGqDlKnYA+pYtpfZ+pU1v1Toke96/lpXL8z8pCugeYx7nns95H/t63RzeUMWk3hiP85HHgrutAseQNA3nezOgT99IRTsuX9duqDPOPH57icJz2cDYynM+96K5hWoegrBYcM77DK66OpLxsAZOrcF/eo1SoY8xMls3bCBh/OtY9u4xn5u73ef+a90Y+f9FNLZ1TakCrlgaJn379iUjI4O3336bOnXqsGaNcUJxs2bN2LZtG/379yc1NZV77rmHs88+mzlz5nDllVcW8aqhhg0bxvDhw/MN33Mgk+Tk5FL5HEIIEZCRHYXnURZTamIU9hAuQlZWFtUrp5CZWfQyPeK7NAGqVq3KJZdcwpQpU1BKcckll1ClShVz/MnU5KFDh/Lggw+aj7OysqgThb3ghBBClK2oKHhg7Na8917juo1vvPFGyLjGjRujaRqrV68u8es6HA4cuS6wKoQQIjZFxTE8gB49euByuXC73XTvHvrjhZUqVaJ79+688cYbZBdwRYeMgs4NEkIIIXKJmoJnsVhYtWoV//77L5a8P6KKsdXn9Xo566yzmD17NuvWrWPVqlWMHTuWdlHWFVoIIUT0iZpdmsBxDzg2aNCAv/76i2eeeYaHHnqIXbt2UbVqVc444wzGjRsXxpRCCCHKo4j20oyErKwsUlJSpJemEKJMSC/N8CpJL82o2aUphBBClCUpeEIIIWKCFDwhhBAxQQqeEEKImCAFTwghREyQgieEECImSMETQggRE6TgCSGEiAlS8IQQQsQEKXhCCCFighQ8IYQQMUEKnhBCiJggBU8IIURMkIInhBAiJkjBE0IIEROk4AkhhIgJUfWL50IIUd6Vxx9RDdiy/2ikI5TYkcPFzyxbeEIIIWKCFDwhhBAxQQqeEEKImCAFTwghREyQgieEECImSMETQggRE6TgCSGEiAlS8IQQQsQEKXhCCCFighS8UqDf0R+HTct30155OdLRjst2VU/sVSuaeeMC2eNt8OmnkY5XKH3KZGwXnI8jJTE0t03DkWCH77+PdMTje+rJ/O3FrsOHH0Y6WeEOHMAyaSK2Nq3yZ3dYoqK96LNnYR00EHvnDjgqJRNn07D1vhkAR/XKxPnbSt6bI96GI60KjtQk7Kc0x3r/fbBlS4Q/TS5R3F70gweof1ZLGtdJpUmNRPPW1H+r261dyPRVhj5Ak1oVQqbNPb1t9b9lmldTSqkyfYcok5WVRUpKCnsOZJKcnHzSr2c97xysf/wOgALQdfD50PyP3fcMxPfq2JN+n7LgsGlo/vsKzMyBv86p70GvmyIVr1COenXQdmw3swIoTQOlgtm/+BouuDByIQuhDbgL+4S3zJx524tz4mTo0zeSEQtkeWs8tnvvDmkf5J3nM2bC1ddELKP9jFPR/1mGSkpC1a6Nvno13htvwnPaadiHDA7mttnA7Tbbjq9CBXy39AGHA33xn+g/LkKlpOBa9AuqRYuIfR4If3sp6aXFUqZOJO3RQShNw5eQiM9qwZqZaWT3Z9zy6UKcZ54FQMMmNbAezgp+Fk1D83qD7UrTWLs1A6zFv+rlkcNZnNmkBpmZRS/TZQvvZOzejcVf7HwVKuB0K5xOL063QukWNMD25muRzVgMvpo1cc9faNy/8SaU1YoGOPr1jmywQngG3W9+QXyVqwDgu6EXzm27zOGOyy+JYMLCBRZevri40PaiGSsfjv79Ih2xQKpJk+A8T042srt8ofP8xusimtHzymic/67FeTALz+vjzOH2Rx42Fqa6buQ+6sL9wUfmeM3pxPPqa3hefBnXgh/w/O9JtMxMLKMiv4cm2tuLu2Ejtr85mbXbs1i/ZifW7GwAvP7vpQbUuvMWc/p9Dw1l81c/snZXNhuWbcRbqTJZV1yDs0FDY3qlqNX32jLLKwXvJOhDHzHXYlzbd4eMc363EHPTefGfYU5WNG30K8HsazaEjHNNmWbc8fng35Vhz1YUH8G1R8/UacERaWl47r7HuO/xRF12bcBdwXm+a1/IOOdnXwbby4+LwpysaOq7b4PZt+0KjkhLw3Nbf/9EKqJt3de5C6pxY2PLM2DVv2hKGfO2Rg1zsLZpI+DfanK5QtqK97IrjGn2h/6Pwq08tJej7TuTfeV1oOukX3AueDwcuu1uVHy8OY0l13zMuvM+nG1OB6D6wwMB2PPsKHzVa5rTOJb9XWZ5peCdBOsXnwUfHA3dFaD5d/VogO2+e8Oaqzhs49407tjtEBcXMk7fsB7wZ390SJiTFe142UmvB0Rndtv704MPkpJCR17YHfDnvvuO8IUqJtukicYdXYeEhNCRjZsA0dnWtXXrgg+8XvTp72F5/lm0DcGVvLxtRfd/r33ndwtXzAKVp/aSMuVtHKtW4K1chX0jQ7eMvQXsZkz+cBoVvvqUPS++hq9SZTgWXH46m5bdbmT5eaCToGVlmfcdrVvgvbwnVK6MtnED+qefmLt6tPXrCnuJiNH2GFukKjUVy6iX0VesAECf/w2WD6YHs/uHR5Pc2UN4PFimvRucLsqya/7dPcp+/J+P0bZtC0ecEtEyMgBQeYtd3nkeZW1dyzlm3NF1tN27sfe9JXR84O+Pi7A+8jDaX0vQf/4Jz4CBeO8ZEN6weZSb9nLkCNUfewAAV3o90i84F+v2YKb9jzwZMrl121aqDRmEslpJG9gfzZmD5nYDxtbsronTKStS8E6G1wuAqlABzePBOultc5SvUSO0TZuMaXJyIpWwcP4GRmIS1lEvo+3ZA4C2bx/e7j3Qf/oRsrMh+0gEQxYiV/bcrI89ir5yBcpiQfN6oy97oH9YYQswf4cEXK7wZSouf1vPu0VtznNNQ1Mq+tq6zweASk7G/dFsfC1aQoUKaBs3YnnzNSxvT0AD9CNH0P3H7Lznd8V7Q68SdZwoE+WkvTTofIaZNeGvxSHjPIlJZN18a3CAz0eNQXeABprHg+XIYQBz9+zB2wfgS61YZllll2Yp0A4fxtu7L841G8jJzMb5+xJU/QbGQrcccG7fjcvfacXboaNxfMO/dlleaGtWYx39Cr5mzfLv5hRlwvLa2OA8j3RxKErFSvi6nA/Vq0NCAqpRI7RDh8zRPpuNnAOZuD79Am3rFuznd0T/5OMIBi4fKj83DOuO7XiqVWftrmzW7Mpm/70PmuMt2UeoMHuG+bjihNdI+PVHdk16nzW7slnzz2aOtjjF3NKu9PYb6JvWl1leKXgnQ/fPPosFz8ujUA0aGF+m00/HPWtu8KCyzRaphIULZMq7FVS7Dq4vvgk+zrMVFRUKyK7/tQRfixa4vl1odFiB6Mse6ExR2Bq5f2uk0DX6SLJYjL/+LTjLG69je3BQcJ4XsgUYcYHvaJ52bn3xeSyzZpqfS/N4IDkZX4+LcM+YheZ2Y3twULjThor29nLkCJXHvgTAlu+M3uqp74ynyuujUJbgClDag0ZHMtuGdVR5fjiZN9xCdtce4PVS48nBJPy7HE+uXp31L+pUZpGl4J0EZfM3tEDDyy3XsQ5VrVqYEhWfqp4GBI/NhEhPD07XpEmYEhVf7uz6rFnGsJQUY8GblmYuIFSrVhHLWBCVmAiAVsQuKFWnTjjilEjgeKl29CiWV8dgu38gvpatgvM8sOuwUeMIpsxPxRm9BfO2c/1zf4ezAvbCqDZtUBUrom3ZAgcOlHXEQkV7e7Fv3WR2zGt0Sj2a1kik+uMPAaB5jZVODdBdTho2r41j7Wp0p5OUGdOME81rJ5M8z/j+Wg/sN1/XmplB0pdlcyGDqCp4ffv2RdM0NE3DbrfTqFEjRowYgce/xq6UYsKECZx99tkkJSWRmprKmWeeyZgxYzh6tGQnTJYG1aK5/47K10uTn34073rvuDuMqYrHHei+73LlP+7y91/B6Z4aEcZUxZM7u3X8GwD4ul4A1aoZ2f3d0N3Pvxi5kAVw5z6J/0ieLetvvgb8FysYNyF8oYrJHTj1wOfDNvgBfG1ONXaDV6tmtnUFuMe+HrmQBVCN/QU4bzt3OkOnq1cvdNxh49hSJLe2o729eCtWwlshGW+FZHwOh5FH1/EmJRkXgiB4bM7ZrAXuOnXJ6NWHjOtvwVXLKNKu+g3JuLE3nmrVzddVgLtO3TLJHFUFD6BHjx7s2rWLdevW8dBDDzFs2DBeesnYbL7lllu4//77ueKKK1i4cCFLly7liSee4OOPP+abb74p4pVLn3fwI4CxFmOvnRYyztG1s3kOja93n7BnK9Ill5knr9qbNsw1QuE492zzqge0a1fIC0SOeuCh4EnQgV1t/i+co1N743iA3Q4tWkYoYcHUG+PN3PYaVUPGOS69yDyOQYeOYU5WNDXyueA813Vc33wHVYzdUI5uXYzsug5nto1gygI0b1FgO/e17wAEe2l6b+1vjrOOGIbm8eA7sy1UqBC+rHlEe3vx1qjFzremkdmrL7rTSU7r01i/Ygvr1+3BU7M2YGT3JiWxfe43OFu1AaVh3bcH+45tZPTqw6aflrJn1DhclYKfz1O9hjFtGYi6I80Oh4O0NKN43H333cydO5dPPvmEhg0bMn36dObNm8cVV1xhTl+vXj0uv/xysnKdIhAuvquvwZeejr5lC/rhwzhsWsilfwA8vftC5cphz1YU/csvAKMg6zt3YuvWxRj+wftmofae3zVi+Y7Hcv99Zkbdv0tK/2A6jg+mB09IHzAwggkL57rjTuwT3kLPycnXXsxLRUUh/d2pwXnu8+GoXjlfds8dd0U248fzsHw8z3jgP3VF+/1XYxf47l3oO3ca89x/abEAZbOhbd6MdfCD6L/8jP7nH6j4eNyjXo3ApwgV7e2lynNPEr98GQqwbtlEva5nox07hiXD6BCkgMwbgqeCpHwwxcye8uF7JH803ejc5+/lqYDdz71SZnmjruDlFR8fz4EDB5g+fTpNmzYNKXYBmqaRkpJS4POdTifOXLsvSrUw6jquVeuwXHs11s/9+5wDxzIwdgf6/vdE6b1fKfJ17YY640x0/5UxzPORcv21rF+HJxLhimBZ/g8QzFrQfcuSxURjH1n1xnicFSvjeOFZY0CgvWgazmkfwPXXRzBd4fTNm4A87STXsWsNsPy7MqLzXF+2FMu0qaHDNm4075udyALnfGkavjPORDucheW9d43PU6MGnt598T78CKpZszAlL1y0txdX/YbEL1+GhnHsjcyMkPEaELcyeD6sLz4By7GjRvvxekO+t4Hp41eu4OhF+ZfzpSGqLh7dt29fMjIymDdvHkopvvvuOy699FIGDhzI559/TuPGjfn445J1FR42bBjDhw/PN7y0Lh4thBD/FSW9eHQ0KNcXj/7ss89ISkoiLi6Oiy66iOuvv55hw4ZxonV56NChZGZmmrdtkb4qgRBCiIiIul2aXbp0Ydy4cdjtdmrWrInVf0JrkyZNWL16dYlfz+Fw4PB3aBBCCBG7om4LLzExkUaNGlG3bl2z2AH06tWLtWvXFrhLUylFpv83mIQQQoiCRF3BK8x1113H9ddfz4033sizzz7L4sWL2bJlC5999hndunVj4cKFkY4ohBAiikXdLs3CaJrG+++/z4QJE3jnnXd45plnsFqtNG7cmN69e9O9e/dIRxRCCBHFoqqXZjhkZWWRkpIivTSFECIP6aUphBBC/AdIwRNCCBETpOAJIYSICVLwhBBCxAQpeEIIIWKCFDwhhBAxQQqeEEKImCAFTwghREyQgieEECImSMETQggRE6TgCSGEiAlS8IQQQsQEKXhCCCFighQ8IYQQMUEKnhBCiJhQbn4AtrQEfv7vcFZWhJMIIUR0OXK4HP4e3pHDQHDZfjwxV/AOHzZmTqP6dSKcRAghRGk5fPgwKSkpx50m5n7x3OfzsXPnTipUqICmaaX62llZWdSpU4dt27aVu19Tl+zhV15zg2SPhPKaG8o2u1KKw4cPU7NmTXT9+EfpYm4LT9d1ateuXabvkZycXO4aZIBkD7/ymhskeySU19xQdtmL2rILkE4rQgghYoIUPCGEEDFBCl4pcjgcPPXUUzgcjkhHKTHJHn7lNTdI9kgor7kherLHXKcVIYQQsUm28IQQQsQEKXhCCCFighQ8IYQQMUEKnhBCiJggBU/8p/h8vkhHEEJEKSl4Me7o0fJ3sdiC7NixA6DISwuJslNeO3yX19yi5GTpUErK45bFkiVLaN26NVu3bo10lJOybNkyGjRowGeffRbpKMWWdyFbHhe6O3bsYPbs2YwaNYrs7OxSvzZtWdm9ezeLFi1ixowZAOUmd0Ag/1dffRXpKCXi8XhQSuHxeCKWQQreSVi9ejWPP/44W7ZsKXdfmmXLltGlSxcuu+wy6tatG+k4J2zZsmW0a9eOwYMHc+mll0Y6TrGsXLmSrl27MmfOHP766y8guNAtLytOK1as4LLLLmP27Nns27cv0nGKbeXKlVx11VW89tpr/Pbbbxw7dizSkUpk5cqVXHHFFYwaNYrx48fjdrsjHalY1q9fzxNPPMEdd9zBL7/8Erl2rsQJcblcqm3btkrTNNW4cWM1ePBg9dFHH4VM4/F4IpTu+JYtW6YSEhLUY489FjLc6XRGKNGJWbNmjUpOTlYPPvigOczn80Uw0fEFsvXu3VtpmqYef/xx1aRJEzVixAj1559/FjhtNFq1apWqWLGieuyxx9S+ffsiHafYVq5cqVJTU9Vjjz2mNm/eHOk4JZY7/65duyIdp9j++ecfVadOHXXvvfeqF198MaLLRSl4J+HFF19Uo0aNUt9884166qmnVMWKFdXNN9+s3nzzzZAFVjQtvLZu3aqqVKmirrvuupDho0ePVoMHD47aIp3X33//rZKTk5WmaWr06NEqIyMj0pGK5HK5lFJKLV26VHXs2FF98cUX6rvvvlPnnHOO6tGjh7rsssvU8uXL1YEDB5RS0dVuArKzs9Xll1+u+vXrFzI8GrPmlpGRoTp37qzuvvvukOHRnjvg0KFD6vzzz1cDBgwIGR7t+Tds2KBq1KihhgwZEjI8Urlll+ZJaNu2LcOGDaNixYoMGzaMlStX0qhRIwYPHsy5557L22+/zdq1a6Nqd6fX66V+/frk5OTw888/A/D888/z1FNPcckll2CxWCKcsGh///035557Lv/73/946623ePDBB3nzzTfJzMyMdLRCrVy5kueff56srCxq1KhBjRo12Lp1K+f/v717j6op/f8A/tmly9E9kTKEiWJY7ktZJA0lmtAUQ1TLZS23lcuiMBoRYmaaFENhKI37jFCurUErk9ugxqVOl4mK3IYajS6nev/+6He2jooyfTuHPq//zvM8Z+/POWuf/XmeZz/7bAcHOnXqFEVERFB8fDxNnTqVPDw86OzZs/Tw4UNlh11LaWkpZWZmkoODg0K5/BiHil6bLCwspMePH5Orq6tCuarHLVdUVET379+nsWPHKkwH1he/sqF6MEXR0dFkY2ND/v7+CvVKOycqJc1+RJYsWQJPT0+UlJQAACZNmgRra2t4e3vDzs4OGhoaCAkJUXKUijIyMjB69Gi4urpi1qxZaNeuHc6cOaPssBrk0aNH6NmzJ5YtWyaWbdq0CYIgYP369So50ktJSRHjk4uIiICRkREeP34MAPDx8UHHjh0RGRmJ+fPnQxAEeHh44OXLl8oKu063b9+GlpYWEhIS6m0jk8mwceNGvHr1qhkje7uEhAQIgoCMjIx625SWliI6OroZo2q448ePQxAEPH/+HABQWVlZq82rV69w8uTJ5g7trezt7TFt2rQ66+Sf4eXLl+L583+NE95/dPjwYdja2qKyshIzZsyAqakpbt++DQBIT09HWFiY+FqVSKVSjBo1ChKJBN9//72yw2mQgoICbNu2DTNnzkRmZqZCXVhYmEomvTt37kAikWDVqlUAXk/llJeXw93dHXv27MHkyZNhamqKP//8U3zfuXPnkJ2drYyQ3yorKwva2tpYu3YtgLqnps6cOQN3d3eVStbJyclQV1fH4cOHAdSdMA4dOoQpU6aIU8/KlpOTg2PHjgGoPpdoaWkhMjKy3ssOMTExGDZsmMp0NGQyGfr3748FCxaIr+sSEBCAq1evNktMnPCagJ2dHdTU1GBubo6UlBRlh9NgWVlZcHR0hLOzM5KSksRyVbwukJqaCgsLC/Tt2xeampqwtrbG/v37FdrUTHpFRUVKivS1W7duwcTEBD169BDLav7o/fz8IAgCLC0tVbJTBFRfs3v69CnOnTuH/Px8ANWzGjo6OkhOTgbw+jPJjxt/f394enri33//VU7Q9RgyZAh69eqFFy9eAKi9qGzRokWYP3++SiS8Bw8eiMfOgQMHUFFRgT59+mDgwIH1Hit+fn6YP39+vYmlOeTn5+PAgQP4+eefcefOHQQGBsLU1FThvFizs5GXl4eRI0fi0qVLzRIfJ7z/QP4DP3HiBLp3747Y2FiF8g+BfHrTyckJFy9eVHY4dZKvKvXz88ODBw8QHx8PBwcH9OvXD1lZWQo/oLCwMGhoaCAgIECpSS8lJQWtW7eGvb09zM3N4evrK9bJT6gvX77EwIEDFVaZqhKpVAovLy9YW1tDW1sb+vr6mDJlCrZs2QIXFxfo6enhzJkzYmLLy8vDsmXL0LZtW9y9e1dpcb85PSY/Po4dO4Z27dqhf//+uH//vlj/999/Y8WKFTAzM0N6enqzxlqf8+fPQ01NDYMGDYKLiwuOHz+OlJQUmJqawsHBAZcvXxbbFhYWwt/fHx06dEBaWprSYk5NTUXXrl3Rs2dPqKuro1evXpg8eTJ69+6NCRMm4M6dO7XeExgYCBsbGzx58qRZYuSE1wQePXoES0tLrFy5UtmhvJeMjAy4uLjAxsam2XpaDSVfVerh4aFQvn37dujo6Ig/8JqdjA0bNsDIyAjPnj1r1ljlrl27Bg0NDQQGBqKiogKRkZEwMTFRSHplZWWQyWRYvnw5XFxcVGJEWlNqairMzMwwe/ZsREVFIS0tDUuXLoW1tTWsra2xatUqTJo0CYIgYNCgQRg0aBCGDBmCLl264MaNG0qLOz8/Hx4eHjh37pxYJk94JSUl2L17Nzp37gxjY2O4u7vDzc0NI0eORIcOHZQad12mT5+Ovn374ssvv8SIESMQHR2N06dPo3379mjXrh3GjBmDyZMnw9HREebm5kqN/81OaVxcHJycnGBnZ4dp06bB2NgYQ4cOxalTp/D06VNcvHgRc+bMgaGhIVJTU5stTk54TSQmJgY6Ojq4cuWKskN5L2lpaXB3d1fo+aqCnJwcDBo0CK6urgrTrmfPnoWJiYnCj6XmSE9+cV8ZEhMTFZJbYWFhnUkPeL2g5c3pWWWSn7yWL19ea3ps3759GDx4MAYPHozk5GRERUVh9uzZmDZtGnbu3ImcnBzlBP3/srOzYWtri7FjxyrMWMinL8vKypCeno558+ZhzJgxcHR0xNq1a5GVlaWskGspLS0FUD1z5OPjg9OnT8PNzQ329vY4fPgwnjx5Al9fXzg4OMDJyQlBQUFKjb++TunWrVthbGyMhw8f4scff8TAgQMhCAKMjIxgZWUFW1vbZk12ACe8JpOfnw97e3vk5eUpO5T3pqo3nsunXR0dHXH37l28fPkSbdu2rXVvD/B6pKcq08ryOIqKiupNekuWLFHqFGBNdZ28qqqqFBJfREQEDAwMsH37dgB1LwBRpvqm6d+8ZqdKSS43NxdHjhxRKHvy5Amsra2xZcsWPH78GG5ubhg6dCji4uKUFGXd3tYpNTQ0FGdh7t+/j4SEBERFReHatWtKmYHhhNeEmmtpbUuUkZEBZ2dnDB8+HEZGRli4cKFYp2on3PrUTHo1r9upUkejvpMXoNiJsLOzw4QJE2qVq4r6kl5VVRVKSkqwcOFCeHh44NWrV0qPPzc3F23atIEgCBgzZgwOHjwIqVQKoPp2hGHDhuHJkye4e/cu3Nzc8Pnnn4udDUA1vv/GdEqViW88b0La2trKDuGj1a1bNwoLCyN1dXXS19enCRMmiHWqdGP/2+jr69NXX31FwcHBFBoaKt6Mq6mpqeTIXuvcuTPt3buXysvLae3atXTx4sU626mpqZFEIiEi1fz+u3XrRuHh4SQIAgUFBYl/siCTyWjp0qW0efNmWrFiBUkkEqXHX1VVRV26dCEbGxt69OgRJSQkkKOjI23fvp1KSkrIwMCA/vjjD+rRowcFBQWRIAgUFxdH//zzDxGpxvcv/77V1dVpzpw51KlTJ/L09KSNGzcSkQr9R6yyMy5jjZGZmanyq0rfpbCwEFFRUWIvXhXVN0KqrKxEXl4enJ2dERUVBUA1Rhj1qfk5zp8/Dz8/P0gkEpVboJKRkQE3NzeMHz8eR44cQWxsLOzt7TF+/HgIgoDBgweLMwHp6ekqe+kkIyMDDg4OsLCwQGJioliuKscIJzz2wVHlVaUNpSongLepmSxqTm/6+/ujT58+KnvSfZP8eDEyMoKmpiauX7+u7JDqlJ6eDmdnZzg6OkIqlaK4uBiXLl2Ci4sLYmJiAHwYx40qd0o54bEPkqquKv3Y1Ex6N27cwMaNG6Grq/tB/cECUJ1MXF1dVfYGf7mMjAw4OjrC0dFR5ZJFY6hqp1QAVOxfRxlroPLycpW6/vWxyszMpMWLF9PVq1fpxYsXdOnSJRowYICyw2o0mUxGGhoayg7jnTIzM8nX15cA0MqVK2no0KHKDum9pKenU0BAAIWEhKjMMzc54THG3kkqlZKfnx+tX7+ePvvsM2WH89GTdzKePXtGoaGhZGNjo+yQ3ouqdUo54THGGuRDGSF9LFRxhPSh44THGGMqStVGSB86TniMMcZaBL7xnDHGWIvACY8xxliLwAmPMcZYi8AJjzHGWIvACY8xxliLwAmPMcZYi8AJjzEl8vHxofHjx4uv7e3taeHChc0ex4ULF0gQBCosLKy3jSAIdPTo0QZvMzAwkPr27fuf4rp37x4JgkApKSn/aTuMEXHCY6wWHx8fEgSBBEEgTU1NsrS0pDVr1lBFRcX/fN9HjhyhoKCgBrVtSJJijL3WStkBMKaKRo8eTbt376aysjI6efIkzZs3jzQ0NGj58uW12jblv2EYGxs3yXYYY7XxCI+xOmhpaVH79u3JwsKC5syZQyNHjqTjx48T0etpyHXr1pG5uTlZWVkREVFeXh5NnDiRDA0NydjYmMaNG0f37t0Tt1lZWUmLFy8mQ0NDatOmDfn5+dGbf3T05pRmWVkZ+fv7U8eOHUlLS4ssLS3pp59+onv37tGIESOIiMjIyIgEQSAfHx8iqn66dHBwMHXp0oUkEgn16dOHfvnlF4X9nDx5krp3704SiYRGjBihEGdD+fv7U/fu3al169bUtWtXCggIIJlMVqtdZGQkdezYkVq3bk0TJ06koqIihfqdO3dSjx49SFtbm6ytrWnr1q2NjoWxhuCEx1gDSCQSKi8vF1//9ttvJJVKKSEhgeLj40kmk5GTkxPp6elRUlIS/f7776Srq0ujR48W3xcSEkJRUVG0a9cuunjxIj1//pxiY2Pful8vLy/av38/hYeHU1paGkVGRpKuri517NiRfv31VyKqfpJBQUEBhYWFERFRcHAw7dmzhyIiIujOnTu0aNEimjp1KiUmJhJRdWJ2c3OjL774glJSUmjmzJm0bNmyRn8nenp6FBUVRXfv3qWwsDDasWMHhYaGKrTJysqiQ4cOUVxcHJ0+fZpu3rxJc+fOFev37t1L33zzDa1bt47S0tJo/fr1FBAQQNHR0Y2Oh7F3Us5j+BhTXd7e3hg3bhyA6idMJyQkQEtLC0uWLBHrTU1NUVZWJr4nJiYGVlZWCk+kLisrg0QiwZkzZwAAZmZm+Pbbb8V6mUyGTz75RNwXAAwfPhwLFiwAAEilUhAREhIS6ozz/PnzICK8ePFCLCstLUXr1q2RnJys0HbGjBmYPHkyAGD58uXo2bOnQr2/v3+tbb2JiBAbG1tv/XfffYcBAwaIr1etWgV1dXXk5+eLZadOnYKamhoKCgoAAJ9++in27dunsJ2goCDY2toCAHJyckBEuHnzZr37Zayh+BoeY3WIj48nXV1dkslkVFVVRVOmTKHAwECxvnfv3grX7VJTUykrK4v09PQUtlNaWkrZ2dlUVFREBQUFNHjwYLGuVatWNHDgwFrTmnIpKSmkrq5Ow4cPb3DcWVlZ9OrVKxo1apRCeXl5OfXr14+IiNLS0hTiICKytbVt8D7kDh48SOHh4ZSdnU3FxcVUUVFB+vr6Cm06depEHTp0UNhPVVUVSaVS0tPTo+zsbJoxYwbNmjVLbFNRUUEGBgaNjoexd+GEx1gdRowYQdu2bSNNTU0yNzenVq0Ufyo6OjoKr4uLi2nAgAG0d+/eWttq27bte8UgkUga/Z7i4mIiIjpx4oRCoiGqvi7ZVC5dukSenp60evVqcnJyIgMDAzpw4ACFhIQ0OtYdO3bUSsDq6upNFitjcpzwGKuDjo4OWVpaNrh9//796eDBg9SuXbtaoxw5MzMzunLlCtnZ2RFR9Ujm+vXr1L9//zrb9+7dm6qqqigxMZFGjhxZq14+wqysrBTLevbsSVpaWpSbm1vvyLBHjx7iAhy5y5cvv/tD1pCcnEwWFhb09ddfi2X379+v1S43N5cePnxI5ubm4n7U1NTIysqKTE1NydzcnP766y/y9PRs1P4Zex+8aIWxJuDp6UkmJiY0btw4SkpKopycHLpw4QL5+vpSfn4+EREtWLCANmzYQEePHqX09HSaO3fuW++h69y5M3l7e9P06dPp6NGj4jYPHTpEREQWFhYkCALFx8fT06dPqbi4mPT09GjJkiW0aNEiio6OpuzsbLpx4wZt3rxZXAgye/ZsyszMpKVLl5JUKqV9+/ZRVFRUoz5vt27dKDc3lw4cOEDZ2dkUHh5e5wIcbW1t8vb2ptTUVEpKSiJfX1+aOHEitW/fnoiIVq9eTcHBwRQeHk4ZGRl069Yt2r17N/3www+NioexBlH2RUTGVE3NRSuNqS8oKICXlxdMTEygpaWFrl27YtasWSgqKgJQvUhlwYIF0NfXh6GhIRYvXgwvL696F60AQElJCRYtWgQzMzNoamrC0tISu3btEuvXrFmD9u3bQxAEeHt7A6heaLNp0yZYWVlBQ0MDbdu2hZOTExITE8X3xcXFwdLSElpaWhg2bBh27drV6EUrS5cuRZs2baCrq4tJkyYhNDQUBgYGYv2qVavQp08fbN26Febm5tDW1oa7uzueP3+usN29e/eib9++0NTUhJGREezs7HDkyBEAvGiFNS1+4jljjLEWgac0GWOMtQic8BhjjLUInPAYY4y1CJzwGGOMtQic8BhjjLUInPAYY4y1CJzwGGOMtQic8BhjjLUInPAYY4y1CJzwGGOMtQic8BhjjLUInPAYY4y1CP8HlN1i8u6vVokAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}